{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "993f2816-8032-4f82-8db6-644ba88aa8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full Patent Object Structure (for debugging) ---\n",
      "{\n",
      "  \"lens_id\": \"049-288-157-543-024\",\n",
      "  \"jurisdiction\": \"US\",\n",
      "  \"doc_number\": \"11613249\",\n",
      "  \"kind\": \"B2\",\n",
      "  \"date_published\": \"2023-03-28\",\n",
      "  \"doc_key\": \"US_11613249_B2_20230328\",\n",
      "  \"docdb_id\": 589723351,\n",
      "  \"lang\": \"en\",\n",
      "  \"biblio\": {\n",
      "    \"publication_reference\": {\n",
      "      \"jurisdiction\": \"US\",\n",
      "      \"doc_number\": \"11613249\",\n",
      "      \"kind\": \"B2\",\n",
      "      \"date\": \"2023-03-28\"\n",
      "    },\n",
      "    \"application_reference\": {\n",
      "      \"jurisdiction\": \"US\",\n",
      "      \"doc_number\": \"201815944563\",\n",
      "      \"kind\": \"A\",\n",
      "      \"date\": \"2018-04-03\"\n",
      "    },\n",
      "    \"priority_claims\": {\n",
      "      \"claims\": [\n",
      "        {\n",
      "          \"jurisdiction\": \"US\",\n",
      "          \"doc_number\": \"201815944563\",\n",
      "          \"kind\": \"A\",\n",
      "          \"date\": \"2018-04-03\",\n",
      "          \"sequence\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"earliest_claim\": {\n",
      "        \"date\": \"2018-04-03\"\n",
      "      }\n",
      "    },\n",
      "    \"invention_title\": [\n",
      "      {\n",
      "        \"text\": \"Automatic navigation using deep reinforcement learning\",\n",
      "        \"lang\": \"en\"\n",
      "      }\n",
      "    ],\n",
      "    \"parties\": {\n",
      "      \"examiners\": {\n",
      "        \"primary_examiner\": {\n",
      "          \"department\": \"3669\",\n",
      "          \"extracted_name\": {\n",
      "            \"value\": \"Rami Khatib\"\n",
      "          }\n",
      "        },\n",
      "        \"assistant_examiner\": {\n",
      "          \"extracted_name\": {\n",
      "            \"value\": \"Shahira Baajour\"\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"applicants\": [\n",
      "        {\n",
      "          \"residence\": \"US\",\n",
      "          \"extracted_name\": {\n",
      "            \"value\": \"FORD GLOBAL TECH LLC\"\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"inventors\": [\n",
      "        {\n",
      "          \"residence\": \"US\",\n",
      "          \"sequence\": 1,\n",
      "          \"extracted_name\": {\n",
      "            \"value\": \"BALAKRISHNAN KAUSHIK\"\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"residence\": \"US\",\n",
      "          \"sequence\": 2,\n",
      "          \"extracted_name\": {\n",
      "            \"value\": \"NARAYANAN PRAVEEN\"\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"residence\": \"US\",\n",
      "          \"sequence\": 3,\n",
      "          \"extracted_name\": {\n",
      "            \"value\": \"LAKEHAL-AYAT MOHSEN\"\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"agents\": [\n",
      "        {\n",
      "          \"extracted_name\": {\n",
      "            \"value\": \"David R. Stevens\"\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"extracted_name\": {\n",
      "            \"value\": \"Stevens Law Group\"\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"owners_all\": [\n",
      "        {\n",
      "          \"recorded_date\": \"2018-04-03\",\n",
      "          \"execution_date\": \"2018-03-09\",\n",
      "          \"extracted_name\": {\n",
      "            \"value\": \"FORD GLOBAL TECHNOLOGIES LLC\"\n",
      "          },\n",
      "          \"extracted_address\": \"330 TOWN CENTER DRIVE, SUITE 800, DEARBORN, MICHIGAN, 48126\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    \"classifications_ipcr\": {\n",
      "      \"classifications\": [\n",
      "        {\n",
      "          \"symbol\": \"B60W30/06\",\n",
      "          \"classification_value\": \"I\",\n",
      "          \"classification_symbol_position\": \"F\"\n",
      "        },\n",
      "        {\n",
      "          \"symbol\": \"G05D1/00\",\n",
      "          \"classification_value\": \"I\",\n",
      "          \"classification_symbol_position\": \"L\"\n",
      "        },\n",
      "        {\n",
      "          \"symbol\": \"G05D1/02\",\n",
      "          \"classification_value\": \"I\",\n",
      "          \"classification_symbol_position\": \"L\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    \"classifications_cpc\": {\n",
      "      \"classifications\": [\n",
      "        {\n",
      "          \"symbol\": \"B60W30/06\",\n",
      "          \"classification_value\": \"I\",\n",
      "          \"classification_symbol_position\": \"F\"\n",
      "        },\n",
      "        {\n",
      "          \"symbol\": \"B60W2556/50\",\n",
      "          \"classification_value\": \"A\",\n",
      "          \"classification_symbol_position\": \"L\"\n",
      "        },\n",
      "        {\n",
      "          \"symbol\": \"G01C21/00\",\n",
      "          \"classification_value\": \"I\",\n",
      "          \"classification_symbol_position\": \"L\"\n",
      "        },\n",
      "        {\n",
      "          \"symbol\": \"B62D15/0285\",\n",
      "          \"classification_value\": \"I\",\n",
      "          \"classification_symbol_position\": \"F\"\n",
      "        },\n",
      "        {\n",
      "          \"symbol\": \"G06N3/006\",\n",
      "          \"classification_value\": \"I\",\n",
      "          \"classification_symbol_position\": \"L\"\n",
      "        },\n",
      "        {\n",
      "          \"symbol\": \"G06N3/045\",\n",
      "          \"classification_value\": \"I\",\n",
      "          \"classification_symbol_position\": \"L\"\n",
      "        },\n",
      "        {\n",
      "          \"symbol\": \"G06N3/08\",\n",
      "          \"classification_value\": \"I\",\n",
      "          \"classification_symbol_position\": \"L\"\n",
      "        },\n",
      "        {\n",
      "          \"symbol\": \"B60W30/06\",\n",
      "          \"classification_value\": \"I\",\n",
      "          \"classification_symbol_position\": \"F\"\n",
      "        },\n",
      "        {\n",
      "          \"symbol\": \"G05D1/0088\",\n",
      "          \"classification_value\": \"I\",\n",
      "          \"classification_symbol_position\": \"L\"\n",
      "        },\n",
      "        {\n",
      "          \"symbol\": \"G05D1/0088\",\n",
      "          \"classification_value\": \"I\",\n",
      "          \"classification_symbol_position\": \"L\"\n",
      "        },\n",
      "        {\n",
      "          \"symbol\": \"G05D1/0221\",\n",
      "          \"classification_value\": \"I\",\n",
      "          \"classification_symbol_position\": \"L\"\n",
      "        },\n",
      "        {\n",
      "          \"symbol\": \"G05D1/0221\",\n",
      "          \"classification_value\": \"I\",\n",
      "          \"classification_symbol_position\": \"L\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    \"references_cited\": {\n",
      "      \"citations\": [\n",
      "        {\n",
      "          \"sequence\": 1,\n",
      "          \"patcit\": {\n",
      "            \"document_id\": {\n",
      "              \"jurisdiction\": \"US\",\n",
      "              \"doc_number\": \"10545510\",\n",
      "              \"kind\": \"B2\",\n",
      "              \"date\": \"2020-01-28\"\n",
      "            },\n",
      "            \"lens_id\": \"019-024-208-856-040\"\n",
      "          },\n",
      "          \"cited_phase\": \"SEA\"\n",
      "        },\n",
      "        {\n",
      "          \"sequence\": 2,\n",
      "          \"patcit\": {\n",
      "            \"document_id\": {\n",
      "              \"jurisdiction\": \"US\",\n",
      "              \"doc_number\": \"10782694\",\n",
      "              \"kind\": \"B2\",\n",
      "              \"date\": \"2020-09-22\"\n",
      "            },\n",
      "            \"lens_id\": \"114-282-510-314-395\"\n",
      "          },\n",
      "          \"cited_phase\": \"SEA\"\n",
      "        },\n",
      "        {\n",
      "          \"sequence\": 3,\n",
      "          \"patcit\": {\n",
      "            \"document_id\": {\n",
      "              \"jurisdiction\": \"US\",\n",
      "              \"doc_number\": \"2018032863\",\n",
      "              \"kind\": \"A1\",\n",
      "              \"date\": \"2018-02-01\"\n",
      "            },\n",
      "            \"lens_id\": \"169-245-508-611-908\"\n",
      "          },\n",
      "          \"cited_phase\": \"SEA\"\n",
      "        },\n",
      "        {\n",
      "          \"sequence\": 4,\n",
      "          \"patcit\": {\n",
      "            \"document_id\": {\n",
      "              \"jurisdiction\": \"US\",\n",
      "              \"doc_number\": \"2020151562\",\n",
      "              \"kind\": \"A1\",\n",
      "              \"date\": \"2020-05-14\"\n",
      "            },\n",
      "            \"lens_id\": \"008-724-839-877-196\"\n",
      "          },\n",
      "          \"cited_phase\": \"SEA\"\n",
      "        },\n",
      "        {\n",
      "          \"sequence\": 5,\n",
      "          \"nplcit\": {\n",
      "            \"text\": \"English Translation of CN-105527963-A.\"\n",
      "          },\n",
      "          \"cited_phase\": \"SEA\"\n",
      "        },\n",
      "        {\n",
      "          \"sequence\": 1,\n",
      "          \"patcit\": {\n",
      "            \"document_id\": {\n",
      "              \"jurisdiction\": \"US\",\n",
      "              \"doc_number\": \"2017329331\",\n",
      "              \"kind\": \"A1\",\n",
      "              \"date\": \"2017-11-16\"\n",
      "            },\n",
      "            \"lens_id\": \"001-949-535-605-223\"\n",
      "          },\n",
      "          \"cited_phase\": \"APP\"\n",
      "        },\n",
      "        {\n",
      "          \"sequence\": 2,\n",
      "          \"patcit\": {\n",
      "            \"document_id\": {\n",
      "              \"jurisdiction\": \"CN\",\n",
      "              \"doc_number\": \"105109482\",\n",
      "              \"kind\": \"A\",\n",
      "              \"date\": \"2015-12-02\"\n",
      "            },\n",
      "            \"lens_id\": \"155-144-817-842-186\"\n",
      "          },\n",
      "          \"cited_phase\": \"APP\"\n",
      "        },\n",
      "        {\n",
      "          \"sequence\": 3,\n",
      "          \"patcit\": {\n",
      "            \"document_id\": {\n",
      "              \"jurisdiction\": \"CN\",\n",
      "              \"doc_number\": \"105527963\",\n",
      "              \"kind\": \"A\",\n",
      "              \"date\": \"2016-04-27\"\n",
      "            },\n",
      "            \"lens_id\": \"103-500-704-713-785\"\n",
      "          },\n",
      "          \"cited_phase\": \"APP\"\n",
      "        },\n",
      "        {\n",
      "          \"sequence\": 4,\n",
      "          \"patcit\": {\n",
      "            \"document_id\": {\n",
      "              \"jurisdiction\": \"CN\",\n",
      "              \"doc_number\": \"107065567\",\n",
      "              \"kind\": \"A\",\n",
      "              \"date\": \"2017-08-18\"\n",
      "            },\n",
      "            \"lens_id\": \"067-306-385-666-842\"\n",
      "          },\n",
      "          \"cited_phase\": \"APP\"\n",
      "        },\n",
      "        {\n",
      "          \"sequence\": 5,\n",
      "          \"nplcit\": {\n",
      "            \"text\": \"A Vision-Guided Parallel Parking System for a Mobile Robot using Approximate Policy Iteration.\"\n",
      "          },\n",
      "          \"cited_phase\": \"APP\"\n",
      "        },\n",
      "        {\n",
      "          \"sequence\": 6,\n",
      "          \"nplcit\": {\n",
      "            \"text\": \"GitHub\\u2014taochenshh/Automatic-Parking: Automatic parking with Reinforcement Learning.\"\n",
      "          },\n",
      "          \"cited_phase\": \"APP\"\n",
      "        },\n",
      "        {\n",
      "          \"sequence\": 7,\n",
      "          \"nplcit\": {\n",
      "            \"text\": \"Smart Parking According to AUDI.\"\n",
      "          },\n",
      "          \"cited_phase\": \"APP\"\n",
      "        }\n",
      "      ],\n",
      "      \"patent_count\": 8,\n",
      "      \"npl_count\": 4\n",
      "    },\n",
      "    \"cited_by\": {}\n",
      "  },\n",
      "  \"families\": {\n",
      "    \"simple_family\": {\n",
      "      \"members\": [\n",
      "        {\n",
      "          \"document_id\": {\n",
      "            \"jurisdiction\": \"US\",\n",
      "            \"doc_number\": \"11613249\",\n",
      "            \"kind\": \"B2\",\n",
      "            \"date\": \"2023-03-28\"\n",
      "          },\n",
      "          \"lens_id\": \"049-288-157-543-024\"\n",
      "        },\n",
      "        {\n",
      "          \"document_id\": {\n",
      "            \"jurisdiction\": \"CN\",\n",
      "            \"doc_number\": \"110341700\",\n",
      "            \"kind\": \"A\",\n",
      "            \"date\": \"2019-10-18\"\n",
      "          },\n",
      "          \"lens_id\": \"141-761-458-761-039\"\n",
      "        },\n",
      "        {\n",
      "          \"document_id\": {\n",
      "            \"jurisdiction\": \"US\",\n",
      "            \"doc_number\": \"20190299978\",\n",
      "            \"kind\": \"A1\",\n",
      "            \"date\": \"2019-10-03\"\n",
      "          },\n",
      "          \"lens_id\": \"088-830-781-013-731\"\n",
      "        },\n",
      "        {\n",
      "          \"document_id\": {\n",
      "            \"jurisdiction\": \"DE\",\n",
      "            \"doc_number\": \"102019108477\",\n",
      "            \"kind\": \"A1\",\n",
      "            \"date\": \"2019-10-10\"\n",
      "          },\n",
      "          \"lens_id\": \"089-742-165-265-720\"\n",
      "        }\n",
      "      ],\n",
      "      \"size\": 4\n",
      "    },\n",
      "    \"extended_family\": {\n",
      "      \"members\": [\n",
      "        {\n",
      "          \"document_id\": {\n",
      "            \"jurisdiction\": \"US\",\n",
      "            \"doc_number\": \"11613249\",\n",
      "            \"kind\": \"B2\",\n",
      "            \"date\": \"2023-03-28\"\n",
      "          },\n",
      "          \"lens_id\": \"049-288-157-543-024\"\n",
      "        },\n",
      "        {\n",
      "          \"document_id\": {\n",
      "            \"jurisdiction\": \"CN\",\n",
      "            \"doc_number\": \"110341700\",\n",
      "            \"kind\": \"A\",\n",
      "            \"date\": \"2019-10-18\"\n",
      "          },\n",
      "          \"lens_id\": \"141-761-458-761-039\"\n",
      "        },\n",
      "        {\n",
      "          \"document_id\": {\n",
      "            \"jurisdiction\": \"US\",\n",
      "            \"doc_number\": \"20190299978\",\n",
      "            \"kind\": \"A1\",\n",
      "            \"date\": \"2019-10-03\"\n",
      "          },\n",
      "          \"lens_id\": \"088-830-781-013-731\"\n",
      "        },\n",
      "        {\n",
      "          \"document_id\": {\n",
      "            \"jurisdiction\": \"DE\",\n",
      "            \"doc_number\": \"102019108477\",\n",
      "            \"kind\": \"A1\",\n",
      "            \"date\": \"2019-10-10\"\n",
      "          },\n",
      "          \"lens_id\": \"089-742-165-265-720\"\n",
      "        }\n",
      "      ],\n",
      "      \"size\": 4\n",
      "    }\n",
      "  },\n",
      "  \"legal_status\": {\n",
      "    \"granted\": true,\n",
      "    \"grant_date\": \"2023-03-28\",\n",
      "    \"anticipated_term_date\": \"2042-01-27\",\n",
      "    \"calculation_log\": [\n",
      "      \"Application Filing Date: 2018-04-03\",\n",
      "      \"Granted Date: 2023-03-28\",\n",
      "      \"Applied 1395 days term extension.\",\n",
      "      \"Anticipated Termination Date: 2042-01-27\"\n",
      "    ],\n",
      "    \"patent_status\": \"ACTIVE\"\n",
      "  },\n",
      "  \"abstract\": [\n",
      "    {\n",
      "      \"text\": \"A method for training an autonomous vehicle to reach a target location. The method includes detecting the state of an autonomous vehicle in a simulated environment, and using a neural network to navigate the vehicle from an initial location to a target destination. During the training phase, a second neural network may reward the first neural network for a desired action taken by the autonomous vehicle, and may penalize the first neural network for an undesired action taken by the autonomous vehicle. A corresponding system and computer program product are also disclosed and claimed herein.\",\n",
      "      \"lang\": \"en\"\n",
      "    }\n",
      "  ],\n",
      "  \"claims\": [\n",
      "    {\n",
      "      \"claims\": [\n",
      "        {\n",
      "          \"claim_text\": [\n",
      "            \"1. A method comprising: identifying a state of an autonomous vehicle within a simulated environment, wherein the simulated environment comprises a plurality of operating parameters for training a reinforcement learning framework to calculate driving maneuvers for the autonomous vehicle; calculating, with an actor neural network, a driving maneuver for navigating the autonomous vehicle from an initial location to a target destination; determining, with a critic neural network, whether the driving maneuver was beneficial for accurately maneuvering the autonomous vehicle to the target destination; in response to determining the driving maneuver was beneficial, causing the critic neural network to reward the actor neural network during a training phase for the reinforcement learning framework; and in response to determining the driving maneuver was not beneficial, causing the critic neural network to penalize the actor neural network during the training phase for the reinforcement learning framework; wherein the critic neural network rewards the actor neural network by providing an error signal calculated with an exploration-exploitation tradeoff model.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"claim_text\": [\n",
      "            \"2. The method of claim 1 , wherein each of the actor neural network and the critic neural network are installed onboard the autonomous vehicle during the training phase for the reinforcement learning framework.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"claim_text\": [\n",
      "            \"3. The method of claim 1 , wherein the autonomous vehicle comprises at least one sensor selected from a group consisting of a camera sensor, a lidar sensor, a radar sensor, a GPS sensor, and an ultrasound sensor.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"claim_text\": [\n",
      "            \"4. The method of claim 1 , further comprising determining a state of the autonomous vehicle within the simulated environment, wherein the state comprises one or more of a location or an orientation of the autonomous vehicle.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"claim_text\": [\n",
      "            \"5. The method of claim 1 , wherein the critic neural network penalizes the actor neural network by providing an error signal calculated with an exploration-exploitation tradeoff model.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"claim_text\": [\n",
      "            \"6. The method of claim 1 , further comprising storing one or more of a state of the autonomous vehicle, an action taken at the state of the autonomous vehicle, or a reward and a penalty corresponding to the action in a replay buffer.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"claim_text\": [\n",
      "            \"7. The method of claim 6 , further comprising sampling the replay buffer to train the actor neural network.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"claim_text\": [\n",
      "            \"8. The method of claim 7 , further comprising iteratively navigating the autonomous vehicle from the initial location to the target destination in accordance with the training.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"claim_text\": [\n",
      "            \"9. The method of claim 1 , wherein calculating the driving maneuver further comprises: calculating a plurality of driving maneuvers for a plurality of autonomous vehicles from the initial location to the target destination, wherein the plurality of autonomous vehicles comprises the autonomous vehicle; and communicating information from a neural network corresponding to each of the plurality of autonomous vehicles to a central master actor.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"claim_text\": [\n",
      "            \"10. A system comprising: an autonomous vehicle comprising a sensor; one or more processors configurable to execute instructions stored in non-transitory computer readable memory, the instructions comprising: identifying a state of an autonomous vehicle within a simulated environment, wherein the simulated environment comprises a plurality of operating parameters for training a reinforcement learning framework to calculate driving maneuvers for the autonomous vehicle; calculating, with an actor neural network, a driving maneuver for navigating the autonomous vehicle from an initial location to a target destination; determining, with a critic neural network, whether the driving maneuver was beneficial for accurately maneuvering the autonomous vehicle to the target destination; in response to determining the driving maneuver was beneficial, causing the critic neural network to reward the actor neural network during a training phase for the reinforcement learning framework; and in response to determining the driving maneuver was not beneficial, causing the critic neural network to penalize the actor neural network during the training phase for the reinforcement learning framework; wherein the critic neural network rewards the actor neural network by providing an error signal calculated with an exploration-exploitation tradeoff model.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"claim_text\": [\n",
      "            \"11. The system of claim 10 , wherein each of the actor neural network and the critic neural network are installed onboard the autonomous vehicle during the training phase for the reinforcement learning framework.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"claim_text\": [\n",
      "            \"12. The system of claim 10 , wherein the sensor of the autonomous vehicle comprises one or more of a camera sensor, a lidar sensor, a radar sensor, a GPS sensor, and an ultrasound sensor.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"claim_text\": [\n",
      "            \"13. The system of claim 10 , wherein the instructions further comprise determining a state of the autonomous vehicle within the simulated environment, wherein the state of the autonomous vehicle comprises one or more of a location or an orientation of the autonomous vehicle.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"claim_text\": [\n",
      "            \"14. The system of claim 10 , wherein the critic neural network rewards the actor neural network by providing an error signal calculated using an exploration-exploitation tradeoff model.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"claim_text\": [\n",
      "            \"15. The system of claim 10 , wherein the instructions further comprise storing one or more of a state of the autonomous vehicle, an action taken at the state of the autonomous vehicle, or a reward and a penalty corresponding to the action in a replay buffer.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"claim_text\": [\n",
      "            \"16. The system of claim 10 , wherein the instructions further comprise: calculating a new plurality of driving maneuvers for a plurality of autonomous vehicles from the initial location to the target destination, wherein the plurality of autonomous vehicles comprises the autonomous vehicle; and communicating information from a neural network corresponding to each of the plurality of autonomous vehicles to a central master actor.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"claim_text\": [\n",
      "            \"17. Non-transitory computer readable storage medium storing instructions for execution by one or more processors, the instructions comprising: identifying a state of an autonomous vehicle within a simulated environment, wherein the simulated environment comprises a plurality of operating parameters for training a reinforcement learning framework to calculate driving maneuvers for the autonomous vehicle; calculating, with an actor neural network, a driving maneuver for navigating the autonomous vehicle from an initial location to a target destination; determining, with a critic neural network, whether the driving maneuver was beneficial for accurately maneuvering the autonomous vehicle to the target destination; in response to determining the driving maneuver was beneficial, causing the critic neural network to reward the actor during a training phase for the reinforcement learning framework; and in response to determining the driving maneuver was not beneficial, causing the critic neural network to penalize the actor neural network during the training phase for the reinforcement learning framework; wherein the critic neural network rewards the actor neural network by providing an error signal calculated with an exploration-exploitation tradeoff model.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"claim_text\": [\n",
      "            \"18. The non-transitory computer readable storage medium of claim 17 , wherein the instructions further comprise: calculating a new plurality of driving maneuvers for a plurality of autonomous vehicles from the initial location to the target destination, wherein the plurality of autonomous vehicles comprises the autonomous vehicle; and communicating information from a neural network corresponding to each of the plurality of autonomous vehicles to a central master actor.\"\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"lang\": \"en\"\n",
      "    }\n",
      "  ],\n",
      "  \"description\": {\n",
      "    \"text\": \"BACKGROUND Field of the Invention This invention relates to navigation for vehicles. Background of the Invention Parking a vehicle, especially parallel parking, is a skill that requires much practice and trial-and-error experience. Even experienced drivers tend to avoid this task since proper maneuvering depends not only on the skill of the driver, but also on largely unpredictable environmental factors, such as the slope and area of the available parking spot and the orientation and movement of adjacent vehicles. In addition, the high costs associated with even small mistakes often deter all but the most confident drivers. Automatic parking technology has been developed to autonomously move a vehicle into a desired parking spot from an initial starting location, such as a traffic lane. To this end, modern automatic parking systems engage in a step-by-step process where steering angle, brake and accelerator values are calculated in situ by an onboard vehicle network. Coordinated control of the steering angle and speed, taking into account the current pose of the vehicle and surrounding environment, virtually ensures collision-free orientation of the vehicle in an available parking space. Though still under development, automatic parking capability is also an integral component of autonomous vehicles. Such vehicles may be required to perform parallel parking maneuvers under the same wide range of initial conditions and/or operational parameters as human drivers. In addition, autonomous vehicles may be required to drive under special scenarios, such as accident zones or construction zones, that are not included as part of a pre-determined map. Successful navigation is critical in any case, as high costs may result from small mistakes. In view of the foregoing, what are needed are systems and methods to train an autonomous vehicle to automatically reach a desired target location. Ideally, such systems and methods would train an autonomous vehicle to efficiently and accurately respond to a wide range of initial locations, orientations, and operating parameters of the vehicle relative to a final target destination location. Such systems and methods would also be scalable, robust, and utilize trial-and-error training to enable a network to learn from its mistakes. BRIEF DESCRIPTION OF THE DRAWINGS In order that the advantages of the invention will be readily understood, a more particular description of the invention briefly described above will be rendered by reference to specific embodiments illustrated in the appended drawings. Understanding that these drawings depict only typical embodiments of the invention and are not therefore to be considered limiting of its scope, the invention will be described and explained with additional specificity and detail through use of the accompanying drawings, in which: FIG. 1 is a high-level block diagram showing one example of a computing system in which a system and method in accordance with the invention may be implemented; FIG. 2 is a high-level block diagram showing components of a system for training an autonomous vehicle to reach a target destination in accordance with certain embodiments of the invention; FIG. 3 is a flow chart showing a process for automatic maneuvering in accordance with embodiments of the invention; FIG. 4 is a high-level schematic diagram showing training an autonomous vehicle to perform perpendicular parking in accordance with certain embodiments of the invention; FIG. 5 is a high-level schematic diagram showing training an autonomous vehicle to perform angled parking in accordance with certain embodiments of the invention; FIG. 6 is a high-level schematic diagram showing a simulated environment providing a parallel parking space and an accident zone in accordance with certain embodiments of the invention; and FIG. 7 is a flow chart showing a process for automatic vehicle navigation using deep reinforcement learning in accordance with certain embodiments of the invention. DETAILED DESCRIPTION Referring to FIG. 1 , one example of a computing system 100 is illustrated. The computing system 100 is presented to show one example of an environment where a system and method in accordance with the invention may be implemented. The computing system 100 may be embodied as a mobile device 100 such as a smart phone or tablet, a desktop computer, a workstation, a server, or the like. The computing system 100 is presented by way of example and is not intended to be limiting. Indeed, the systems and methods disclosed herein may be applicable to a wide variety of different computing systems in addition to the computing system 100 shown. The systems and methods disclosed herein may also potentially be distributed across multiple computing systems 100 . As shown, the computing system 100 includes at least one processor 102 and may include more than one processor 102 . The processor 102 may be operably connected to a memory 104 . The memory 104 may include one or more non-volatile storage devices such as hard drives 104 a, solid state drives 104 a, CD-ROM drives 104 a, DVD-ROM drives 104 a, tape drives 104 a, or the like. The memory 104 may also include non-volatile memory such as a read-only memory 104 b (e.g., ROM, EPROM, EEPROM, and/or Flash ROM) or volatile memory such as a random access memory 104 c (RAM or operational memory). A bus 106 , or plurality of buses 106 , may interconnect the processor 102 , memory devices 104 , and other devices to enable data and/or instructions to pass therebetween. To enable communication with external systems or devices, the computing system 100 may include one or more ports 108 . Such ports 108 may be embodied as wired ports 108 (e.g., USB ports, serial ports, Firewire ports, SCSI ports, parallel ports, etc.) or wireless ports 108 (e.g., Bluetooth, IrDA, etc.). The ports 108 may enable communication with one or more input devices 110 (e.g., keyboards, mice, touchscreens, cameras, microphones, scanners, storage devices, etc.) and output devices 112 (e.g., displays, monitors, speakers, printers, storage devices, etc.). The ports 108 may also enable communication with other computing systems 100 . In certain embodiments, the computing system 100 includes a wired or wireless network adapter 114 to connect the computing system 100 to a network 116 , such as a LAN, WAN, or the Internet. Such a network 116 may enable the computing system 100 to connect to one or more servers 118 , workstations 120 , personal computers 120 , mobile computing devices, or other devices. The network 116 may also enable the computing system 100 to connect to another network by way of a router 122 or other device 122 . Such a router 122 may allow the computing system 100 to communicate with servers, workstations, personal computers, or other devices located on different networks. As previously mentioned, autonomous vehicle technology is currently under development with the goal of providing a fully-autonomous vehicle capable of performing the same functions and maneuvers as a human operator, with even greater precision and efficiency. Automatic parking and navigation under a variety of circumstances is critical to autonomous vehicle functionality. Embodiments of the invention address this issue by training autonomous vehicles in a simulated environment to efficiently and accurately respond to a range of initial locations, orientations, and operating parameters of the vehicle relative to a final target destination location. As discussed in detail below, a system for automatically navigating an autonomous vehicle using deep reinforcement learning in accordance with the invention may guide an autonomous vehicle from an initial location to a desired target location in a step-by-step process. In certain embodiments, steering angle, brake and accelerator values may be calculated in situ by an onboard neural network. The network may receive the current location and orientation of the vehicle as input from an array of sensors. Two unique deep reinforcement learning frameworks\\u2014a deep Q-network and an asynchronous advantage (\\u201cA3N\\u201d) actor-critic network\\u2014may be implemented to train the onboard network. Output from these frameworks may be fed into the control system of the autonomous vehicle in real time to execute the maneuver. Referring now to FIG. 2 , a system 200 for automatic navigation using deep reinforcement learning in accordance with the invention may include an autonomous vehicle having an array of sensors 208 and an automatic maneuvering system 206 . These subsystems may interface with a neural network onboard the autonomous vehicle to train the neural network to reach a target destination accurately and efficiently. Sensors 208 may include, for example, camera sensors, lidar sensors, radar sensors, location or GPS sensors, ultrasound sensors, and the like. Information gathered from the various sensors 208 may be processed by the onboard neural network and received by the automatic maneuvering system 206 . In this manner, the sensors 208 may inform and update the automatic maneuvering system 206 substantially continuously regarding a current state of the autonomous vehicle, including its location, orientation, and status. In addition, the sensors 208 may provide to a display compiler 210 information regarding a current state of the autonomous vehicle. Such information may be communicated to the display compiler 210 periodically or substantially continuously via the onboard network. The display compiler 210 may use this information, in combination with information from pre-determined maps 212 (such as those provided by GPS data) of the surrounding area, to make real-time calculations and produce graphical representations relevant to navigation of the autonomous vehicle. This compiled data may be communicated to a dashboard 214 for display to a user, as discussed in more detail below. In certain embodiments, a dashboard 214 or other user interface may be visible to a user to enable activation and control of the system 200 . In some embodiments, the dashboard 214 may be displayed on a remotely-located computer, mobile phone, smart device, or the like, and may maintain connectivity with the neural network by way of an appropriate wireless communication technology, such as a Wi-Fi connection, cellular data connection, the internet, or other communication technology known to those in the art. The dashboard 214 may enable a user to activate the system via an activation mechanism 202 . The dashboard 214 may also include a monitor 204 or other display device to enable a user to monitor the state of the autonomous vehicle and/or its surrounding environment. In certain embodiments, the activation mechanism 202 may include a physical button, a virtual button on a screen, a voice command, a mouse click, a finger touch, or the like. In some embodiments, the monitor 204 may provide a real-time initial location of the autonomous vehicle, and the activation mechanism 202 may operate in combination with the monitor 204 to enable the user to activate the automatic maneuvering system 206 by selecting a final destination on the monitor 204 . Referring now to FIG. 3 , embodiments of the present invention may incorporate an automatic maneuvering system 206 which is scalable, efficient, robust, and can account for a wide range of initial locations and/or orientations of the autonomous vehicle relative to its final or target destination. The automatic maneuvering system 206 may include a deep reinforcement learning framework, and may be implemented in a simulated environment where numerous trials and errors may be used to train the onboard neural network. In certain embodiments, the automatic maneuvering system 206 may train the onboard neural network to learn from mistakes using an exploration-exploitation tradeoff. To this end, embodiments of an automatic maneuvering system 206 in accordance with the invention may perform certain method 300 steps. For example, the automatic maneuvering system 206 may be activated 302 by a user via an activation mechanism 202 such as a physical button, a virtual button on a screen, a voice command, a mouse click, a finger touch on a screen, or the like. In some embodiments, the activation mechanism 202 may be visible and accessible to a user via a physical or virtual dashboard 214 of a remote device. In other embodiments, the activation mechanism 202 may be located onboard the autonomous vehicle. In certain embodiments, the activation mechanism 202 may allow a user to select a target destination for the autonomous vehicle, or the user may select the target destination via a monitor 204 or other mechanism or device known to those in the art. The automatic maneuvering system 206 may confirm 304 the selected destination as the final destination for the autonomous vehicle by determining location and/or directional coordinates corresponding to the selected destination. Location coordinates may be determined by referencing data gathered by onboard sensors 208 , including GPS sensors, and/or predetermined maps 212 . Directional coordinates may include, for example, a final heading angle or steering angle for the autonomous vehicle. In one embodiment, a final destination or target position may be expressed as (x, y, h) F , where x and y are locations on perpendicular lateral axes, and h is a final heading angle. In some embodiments, the automatic maneuvering system 206 may ascertain 306 drive boundaries within a surrounding area to facilitate navigating the autonomous vehicle from an initial location to a final target destination without interference from objects or obstacles in the vicinity. Drive boundaries may include, for example, stationary objects or obstacles such as road signs, trees, buildings, bodies of water, and the like. Drive boundaries may be determined by referencing sensor 208 data and/or pre-determined maps 212 . Upon determining a safe drive area based on the drive boundaries, the autonomous vehicle may be localized 308 using sensor 208 data and pre-determined maps 212 . Localizing 308 the autonomous vehicle may include determining an orientation of the vehicle, a location of the vehicle, a control status, a steering angle, and the like. This information, in addition to the final destination coordinates and drive boundaries, may be received 310 by the onboard neural network via onboard sensors 208 . In certain embodiments, the reinforcement learning control framework may include a deep Q-network that learns from mistakes using an exploration-exploitation tradeoff. As discussed in more detail below, the deep Q-network may utilize numerous trials and errors where it is rewarded for good actions and penalized for bad actions. In one embodiment, an epsilon-greedy strategy may be used for exploration versus exploitation decisions during the training of the neural networks. The information received 310 by the onboard neural network may be processed and utilized to navigate 312 the vehicle from its initial location to its final location. In some embodiments, based on this information, the neural network may determine appropriate incremental adjustments to a vehicle steering angle, acceleration, and/or brake to enable the autonomous vehicle to reach the final target destination. For example, in one embodiment, the system may be initially activated 302 at time t t . The onboard neural network may receive 310 sensor information for the autonomous vehicle that corresponds to t t , and the reinforcement learning control framework may be utilized to process such information. Based on that information, appropriate vehicle controls or settings may be determined and used to navigate 312 the autonomous vehicle to a new position at time t t+1 . Location and directional coordinates corresponding to the new position may be compared 314 with the final destination. If the new position coordinates match the final destination coordinates, the method 300 may end. If not, the method 300 may return to localize 308 the vehicle and iterate the process 300 until the autonomous vehicle reaches the final destination. Referring now to FIG. 4 , certain embodiments of the invention may provide a simulated environment 400 having perpendicular parking spaces 404 . As discussed above, in some embodiments, a deep Q-network may be used to train an autonomous vehicle 402 to automatically occupy an available perpendicular parking space 404 . The autonomous vehicle 402 may include an array of onboard sensors to gather data from the external environment. The array of sensors may include, for example, image camera sensors, depth camera sensors, infrared camera sensors, lidar sensors, radar sensors, ultrasound sensors, and the like. This data may be input into the automatic maneuvering system 206 and used in combination with predetermined map data to train the autonomous vehicle 402 to properly and efficiently maneuver into the perpendicular parking space 404 . In some embodiments, a user may activate the system and select a perpendicular parking space 404 as the target destination. Using data from the array of onboard sensors as well as predetermined map information, the automatic maneuvering system 206 may determine location and/or directional coordinates corresponding to the perpendicular parking space 404 . The automatic maneuvering system 206 may determine a safe driving area by identifying and locating drive boundaries in the surrounding area. As shown, for example, drive boundaries may include a curb 406 and other vehicles 408 parked in adjacent parking spaces. Onboard sensors may further gather information regarding a current state of the autonomous vehicle 402 , including its location and orientation. The automatic maneuvering system 206 may input this information into the reinforcement learning framework of the onboard neural network for processing. Based on this information, the reinforcement learning framework may output appropriate vehicle control indications or settings to the autonomous vehicle 402 , such as steering angle, acceleration, and brake. In one embodiment, for example, the reinforcement learning framework may determine that the autonomous vehicle 402 should adjust its steering angle by 15 degrees and decelerate by 2 mph within a one second period of time. These indications may be input into the vehicle control system, resulting in a vehicle action. Upon expiration of the one second period of time, a new position of the autonomous vehicle 402 may be determined. This process may be repeated until the new position of the autonomous vehicle 402 matches the coordinates for the perpendicular parking space 404 such that the autonomous vehicle 402 is properly positioned within the perpendicular parking space 404 . In embodiments utilizing a deep Q-network during the training phase, the reinforcement learning framework may include an actor network and a critic network. The first neural network, or actor network, may determine appropriate vehicle control indications or settings for implementation by the vehicle control system, while a second neural network, or critic network, may monitor actions taken by the autonomous vehicle 402 in accordance with those indications. The second neural network, or critic network, may analyze each action taken by the autonomous vehicle 402 to determine whether it was beneficial or detrimental to accurately and efficiently maneuvering the autonomous vehicle 402 into the perpendicular parking space 404 or other final target destination. If the action taken was desired, or beneficial, the second neural network may reward the first neural network by generating a certain signal. If the action taken was not desired, or detrimental, to effectively navigating the autonomous vehicle 402 to the target destination, the second neural network my penalize the first neural network via a temporal difference error signal. In this manner, the critic network trains the actor network to perform beneficial actions and to \\u201clearn\\u201d from its mistakes during the training phase. In certain embodiments, a replay buffer may store past vehicle states, actions taken at each state, and the corresponding rewards and penalties applied. For training, a small batch of data may be sampled from the replay buffer and used to train each neural network. When the replay buffer is full, the old data may be discarded and replaced by new data obtained from more recent performance episodes. Referring now to FIG. 5 , another embodiment of the invention may provide a simulated environment 500 having angled parking spaces 504 . In this embodiment, an actor-critic formulation such as A3C may be used. Specifically, multiple autonomous vehicles 502 , 506 may navigate to a corresponding angled parking space 504 , 508 substantially simultaneously. Their resulting performances may be cumulated by a central master actor and used to train their respective neural networks. As shown, for example, a first autonomous vehicle 502 may be located and oriented in a particular position relative to a first angled parking space 504 . A second autonomous vehicle 506 may be located and oriented in the same position relative to a second angled parking space 508 . In each case, the final target destination for each of the first and second autonomous vehicles 502 , 504 may be the first and second angled parking spaces 504 , 508 , respectively. An automatic maneuvering system 206 of each autonomous vehicle 502 , 506 may be activated by a user to automatically maneuver each of the autonomous vehicles 502 , 506 from their initial positions to their respective angled parking spaces 504 , 508 . Each automatic maneuvering system 206 may operate independently to explore the state-action space and thereby determine a good policy for navigation. As above, an array of onboard sensors associated with each vehicle 502 , 506 may gather information substantially continuously regarding the current state of its respective autonomous vehicle 502 , 506 . This information may be communicated to onboard neural networks associated with each autonomous vehicle 502 , 506 for processing. A designated network corresponding to one of the autonomous vehicles 502 for example, or central master actor, may update the neural networks of both autonomous vehicles 502 , 506 based on information received from each autonomous vehicle 502 , 506 upon exploring the same environment 500 . Resulting weights or scores after rewards and penalties have been applied by each neural network may be shared across the different autonomous vehicle 502 , 506 networks. Training multiple autonomous vehicles 502 , 506 in this manner may result in faster learning, since multiple autonomous vehicles 502 , 506 execute the same task in parallel across multiple threads of a network. Referring now to FIG. 6 , certain embodiments may incorporate a dual-framework system, where both a deep Q-network and an A3C actor-critic formulation may be used to train an autonomous vehicle 610 to reach a target destination in accordance with the invention. One embodiment of the invention may train an autonomous vehicle 610 to perform various tasks (i.e., parking, navigating accident or construction zones, or the like) utilizing both the deep Q-network framework and the A3C framework. The performance of each framework may then be analyzed to determine which framework performs better in which regions of the phase space. For example, in one embodiment, the deep Q-network framework may demonstrate better performance at the autonomous vehicle's initial location, while the A3C framework may demonstrate better performance at or near its final destination. This information may be stored in a look-up table that identifies various locations or regions where each of the frameworks is superior to the other in performance. The look-up table may be stored locally onboard the autonomous vehicle 610 . Alternatively, the look-up table may be stored remotely on a server or database, and communicated to the autonomous vehicle 610 via V2V communication, WiFi, the internet, or other communication method known to those in the art. In any case, activation of the automatic navigation system in accordance with embodiments of the invention may also trigger activation of the better-performing framework, depending on the state of the vehicle 610 and the task to be performed. As shown, one embodiment of a simulated environment 600 in accordance with the invention may include an autonomous vehicle 610 having an available parallel parking space 614 as its target destination. Embodiments of the invention may access a look-up table to determine that the deep Q-network is superior to the A3C framework at an initial vehicle 610 location, while the A3C framework is superior to the deep Q-network until the autonomous vehicle 610 nears the parallel parking space 614 . Accordingly, the deep Q-network may be automatically triggered in response to sensor data indicating that the autonomous vehicle 610 is situated in its initial position, while the A3C framework may be automatically triggered in response to changed sensor data indicating that the autonomous vehicle 610 has moved to a position nearer to the parallel parking space 614 . In another embodiment, an autonomous vehicle 610 may have a target destination 612 that requires the autonomous vehicle 610 to make a left-hand turn 606 through an intersection. A direct path from the initial location of the autonomous vehicle 610 to the target destination 612 may be obstructed, however, due to a collision 616 between a preceding vehicle 602 attempting to make the same left-hand turn, and a bus 604 traveling in the opposite direction. Training the autonomous vehicle 610 to avoid the collision 616 in transit to its target destination 612 in accordance with embodiments of the invention may also utilize a dual framework to determine in which regions of the phase space each performs better. In some embodiments, a score may be calculated for each region of the phase space, and may be associated with the corresponding framework. A discussed above, a score may be calculated according to the rewards and penalties received for corresponding actions. The framework with the highest score for a particular region of the phase space may be identified as the better performer for that region. This information may then recorded in a look-up table, as discussed above, and the appropriate framework may be triggered based on the region in which the autonomous vehicle 610 is located. Referring now to FIG. 7 , a process 700 for automatic vehicle navigation using deep reinforcement learning in accordance with embodiments of the invention may include detecting 702 a vehicle state. A vehicle state may include, for example, its location, orientation, steering angle, control status, and the like. The vehicle state may be determined by referencing sensor data, as well as referencing data from external sources such as predetermined maps of a surrounding area. The vehicle may then begin navigation 704 to a target destination. The target destination may be selected by a user, and location coordinates corresponding to the target destination may be input into the automatic maneuvering system. The automatic maneuvering system may process this information to enable the vehicle to take successive actions to reach the target destination. For each action taken, the process 700 may query 706 whether the action was desirable. If yes, the system may generate a signal to reward 708 the network for the action. If not, the system may generate a signal to penalize 710 the network for the action. In either case, the reward or penalty received may be associated with the action taken and stored 12 in a replay buffer. Data from the replay buffer may be sampled and used to train networks. In certain embodiments, the data may also be communicated 714 to a central master actor, such as a network or processor associated with a designated autonomous vehicle. The central master actor may process the information and cumulate it with information obtained from networks associated with other autonomous vehicles performing the same task under the same circumstances. The cumulated information may then be disseminated 716 back to the networks associated with those autonomous vehicles to facilitate faster learning. In the above disclosure, reference has been made to the accompanying drawings, which form a part hereof, and in which is shown by way of illustration specific implementations in which the disclosure may be practiced. It is understood that other implementations may be utilized and structural changes may be made without departing from the scope of the present disclosure. References in the specification to \\u201cone embodiment,\\u201d \\u201can embodiment,\\u201d \\u201can example embodiment,\\u201d etc., indicate that the embodiment described may include a particular feature, structure, or characteristic, but every embodiment may not necessarily include the particular feature, structure, or characteristic. Moreover, such phrases are not necessarily referring to the same embodiment. Further, when a particular feature, structure, or characteristic is described in connection with an embodiment, it is submitted that it is within the knowledge of one skilled in the art to affect such feature, structure, or characteristic in connection with other embodiments whether or not explicitly described. Implementations of the systems, devices, and methods disclosed herein may comprise or utilize a special purpose or general-purpose computer including computer hardware, such as, for example, one or more processors and system memory, as discussed herein. Implementations within the scope of the present disclosure may also include physical and other computer-readable media for carrying or storing computer-executable instructions and/or data structures. Such computer-readable media can be any available media that can be accessed by a general purpose or special purpose computer system. Computer-readable media that store computer-executable instructions are computer storage media (devices). Computer-readable media that carry computer-executable instructions are transmission media. Thus, by way of example, and not limitation, implementations of the disclosure can comprise at least two distinctly different kinds of computer-readable media: computer storage media (devices) and transmission media. Computer storage media (devices) includes RAM, ROM, EEPROM, CD-ROM, solid state drives (\\u201cSSDs\\u201d) (e.g., based on RAM), Flash memory, phase-change memory (\\u201cPCM\\u201d), other types of memory, other optical disk storage, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store desired program code means in the form of computer-executable instructions or data structures and which can be accessed by a general purpose or special purpose computer. An implementation of the devices, systems, and methods disclosed herein may communicate over a computer network. A \\u201cnetwork\\u201d is defined as one or more data links that enable the transport of electronic data between computer systems and/or modules and/or other electronic devices. When information is transferred or provided over a network or another communications connection (either hardwired, wireless, or a combination of hardwired or wireless) to a computer, the computer properly views the connection as a transmission medium. Transmissions media can include a network and/or data links, which can be used to carry desired program code means in the form of computer-executable instructions or data structures and which can be accessed by a general purpose or special purpose computer. Combinations of the above should also be included within the scope of computer-readable media. Computer-executable instructions comprise, for example, instructions and data which, when executed at a processor, cause a general purpose computer, special purpose computer, or special purpose processing device to perform a certain function or group of functions. The computer executable instructions may be, for example, binaries, intermediate format instructions such as assembly language, or even source code. Although the subject matter has been described in language specific to structural features and/or methodological acts, it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the described features or acts described above. Rather, the described features and acts are disclosed as example forms of implementing the claims. Those skilled in the art will appreciate that the disclosure may be practiced in network computing environments with many types of computer system configurations, including, an in-dash vehicle computer, personal computers, desktop computers, laptop computers, message processors, hand-held devices, multi-processor systems, microprocessor-based or programmable consumer electronics, network PCs, minicomputers, mainframe computers, mobile telephones, PDAs, tablets, pagers, routers, switches, various storage devices, and the like. The disclosure may also be practiced in distributed system environments where local and remote computer systems, which are linked (either by hardwired data links, wireless data links, or by a combination of hardwired and wireless data links) through a network, both perform tasks. In a distributed system environment, program modules may be located in both local and remote memory storage devices. Further, where appropriate, functions described herein can be performed in one or more of: hardware, software, firmware, digital components, or analog components. For example, one or more application specific integrated circuits (ASICs) can be programmed to carry out one or more of the systems and procedures described herein. Certain terms are used throughout the description and claims to refer to particular system components. As one skilled in the art will appreciate, components may be referred to by different names. This document does not intend to distinguish between components that differ in name, but not function. It should be noted that the sensor embodiments discussed above may comprise computer hardware, software, firmware, or any combination thereof to perform at least a portion of their functions. For example, a sensor may include computer code configured to be executed in one or more processors, and may include hardware logic/electrical circuitry controlled by the computer code. These example devices are provided herein purposes of illustration, and are not intended to be limiting. Embodiments of the present disclosure may be implemented in further types of devices, as would be known to persons skilled in the relevant art(s). At least some embodiments of the disclosure have been directed to computer program products comprising such logic (e.g., in the form of software) stored on any computer useable medium. Such software, when executed in one or more data processing devices, causes a device to operate as described herein. While various embodiments of the present disclosure have been described above, it should be understood that they have been presented by way of example only, and not limitation. It will be apparent to persons skilled in the relevant art that various changes in form and detail can be made therein without departing from the spirit and scope of the disclosure. Thus, the breadth and scope of the present disclosure should not be limited by any of the above-described exemplary embodiments, but should be defined only in accordance with the following claims and their equivalents. The foregoing description has been presented for the purposes of illustration and description. It is not intended to be exhaustive or to limit the disclosure to the precise form disclosed. Many modifications and variations are possible in light of the above teaching. Further, it should be noted that any or all of the aforementioned alternate implementations may be used in any combination desired to form additional hybrid implementations of the disclosure.\",\n",
      "    \"lang\": \"en\"\n",
      "  },\n",
      "  \"publication_type\": \"GRANTED_PATENT\"\n",
      "}\n",
      "----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "API_TOKEN = \"QKooD88tnEbnJNTnQVnyHOia3y8aBhHPw18hOq9R9NC2Eo2yW9kx\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "lens_id = \"049-288-157-543-024\"\n",
    "\n",
    "url = \"https://api.lens.org/patent/search\"\n",
    "query_body = {\n",
    "    \"query\": {\n",
    "        \"terms\": {\n",
    "            \"lens_id\": [lens_id]\n",
    "        }\n",
    "    },\n",
    "    \"size\": 1\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(query_body))\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    if data and \"data\" in data and len(data[\"data\"]) > 0:\n",
    "        first_patent = data[\"data\"][0]\n",
    "\n",
    "        print(\"\\n--- Full Patent Object Structure (for debugging) ---\")\n",
    "        print(json.dumps(first_patent, indent=2))\n",
    "\n",
    "    else:\n",
    "        print(\"No patent found for the given Lens ID or data structure unexpected.\")\n",
    "else:\n",
    "    print(f\"Failed: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5ce8d02-16d3-4415-bdb4-c865d1e53717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Patent JSON Key Structure Tree ---\n",
      "ROOT\n",
      "  └── lens_id\n",
      "  └── jurisdiction\n",
      "  └── doc_number\n",
      "  └── kind\n",
      "  └── date_published\n",
      "  └── doc_key\n",
      "  └── docdb_id\n",
      "  └── lang\n",
      "  └── biblio\n",
      "    └── publication_reference\n",
      "      └── jurisdiction\n",
      "      └── doc_number\n",
      "      └── kind\n",
      "      └── date\n",
      "    └── application_reference\n",
      "      └── jurisdiction\n",
      "      └── doc_number\n",
      "      └── kind\n",
      "      └── date\n",
      "    └── priority_claims\n",
      "      └── claims []\n",
      "        └── (item structure shown below)\n",
      "        └── [0]\n",
      "          └── jurisdiction\n",
      "          └── doc_number\n",
      "          └── kind\n",
      "          └── date\n",
      "          └── sequence\n",
      "      └── earliest_claim\n",
      "        └── date\n",
      "    └── invention_title []\n",
      "      └── (item structure shown below)\n",
      "      └── [0]\n",
      "        └── text\n",
      "        └── lang\n",
      "    └── parties\n",
      "      └── examiners\n",
      "        └── primary_examiner\n",
      "          └── department\n",
      "          └── extracted_name\n",
      "            └── value\n",
      "        └── assistant_examiner\n",
      "          └── extracted_name\n",
      "            └── value\n",
      "      └── applicants []\n",
      "        └── (item structure shown below)\n",
      "        └── [0]\n",
      "          └── residence\n",
      "          └── extracted_name\n",
      "            └── value\n",
      "      └── inventors []\n",
      "        └── (item structure shown below)\n",
      "        └── [0]\n",
      "          └── residence\n",
      "          └── sequence\n",
      "          └── extracted_name\n",
      "            └── value\n",
      "      └── agents []\n",
      "        └── (item structure shown below)\n",
      "        └── [0]\n",
      "          └── extracted_name\n",
      "            └── value\n",
      "      └── owners_all []\n",
      "        └── (item structure shown below)\n",
      "        └── [0]\n",
      "          └── recorded_date\n",
      "          └── execution_date\n",
      "          └── extracted_name\n",
      "            └── value\n",
      "          └── extracted_address\n",
      "    └── classifications_ipcr\n",
      "      └── classifications []\n",
      "        └── (item structure shown below)\n",
      "        └── [0]\n",
      "          └── symbol\n",
      "          └── classification_value\n",
      "          └── classification_symbol_position\n",
      "    └── classifications_cpc\n",
      "      └── classifications []\n",
      "        └── (item structure shown below)\n",
      "        └── [0]\n",
      "          └── symbol\n",
      "          └── classification_value\n",
      "          └── classification_symbol_position\n",
      "    └── references_cited\n",
      "      └── citations []\n",
      "        └── (item structure shown below)\n",
      "        └── [0]\n",
      "          └── sequence\n",
      "          └── patcit\n",
      "            └── document_id\n",
      "              └── jurisdiction\n",
      "              └── doc_number\n",
      "              └── kind\n",
      "              └── date\n",
      "            └── lens_id\n",
      "          └── cited_phase\n",
      "      └── patent_count\n",
      "      └── npl_count\n",
      "    └── cited_by\n",
      "  └── families\n",
      "    └── simple_family\n",
      "      └── members []\n",
      "        └── (item structure shown below)\n",
      "        └── [0]\n",
      "          └── document_id\n",
      "            └── jurisdiction\n",
      "            └── doc_number\n",
      "            └── kind\n",
      "            └── date\n",
      "          └── lens_id\n",
      "      └── size\n",
      "    └── extended_family\n",
      "      └── members []\n",
      "        └── (item structure shown below)\n",
      "        └── [0]\n",
      "          └── document_id\n",
      "            └── jurisdiction\n",
      "            └── doc_number\n",
      "            └── kind\n",
      "            └── date\n",
      "          └── lens_id\n",
      "      └── size\n",
      "  └── legal_status\n",
      "    └── granted\n",
      "    └── grant_date\n",
      "    └── anticipated_term_date\n",
      "    └── calculation_log []\n",
      "      └── (list of primitive types)\n",
      "    └── patent_status\n",
      "  └── abstract []\n",
      "    └── (item structure shown below)\n",
      "    └── [0]\n",
      "      └── text\n",
      "      └── lang\n",
      "  └── claims []\n",
      "    └── (item structure shown below)\n",
      "    └── [0]\n",
      "      └── claims []\n",
      "        └── (item structure shown below)\n",
      "        └── [0]\n",
      "          └── claim_text []\n",
      "            └── (list of primitive types)\n",
      "      └── lang\n",
      "  └── description\n",
      "    └── text\n",
      "    └── lang\n",
      "  └── publication_type\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "API_TOKEN = \"QKooD88tnEbnJNTnQVnyHOia3y8aBhHPw18hOq9R9NC2Eo2yW9kx\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "lens_id = \"049-288-157-543-024\" # Example Lens ID\n",
    "\n",
    "url = \"https://api.lens.org/patent/search\"\n",
    "query_body = {\n",
    "    \"query\": {\n",
    "        \"terms\": {\n",
    "            \"lens_id\": [lens_id]\n",
    "        }\n",
    "    },\n",
    "    \"size\": 1\n",
    "}\n",
    "\n",
    "def print_json_key_tree(obj, indent=0, key_name=None):\n",
    "    \"\"\"\n",
    "    Recursively prints only the key names of a JSON object in a tree format.\n",
    "    \"\"\"\n",
    "    prefix = \"  \" * indent\n",
    "    node_indicator = \"\"\n",
    "\n",
    "    if key_name:\n",
    "        node_indicator = f\"└── {key_name}\"\n",
    "\n",
    "    if isinstance(obj, dict):\n",
    "        if key_name:\n",
    "            print(f\"{prefix}{node_indicator}\")\n",
    "        else: # For the root object\n",
    "            print(f\"{prefix}ROOT\")\n",
    "\n",
    "        keys = list(obj.keys())\n",
    "        for key in keys:\n",
    "            print_json_key_tree(obj[key], indent + 1, key)\n",
    "\n",
    "    elif isinstance(obj, list):\n",
    "        if key_name:\n",
    "            print(f\"{prefix}{node_indicator} []\") # Indicate it's a list\n",
    "        else: # For the root list\n",
    "            print(f\"{prefix}ROOT []\")\n",
    "\n",
    "        if obj and isinstance(obj[0], (dict, list)):\n",
    "            # If list contains complex objects, show structure of first item\n",
    "            print(f\"{prefix}  └── (item structure shown below)\")\n",
    "            print_json_key_tree(obj[0], indent + 1, \"[0]\")\n",
    "        else:\n",
    "            # If list contains primitive types, just indicate that\n",
    "            print(f\"{prefix}  └── (list of primitive types)\")\n",
    "\n",
    "    else:\n",
    "        # Leaf node (string, number, boolean, null) - just print its key name\n",
    "        if key_name:\n",
    "            print(f\"{prefix}{node_indicator}\")\n",
    "\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(query_body))\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    if data and \"data\" in data and len(data[\"data\"]) > 0:\n",
    "        first_patent = data[\"data\"][0]\n",
    "\n",
    "        print(\"\\n--- Patent JSON Key Structure Tree ---\")\n",
    "        # The API response itself contains \"data\" as a list, then the patent object.\n",
    "        # Let's start the tree from the actual patent object itself for clarity.\n",
    "        # Or, if you want to see the 'data' -> [0] -> patent structure:\n",
    "        # print_json_key_tree(data)\n",
    "        \n",
    "        # To show the structure *of the patent document itself*:\n",
    "        print_json_key_tree(first_patent)\n",
    "\n",
    "    else:\n",
    "        print(\"No patent found for the given Lens ID or data structure unexpected.\")\n",
    "else:\n",
    "    print(f\"Failed: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dca5f485-6551-4430-b271-8a7cb0fce197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top-Level Keys of the Patent Object ---\n",
      "- lens_id\n",
      "- jurisdiction\n",
      "- doc_number\n",
      "- kind\n",
      "- date_published\n",
      "- doc_key\n",
      "- docdb_id\n",
      "- lang\n",
      "- biblio\n",
      "- families\n",
      "- legal_status\n",
      "- abstract\n",
      "- claims\n",
      "- description\n",
      "- publication_type\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "API_TOKEN = \"QKooD88tnEbnJNTnQVnyHOia3y8aBhHPw18hOq9R9NC2Eo2yW9kx\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "lens_id = \"049-288-157-543-024\" # Example Lens ID\n",
    "\n",
    "url = \"https://api.lens.org/patent/search\"\n",
    "query_body = {\n",
    "    \"query\": {\n",
    "        \"terms\": {\n",
    "            \"lens_id\": [lens_id]\n",
    "        }\n",
    "    },\n",
    "    \"size\": 1\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(query_body))\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    if data and \"data\" in data and len(data[\"data\"]) > 0:\n",
    "        first_patent = data[\"data\"][0]\n",
    "\n",
    "        print(\"\\n--- Top-Level Keys of the Patent Object ---\")\n",
    "        for key in first_patent.keys():\n",
    "            print(f\"- {key}\")\n",
    "\n",
    "    else:\n",
    "        print(\"No patent found for the given Lens ID or data structure unexpected.\")\n",
    "else:\n",
    "    print(f\"Failed: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "093e59ff-c258-4a06-a384-c70a10ef0876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top-Level Keys within 'biblio' ---\n",
      "- publication_reference\n",
      "- application_reference\n",
      "- priority_claims\n",
      "- invention_title\n",
      "- parties\n",
      "- classifications_ipcr\n",
      "- classifications_cpc\n",
      "- references_cited\n",
      "- cited_by\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "API_TOKEN = \"QKooD88tnEbnJNTnQVnyHOia3y8aBhHPw18hOq9R9NC2Eo2yW9kx\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "lens_id = \"049-288-157-543-024\" # Example Lens ID\n",
    "\n",
    "url = \"https://api.lens.org/patent/search\"\n",
    "query_body = {\n",
    "    \"query\": {\n",
    "        \"terms\": {\n",
    "            \"lens_id\": [lens_id]\n",
    "        }\n",
    "    },\n",
    "    \"size\": 1\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(query_body))\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    if data and \"data\" in data and len(data[\"data\"]) > 0:\n",
    "        first_patent = data[\"data\"][0]\n",
    "\n",
    "        # Safely get the 'biblio' dictionary\n",
    "        biblio = first_patent.get(\"biblio\", {})\n",
    "\n",
    "        if biblio:\n",
    "            print(\"\\n--- Top-Level Keys within 'biblio' ---\")\n",
    "            for key in biblio.keys():\n",
    "                print(f\"- {key}\")\n",
    "        else:\n",
    "            print(\"\\n'biblio' section not found or is empty for this patent.\")\n",
    "\n",
    "    else:\n",
    "        print(\"No patent found for the given Lens ID or data structure unexpected.\")\n",
    "else:\n",
    "    print(f\"Failed: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a41f249a-434f-4d88-8a70-bf00f5177f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top-Level Keys within 'biblio.application_reference' ---\n",
      "- jurisdiction\n",
      "- doc_number\n",
      "- kind\n",
      "- date\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "API_TOKEN = \"QKooD88tnEbnJNTnQVnyHOia3y8aBhHPw18hOq9R9NC2Eo2yW9kx\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "lens_id = \"049-288-157-543-024\" # Example Lens ID\n",
    "\n",
    "url = \"https://api.lens.org/patent/search\"\n",
    "query_body = {\n",
    "    \"query\": {\n",
    "        \"terms\": {\n",
    "            \"lens_id\": [lens_id]\n",
    "        }\n",
    "    },\n",
    "    \"size\": 1\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(query_body))\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    if data and \"data\" in data and len(data[\"data\"]) > 0:\n",
    "        first_patent = data[\"data\"][0]\n",
    "\n",
    "        # Safely get the 'biblio' dictionary\n",
    "        biblio = first_patent.get(\"biblio\", {})\n",
    "\n",
    "        if biblio:\n",
    "            # Safely get the 'publication_reference' from within 'biblio'\n",
    "            publication_reference = biblio.get(\"application_reference\", {})\n",
    "\n",
    "            if publication_reference:\n",
    "                print(\"\\n--- Top-Level Keys within 'biblio.application_reference' ---\")\n",
    "                for key in publication_reference.keys():\n",
    "                    print(f\"- {key}\")\n",
    "            else:\n",
    "                print(\"\\n'application_reference' section not found or is empty within 'biblio' for this patent.\")\n",
    "        else:\n",
    "            print(\"\\n'biblio' section not found or is empty for this patent.\")\n",
    "\n",
    "    else:\n",
    "        print(\"No patent found for the given Lens ID or data structure unexpected.\")\n",
    "else:\n",
    "    print(f\"Failed: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ffd80f6-d529-447f-b57b-74711828f91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top-Level Keys within 'biblio.parties' ---\n",
      "- examiners\n",
      "- applicants\n",
      "- inventors\n",
      "- agents\n",
      "- owners_all\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "API_TOKEN = \"QKooD88tnEbnJNTnQVnyHOia3y8aBhHPw18hOq9R9NC2Eo2yW9kx\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "lens_id = \"049-288-157-543-024\" # Example Lens ID\n",
    "\n",
    "url = \"https://api.lens.org/patent/search\"\n",
    "query_body = {\n",
    "    \"query\": {\n",
    "        \"terms\": {\n",
    "            \"lens_id\": [lens_id]\n",
    "        }\n",
    "    },\n",
    "    \"size\": 1\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(query_body))\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    if data and \"data\" in data and len(data[\"data\"]) > 0:\n",
    "        first_patent = data[\"data\"][0]\n",
    "\n",
    "        # Safely get the 'biblio' dictionary\n",
    "        biblio = first_patent.get(\"biblio\", {})\n",
    "\n",
    "        if biblio:\n",
    "            # Safely get the 'parties' dictionary within 'biblio'\n",
    "            parties = biblio.get(\"parties\", {})\n",
    "\n",
    "            if parties:\n",
    "                print(\"\\n--- Top-Level Keys within 'biblio.parties' ---\")\n",
    "                for key in parties.keys():\n",
    "                    print(f\"- {key}\")\n",
    "            else:\n",
    "                print(\"\\n'parties' section not found or is empty within 'biblio' for this patent.\")\n",
    "        else:\n",
    "            print(\"\\n'biblio' section not found or is empty for this patent.\")\n",
    "\n",
    "    else:\n",
    "        print(\"No patent found for the given Lens ID or data structure unexpected.\")\n",
    "else:\n",
    "    print(f\"Failed: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21647e30-d16c-47be-b628-06e402927240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patent Title: Automatic navigation using deep reinforcement learning\n",
      "Patent Abstract: A method for training an autonomous vehicle to reach a target location. The method includes detecting the state of an autonomous vehicle in a simulated environment, and using a neural network to navigate the vehicle from an initial location to a target destination. During the training phase, a second neural network may reward the first neural network for a desired action taken by the autonomous vehicle, and may penalize the first neural network for an undesired action taken by the autonomous vehicle. A corresponding system and computer program product are also disclosed and claimed herein.\n",
      "\n",
      "Full Text Claims (truncated for display):\n",
      "1. A method comprising: identifying a state of an autonomous vehicle within a simulated environment, wherein the simulated environment comprises a plurality of operating parameters for training a reinforcement learning framework to calculate driving maneuvers for the autonomous vehicle; calculating, with an actor neural network, a driving maneuver for navigating the autonomous vehicle from an initial location to a target destination; determining, with a critic neural network, whether the driving...\n",
      "\n",
      "Full Text Description (truncated for display):\n",
      "BACKGROUND Field of the Invention This invention relates to navigation for vehicles. Background of the Invention Parking a vehicle, especially parallel parking, is a skill that requires much practice and trial-and-error experience. Even experienced drivers tend to avoid this task since proper maneuvering depends not only on the skill of the driver, but also on largely unpredictable environmental factors, such as the slope and area of the available parking spot and the orientation and movement of...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "API_TOKEN = \"QKooD88tnEbnJNTnQVnyHOia3y8aBhHPw18hOq9R9NC2Eo2yW9kx\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "lens_id = \"049-288-157-543-024\"\n",
    "url = \"https://api.lens.org/patent/search\"\n",
    "query_body = {\n",
    "    \"query\": {\n",
    "        \"terms\": {\n",
    "            \"lens_id\": [lens_id]\n",
    "        }\n",
    "    },\n",
    "    \"size\": 1\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(query_body))\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    if data and \"data\" in data and len(data[\"data\"]) > 0:\n",
    "        first_patent = data[\"data\"][0]\n",
    "\n",
    "        # --- Title ---\n",
    "        biblio = first_patent.get(\"biblio\", {})\n",
    "        invention_title_list = biblio.get(\"invention_title\", [])\n",
    "        title_text = invention_title_list[0].get(\"text\", \"N/A\") if invention_title_list else \"N/A\"\n",
    "\n",
    "        # --- Abstract ---\n",
    "        abstract_list = first_patent.get(\"abstract\", [])\n",
    "        abstract_text = abstract_list[0].get(\"text\", \"N/A\") if abstract_list else \"N/A\"\n",
    "\n",
    "        # --- Claims (updated parsing) ---\n",
    "        claims_outer = first_patent.get(\"claims\", [])\n",
    "        claims_texts = []\n",
    "\n",
    "        if claims_outer and isinstance(claims_outer, list):\n",
    "            inner_claims_list = claims_outer[0].get(\"claims\", [])\n",
    "            for claim in inner_claims_list:\n",
    "                claim_text_list = claim.get(\"claim_text\", [])\n",
    "                claims_texts.extend(claim_text_list)\n",
    "\n",
    "        claims_combined = \"\\n\".join(claims_texts) if claims_texts else \"N/A\"\n",
    "\n",
    "        # --- Description ---\n",
    "        description_obj = first_patent.get(\"description\", {})\n",
    "        description_text = description_obj.get(\"text\", \"N/A\")\n",
    "\n",
    "        # --- Print ---\n",
    "        print(\"Patent Title:\", title_text)\n",
    "        print(\"Patent Abstract:\", abstract_text)\n",
    "\n",
    "        print(\"\\nFull Text Claims (truncated for display):\")\n",
    "        print(claims_combined[:500] + \"...\" if len(claims_combined) > 500 else claims_combined)\n",
    "\n",
    "        print(\"\\nFull Text Description (truncated for display):\")\n",
    "        print(description_text[:500] + \"...\" if len(description_text) > 500 else description_text)\n",
    "\n",
    "    else:\n",
    "        print(\"No patent found for the given Lens ID or data structure unexpected.\")\n",
    "else:\n",
    "    print(f\"Failed: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "870bb7aa-09ff-48dc-98a1-67540a93b900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking attribute presence for the first 10 patents from 'lens-export.csv' ---\n",
      "[1/10] Lens ID: 143-105-704-034-927 - PASS - All required attributes are present.\n",
      "[2/10] Lens ID: 049-288-157-543-024 - PASS - All required attributes are present.\n",
      "[3/10] Lens ID: 038-549-955-608-076 - PASS - All required attributes are present.\n",
      "[4/10] Lens ID: 060-633-857-515-414 - PASS - All required attributes are present.\n",
      "[5/10] Lens ID: 198-026-218-217-031 - PASS - All required attributes are present.\n",
      "[6/10] Lens ID: 075-769-703-927-237 - PASS - All required attributes are present.\n",
      "[7/10] Lens ID: 095-518-093-968-654 - PASS - All required attributes are present.\n",
      "[8/10] Lens ID: 113-036-063-984-644 - PASS - All required attributes are present.\n",
      "[9/10] Lens ID: 012-259-548-123-929 - PASS - All required attributes are present.\n",
      "[10/10] Lens ID: 060-517-777-247-722 - PASS - All required attributes are present.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd # Import pandas\n",
    "\n",
    "API_TOKEN = \"QKooD88tnEbnJNTnQVnyHOia3y8aBhHPw18hOq9R9NC2Eo2yW9kx\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# --- Function to check patent attributes ---\n",
    "def check_patent_attributes(lens_id, api_url, headers):\n",
    "    \"\"\"\n",
    "    Checks for the presence of specified high-level attributes for a given Lens ID.\n",
    "    \"\"\"\n",
    "    query_body = {\n",
    "        \"query\": {\n",
    "            \"terms\": {\n",
    "                \"lens_id\": [lens_id]\n",
    "            }\n",
    "        },\n",
    "        \"size\": 1\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(api_url, headers=headers, data=json.dumps(query_body))\n",
    "        response.raise_for_status() # Raises an HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "        data = response.json()\n",
    "        if not data or \"data\" not in data or len(data[\"data\"]) == 0:\n",
    "            return False, \"No patent found or data structure unexpected from API response.\"\n",
    "\n",
    "        first_patent = data[\"data\"][0]\n",
    "\n",
    "        # Attributes to check for presence (based on our agreed list)\n",
    "        required_attributes = [\n",
    "            \"lens_id\", \"jurisdiction\", \"date_published\", \"biblio\",\n",
    "            \"legal_status\", \"abstract\", \"claims\", \"description\", \"families\"\n",
    "        ]\n",
    "\n",
    "        missing_attributes = []\n",
    "        for attr in required_attributes:\n",
    "            if attr not in first_patent:\n",
    "                missing_attributes.append(attr)\n",
    "            # For nested objects like biblio, abstract, claims, description, families\n",
    "            # we also check if their values are not None/empty after existence\n",
    "            elif first_patent.get(attr) is None:\n",
    "                 missing_attributes.append(f\"{attr} (value is None)\")\n",
    "            elif isinstance(first_patent.get(attr), (list, dict)) and not first_patent.get(attr):\n",
    "                # If it's an empty list or empty dictionary, consider it effectively missing for content\n",
    "                missing_attributes.append(f\"{attr} (value is empty)\")\n",
    "\n",
    "\n",
    "        if missing_attributes:\n",
    "            return False, f\"Missing or empty attributes: {', '.join(missing_attributes)}\"\n",
    "        else:\n",
    "            return True, \"All required attributes are present.\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return False, f\"API Request Failed: {e}\"\n",
    "    except json.JSONDecodeError:\n",
    "        return False, \"Failed to decode JSON response.\"\n",
    "    except Exception as e:\n",
    "        return False, f\"An unexpected error occurred: {e}\"\n",
    "\n",
    "# --- Main script execution ---\n",
    "csv_file_path = 'lens-export.csv' # Make sure this file is in the same directory\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    if 'Lens ID' not in df.columns:\n",
    "        print(f\"Error: '{csv_file_path}' does not contain a 'Lens ID' column.\")\n",
    "    else:\n",
    "        lens_ids_to_check = df['Lens ID'].head(10).tolist() # Get the first 10 Lens IDs\n",
    "\n",
    "        print(f\"\\n--- Checking attribute presence for the first {len(lens_ids_to_check)} patents from '{csv_file_path}' ---\")\n",
    "        for i, lid in enumerate(lens_ids_to_check):\n",
    "            is_present, message = check_patent_attributes(str(lid), url, headers) # Ensure ID is string\n",
    "            status = \"PASS\" if is_present else \"FAIL\"\n",
    "            print(f\"[{i+1}/{len(lens_ids_to_check)}] Lens ID: {lid} - {status} - {message}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{csv_file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while reading the CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0472681-8e80-4cd7-a49c-e32ea7f0f547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking attribute presence for the first 10 patents from 'lens-export.csv' ---\n",
      "[1/10] Lens ID: 143-105-704-034-927 - PASS - All required attributes (high-level and nested) are present.\n",
      "[2/10] Lens ID: 049-288-157-543-024 - PASS - All required attributes (high-level and nested) are present.\n",
      "[3/10] Lens ID: 038-549-955-608-076 - PASS - All required attributes (high-level and nested) are present.\n",
      "[4/10] Lens ID: 060-633-857-515-414 - PASS - All required attributes (high-level and nested) are present.\n",
      "[5/10] Lens ID: 198-026-218-217-031 - PASS - All required attributes (high-level and nested) are present.\n",
      "[6/10] Lens ID: 075-769-703-927-237 - PASS - All required attributes (high-level and nested) are present.\n",
      "[7/10] Lens ID: 095-518-093-968-654 - PASS - All required attributes (high-level and nested) are present.\n",
      "[8/10] Lens ID: 113-036-063-984-644 - PASS - All required attributes (high-level and nested) are present.\n",
      "[9/10] Lens ID: 012-259-548-123-929 - PASS - All required attributes (high-level and nested) are present.\n",
      "[10/10] Lens ID: 060-517-777-247-722 - PASS - All required attributes (high-level and nested) are present.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd # Import pandas\n",
    "\n",
    "API_TOKEN = \"QKooD88tnEbnJNTnQVnyHOia3y8aBhHPw18hOq9R9NC2Eo2yW9kx\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# --- Function to check patent attributes ---\n",
    "def check_patent_attributes(lens_id, api_url, headers):\n",
    "    \"\"\"\n",
    "    Checks for the presence of specified high-level and nested attributes for a given Lens ID.\n",
    "    \"\"\"\n",
    "    query_body = {\n",
    "        \"query\": {\n",
    "            \"terms\": {\n",
    "                \"lens_id\": [lens_id]\n",
    "            }\n",
    "        },\n",
    "        \"size\": 1\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(api_url, headers=headers, data=json.dumps(query_body))\n",
    "        response.raise_for_status() # Raises an HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "        data = response.json()\n",
    "        if not data or \"data\" not in data or len(data[\"data\"]) == 0:\n",
    "            return False, \"No patent found or data structure unexpected from API response.\"\n",
    "\n",
    "        first_patent = data[\"data\"][0]\n",
    "\n",
    "        # 1. High-level attributes check\n",
    "        required_high_level_attributes = [\n",
    "            \"lens_id\", \"jurisdiction\", \"date_published\", \"biblio\",\n",
    "            \"legal_status\", \"abstract\", \"claims\", \"description\", \"families\"\n",
    "        ]\n",
    "\n",
    "        missing_attributes = []\n",
    "        for attr in required_high_level_attributes:\n",
    "            if attr not in first_patent:\n",
    "                missing_attributes.append(attr)\n",
    "            elif first_patent.get(attr) is None:\n",
    "                 missing_attributes.append(f\"{attr} (value is None)\")\n",
    "            elif isinstance(first_patent.get(attr), (list, dict)) and not first_patent.get(attr):\n",
    "                missing_attributes.append(f\"{attr} (value is empty)\")\n",
    "\n",
    "        if missing_attributes:\n",
    "            return False, f\"Missing or empty high-level attributes: {', '.join(missing_attributes)}\"\n",
    "\n",
    "        # If high-level biblio is missing, we can't do nested checks\n",
    "        biblio = first_patent.get(\"biblio\", {})\n",
    "        if not biblio:\n",
    "            return False, \"'biblio' high-level attribute is missing or empty, cannot check nested fields.\"\n",
    "\n",
    "        # 2. Nested attributes within 'biblio' check\n",
    "        required_biblio_attributes = [\n",
    "            \"invention_title\", \"parties\", \"classifications_cpc\", \"priority_claims\"\n",
    "        ]\n",
    "        \n",
    "        for attr in required_biblio_attributes:\n",
    "            if attr not in biblio:\n",
    "                missing_attributes.append(f\"biblio.{attr}\")\n",
    "            elif biblio.get(attr) is None:\n",
    "                 missing_attributes.append(f\"biblio.{attr} (value is None)\")\n",
    "            elif isinstance(biblio.get(attr), (list, dict)) and not biblio.get(attr):\n",
    "                missing_attributes.append(f\"biblio.{attr} (value is empty)\")\n",
    "\n",
    "        if missing_attributes:\n",
    "            return False, f\"Missing or empty nested attributes in 'biblio': {', '.join(missing_attributes)}\"\n",
    "            \n",
    "        # If biblio.parties is missing, we can't do nested checks within it\n",
    "        parties = biblio.get(\"parties\", {})\n",
    "        if not parties:\n",
    "            return False, \"biblio.parties is missing or empty, cannot check nested fields.\"\n",
    "\n",
    "        # 3. Nested attribute within 'biblio.parties' check\n",
    "        required_parties_attributes = [\"applicants\"]\n",
    "\n",
    "        for attr in required_parties_attributes:\n",
    "            if attr not in parties:\n",
    "                missing_attributes.append(f\"biblio.parties.{attr}\")\n",
    "            elif parties.get(attr) is None:\n",
    "                 missing_attributes.append(f\"biblio.parties.{attr} (value is None)\")\n",
    "            elif isinstance(parties.get(attr), (list, dict)) and not parties.get(attr):\n",
    "                missing_attributes.append(f\"biblio.parties.{attr} (value is empty)\")\n",
    "\n",
    "        if missing_attributes:\n",
    "            return False, f\"Missing or empty nested attributes in 'biblio.parties': {', '.join(missing_attributes)}\"\n",
    "        else:\n",
    "            return True, \"All required attributes (high-level and nested) are present.\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return False, f\"API Request Failed: {e}\"\n",
    "    except json.JSONDecodeError:\n",
    "        return False, \"Failed to decode JSON response.\"\n",
    "    except Exception as e:\n",
    "        return False, f\"An unexpected error occurred: {e}\"\n",
    "\n",
    "# --- Main script execution ---\n",
    "csv_file_path = 'lens-export.csv' # Make sure this file is in the same directory\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    if 'Lens ID' not in df.columns:\n",
    "        print(f\"Error: '{csv_file_path}' does not contain a 'Lens ID' column.\")\n",
    "    else:\n",
    "        lens_ids_to_check = df['Lens ID'].head(10).tolist() # Get the first 10 Lens IDs\n",
    "\n",
    "        print(f\"\\n--- Checking attribute presence for the first {len(lens_ids_to_check)} patents from '{csv_file_path}' ---\")\n",
    "        for i, lid in enumerate(lens_ids_to_check):\n",
    "            is_present, message = check_patent_attributes(str(lid), url, headers) # Ensure ID is string\n",
    "            status = \"PASS\" if is_present else \"FAIL\"\n",
    "            print(f\"[{i+1}/{len(lens_ids_to_check)}] Lens ID: {lid} - {status} - {message}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{csv_file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while reading the CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9b4f6dd-e685-4c89-be88-f7b7c8f468b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 667 patents from 'lens-export.csv'...\n",
      "Output will be saved to 'patents_data.jsonl'\n",
      "Processing [1/667] Lens ID: 143-105-704-034-927\n",
      "Processing [2/667] Lens ID: 049-288-157-543-024\n",
      "Processing [3/667] Lens ID: 038-549-955-608-076\n",
      "Processing [4/667] Lens ID: 060-633-857-515-414\n",
      "Processing [5/667] Lens ID: 198-026-218-217-031\n",
      "Processing [6/667] Lens ID: 075-769-703-927-237\n",
      "Processing [7/667] Lens ID: 095-518-093-968-654\n",
      "Processing [8/667] Lens ID: 113-036-063-984-644\n",
      "Processing [9/667] Lens ID: 012-259-548-123-929\n",
      "Processing [10/667] Lens ID: 060-517-777-247-722\n",
      "Progress: 10/667 processed (10 successful, 0 failed) - Est. 0.2 min elapsed\n",
      "Processing [11/667] Lens ID: 193-033-748-948-249\n",
      "Processing [12/667] Lens ID: 053-746-739-639-210\n",
      "Processing [13/667] Lens ID: 069-940-051-179-447\n",
      "Processing [14/667] Lens ID: 103-175-721-461-886\n",
      "Processing [15/667] Lens ID: 048-568-730-766-299\n",
      "Processing [16/667] Lens ID: 129-785-504-992-471\n",
      "Processing [17/667] Lens ID: 101-845-477-318-38X\n",
      "Processing [18/667] Lens ID: 116-589-304-325-05X\n",
      "Rate limited for Lens ID 116-589-304-325-05X. Waiting 1.0s before retry 1/5\n",
      "Processing [19/667] Lens ID: 186-282-779-726-255\n",
      "Processing [20/667] Lens ID: 058-190-295-912-474\n",
      "Rate limited for Lens ID 058-190-295-912-474. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 058-190-295-912-474. Waiting 2.0s before retry 2/5\n",
      "Progress: 20/667 processed (20 successful, 0 failed) - Est. 0.3 min elapsed\n",
      "Processing [21/667] Lens ID: 139-797-198-660-380\n",
      "Processing [22/667] Lens ID: 025-751-012-706-559\n",
      "Rate limited for Lens ID 025-751-012-706-559. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 025-751-012-706-559. Waiting 2.0s before retry 2/5\n",
      "Processing [23/667] Lens ID: 100-171-379-105-837\n",
      "Processing [24/667] Lens ID: 164-873-951-725-331\n",
      "Rate limited for Lens ID 164-873-951-725-331. Waiting 1.0s before retry 1/5\n",
      "Processing [25/667] Lens ID: 145-339-265-727-741\n",
      "Rate limited for Lens ID 145-339-265-727-741. Waiting 1.0s before retry 1/5\n",
      "Processing [26/667] Lens ID: 058-983-780-730-21X\n",
      "Rate limited for Lens ID 058-983-780-730-21X. Waiting 1.0s before retry 1/5\n",
      "Processing [27/667] Lens ID: 192-748-752-121-992\n",
      "Rate limited for Lens ID 192-748-752-121-992. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 192-748-752-121-992. Waiting 2.0s before retry 2/5\n",
      "Processing [28/667] Lens ID: 113-449-917-307-387\n",
      "Processing [29/667] Lens ID: 077-545-375-863-413\n",
      "Rate limited for Lens ID 077-545-375-863-413. Waiting 1.0s before retry 1/5\n",
      "Processing [30/667] Lens ID: 166-635-481-888-812\n",
      "Rate limited for Lens ID 166-635-481-888-812. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 166-635-481-888-812. Waiting 2.0s before retry 2/5\n",
      "Progress: 30/667 processed (30 successful, 0 failed) - Est. 0.5 min elapsed\n",
      "Processing [31/667] Lens ID: 026-467-187-127-813\n",
      "Rate limited for Lens ID 026-467-187-127-813. Waiting 1.0s before retry 1/5\n",
      "Processing [32/667] Lens ID: 051-610-043-141-451\n",
      "Rate limited for Lens ID 051-610-043-141-451. Waiting 1.0s before retry 1/5\n",
      "Processing [33/667] Lens ID: 167-000-971-292-525\n",
      "Rate limited for Lens ID 167-000-971-292-525. Waiting 1.0s before retry 1/5\n",
      "Processing [34/667] Lens ID: 061-822-979-793-534\n",
      "Rate limited for Lens ID 061-822-979-793-534. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 061-822-979-793-534. Waiting 2.0s before retry 2/5\n",
      "Processing [35/667] Lens ID: 060-727-932-305-810\n",
      "Rate limited for Lens ID 060-727-932-305-810. Waiting 1.0s before retry 1/5\n",
      "Processing [36/667] Lens ID: 186-163-080-978-190\n",
      "Rate limited for Lens ID 186-163-080-978-190. Waiting 1.0s before retry 1/5\n",
      "Processing [37/667] Lens ID: 180-769-456-773-336\n",
      "Rate limited for Lens ID 180-769-456-773-336. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 180-769-456-773-336. Waiting 2.0s before retry 2/5\n",
      "Processing [38/667] Lens ID: 113-452-465-051-137\n",
      "Rate limited for Lens ID 113-452-465-051-137. Waiting 1.0s before retry 1/5\n",
      "Processing [39/667] Lens ID: 082-124-598-211-549\n",
      "Rate limited for Lens ID 082-124-598-211-549. Waiting 1.0s before retry 1/5\n",
      "Processing [40/667] Lens ID: 155-367-700-352-122\n",
      "Rate limited for Lens ID 155-367-700-352-122. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 155-367-700-352-122. Waiting 2.0s before retry 2/5\n",
      "Progress: 40/667 processed (40 successful, 0 failed) - Est. 0.7 min elapsed\n",
      "Processing [41/667] Lens ID: 195-807-041-711-749\n",
      "Rate limited for Lens ID 195-807-041-711-749. Waiting 1.0s before retry 1/5\n",
      "Processing [42/667] Lens ID: 128-349-666-794-649\n",
      "Processing [43/667] Lens ID: 175-247-443-581-926\n",
      "Rate limited for Lens ID 175-247-443-581-926. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 175-247-443-581-926. Waiting 2.0s before retry 2/5\n",
      "Processing [44/667] Lens ID: 122-987-248-616-530\n",
      "Rate limited for Lens ID 122-987-248-616-530. Waiting 1.0s before retry 1/5\n",
      "Processing [45/667] Lens ID: 078-506-361-795-418\n",
      "Rate limited for Lens ID 078-506-361-795-418. Waiting 1.0s before retry 1/5\n",
      "Processing [46/667] Lens ID: 097-164-554-578-42X\n",
      "Rate limited for Lens ID 097-164-554-578-42X. Waiting 1.0s before retry 1/5\n",
      "Processing [47/667] Lens ID: 190-513-922-658-460\n",
      "Rate limited for Lens ID 190-513-922-658-460. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 190-513-922-658-460. Waiting 2.0s before retry 2/5\n",
      "Processing [48/667] Lens ID: 001-934-753-198-994\n",
      "Rate limited for Lens ID 001-934-753-198-994. Waiting 1.0s before retry 1/5\n",
      "Processing [49/667] Lens ID: 161-269-361-120-738\n",
      "Rate limited for Lens ID 161-269-361-120-738. Waiting 1.0s before retry 1/5\n",
      "Processing [50/667] Lens ID: 189-779-261-703-094\n",
      "Rate limited for Lens ID 189-779-261-703-094. Waiting 1.0s before retry 1/5\n",
      "Progress: 50/667 processed (50 successful, 0 failed) - Est. 0.8 min elapsed\n",
      "Processing [51/667] Lens ID: 107-953-254-357-759\n",
      "Rate limited for Lens ID 107-953-254-357-759. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 107-953-254-357-759. Waiting 2.0s before retry 2/5\n",
      "Processing [52/667] Lens ID: 046-901-913-448-035\n",
      "Rate limited for Lens ID 046-901-913-448-035. Waiting 1.0s before retry 1/5\n",
      "Processing [53/667] Lens ID: 155-046-752-976-597\n",
      "Rate limited for Lens ID 155-046-752-976-597. Waiting 1.0s before retry 1/5\n",
      "Processing [54/667] Lens ID: 130-752-287-073-288\n",
      "Rate limited for Lens ID 130-752-287-073-288. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 130-752-287-073-288. Waiting 2.0s before retry 2/5\n",
      "Processing [55/667] Lens ID: 183-561-639-401-216\n",
      "Processing [56/667] Lens ID: 091-906-447-030-962\n",
      "Rate limited for Lens ID 091-906-447-030-962. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 091-906-447-030-962. Waiting 2.0s before retry 2/5\n",
      "Processing [57/667] Lens ID: 065-006-800-908-793\n",
      "Processing [58/667] Lens ID: 028-379-221-806-143\n",
      "Rate limited for Lens ID 028-379-221-806-143. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 028-379-221-806-143. Waiting 2.0s before retry 2/5\n",
      "Processing [59/667] Lens ID: 075-122-279-151-574\n",
      "Rate limited for Lens ID 075-122-279-151-574. Waiting 1.0s before retry 1/5\n",
      "Processing [60/667] Lens ID: 016-614-276-956-677\n",
      "Rate limited for Lens ID 016-614-276-956-677. Waiting 1.0s before retry 1/5\n",
      "Progress: 60/667 processed (60 successful, 0 failed) - Est. 1.0 min elapsed\n",
      "Processing [61/667] Lens ID: 045-366-879-606-758\n",
      "Rate limited for Lens ID 045-366-879-606-758. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 045-366-879-606-758. Waiting 2.0s before retry 2/5\n",
      "Processing [62/667] Lens ID: 060-928-902-466-294\n",
      "Rate limited for Lens ID 060-928-902-466-294. Waiting 1.0s before retry 1/5\n",
      "Processing [63/667] Lens ID: 014-505-515-676-715\n",
      "Rate limited for Lens ID 014-505-515-676-715. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 014-505-515-676-715. Waiting 2.0s before retry 2/5\n",
      "Processing [64/667] Lens ID: 178-628-303-116-633\n",
      "Processing [65/667] Lens ID: 189-493-985-631-66X\n",
      "Rate limited for Lens ID 189-493-985-631-66X. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 189-493-985-631-66X. Waiting 2.0s before retry 2/5\n",
      "Processing [66/667] Lens ID: 008-116-745-395-031\n",
      "Rate limited for Lens ID 008-116-745-395-031. Waiting 1.0s before retry 1/5\n",
      "Processing [67/667] Lens ID: 048-361-194-196-094\n",
      "Rate limited for Lens ID 048-361-194-196-094. Waiting 1.0s before retry 1/5\n",
      "Processing [68/667] Lens ID: 046-866-496-060-361\n",
      "Rate limited for Lens ID 046-866-496-060-361. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 046-866-496-060-361. Waiting 2.0s before retry 2/5\n",
      "Processing [69/667] Lens ID: 131-212-684-899-55X\n",
      "Processing [70/667] Lens ID: 032-232-915-970-122\n",
      "Rate limited for Lens ID 032-232-915-970-122. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 032-232-915-970-122. Waiting 2.0s before retry 2/5\n",
      "Progress: 70/667 processed (70 successful, 0 failed) - Est. 1.2 min elapsed\n",
      "Processing [71/667] Lens ID: 143-134-226-642-137\n",
      "Rate limited for Lens ID 143-134-226-642-137. Waiting 1.0s before retry 1/5\n",
      "Processing [72/667] Lens ID: 004-293-196-235-976\n",
      "Rate limited for Lens ID 004-293-196-235-976. Waiting 1.0s before retry 1/5\n",
      "Processing [73/667] Lens ID: 091-870-925-050-57X\n",
      "Rate limited for Lens ID 091-870-925-050-57X. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 091-870-925-050-57X. Waiting 2.0s before retry 2/5\n",
      "Processing [74/667] Lens ID: 189-925-248-856-849\n",
      "Rate limited for Lens ID 189-925-248-856-849. Waiting 1.0s before retry 1/5\n",
      "Processing [75/667] Lens ID: 084-844-903-514-481\n",
      "Rate limited for Lens ID 084-844-903-514-481. Waiting 1.0s before retry 1/5\n",
      "Processing [76/667] Lens ID: 057-588-125-434-506\n",
      "Rate limited for Lens ID 057-588-125-434-506. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 057-588-125-434-506. Waiting 2.0s before retry 2/5\n",
      "Processing [77/667] Lens ID: 139-375-767-260-230\n",
      "Processing [78/667] Lens ID: 119-426-249-716-180\n",
      "Processing [79/667] Lens ID: 192-792-994-172-15X\n",
      "Rate limited for Lens ID 192-792-994-172-15X. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 192-792-994-172-15X. Waiting 2.0s before retry 2/5\n",
      "Processing [80/667] Lens ID: 135-651-195-904-944\n",
      "Rate limited for Lens ID 135-651-195-904-944. Waiting 1.0s before retry 1/5\n",
      "Progress: 80/667 processed (80 successful, 0 failed) - Est. 1.3 min elapsed\n",
      "Processing [81/667] Lens ID: 046-916-057-752-641\n",
      "Rate limited for Lens ID 046-916-057-752-641. Waiting 1.0s before retry 1/5\n",
      "Processing [82/667] Lens ID: 150-303-210-820-97X\n",
      "Rate limited for Lens ID 150-303-210-820-97X. Waiting 1.0s before retry 1/5\n",
      "Processing [83/667] Lens ID: 073-203-189-213-307\n",
      "Rate limited for Lens ID 073-203-189-213-307. Waiting 1.0s before retry 1/5\n",
      "Processing [84/667] Lens ID: 054-634-255-245-952\n",
      "Rate limited for Lens ID 054-634-255-245-952. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 054-634-255-245-952. Waiting 2.0s before retry 2/5\n",
      "Processing [85/667] Lens ID: 197-980-748-943-203\n",
      "Rate limited for Lens ID 197-980-748-943-203. Waiting 1.0s before retry 1/5\n",
      "Processing [86/667] Lens ID: 006-727-413-077-408\n",
      "Rate limited for Lens ID 006-727-413-077-408. Waiting 1.0s before retry 1/5\n",
      "Processing [87/667] Lens ID: 184-809-158-604-963\n",
      "Rate limited for Lens ID 184-809-158-604-963. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 184-809-158-604-963. Waiting 2.0s before retry 2/5\n",
      "Processing [88/667] Lens ID: 148-208-536-253-736\n",
      "Processing [89/667] Lens ID: 005-474-397-837-331\n",
      "Rate limited for Lens ID 005-474-397-837-331. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 005-474-397-837-331. Waiting 2.0s before retry 2/5\n",
      "Processing [90/667] Lens ID: 095-448-015-407-949\n",
      "Rate limited for Lens ID 095-448-015-407-949. Waiting 1.0s before retry 1/5\n",
      "Progress: 90/667 processed (90 successful, 0 failed) - Est. 1.5 min elapsed\n",
      "Processing [91/667] Lens ID: 053-457-891-347-836\n",
      "Rate limited for Lens ID 053-457-891-347-836. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 053-457-891-347-836. Waiting 2.0s before retry 2/5\n",
      "Processing [92/667] Lens ID: 075-073-899-106-848\n",
      "Processing [93/667] Lens ID: 175-540-787-004-199\n",
      "Rate limited for Lens ID 175-540-787-004-199. Waiting 1.0s before retry 1/5\n",
      "Processing [94/667] Lens ID: 183-697-799-973-54X\n",
      "Rate limited for Lens ID 183-697-799-973-54X. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 183-697-799-973-54X. Waiting 2.0s before retry 2/5\n",
      "Processing [95/667] Lens ID: 161-515-306-806-076\n",
      "Rate limited for Lens ID 161-515-306-806-076. Waiting 1.0s before retry 1/5\n",
      "Processing [96/667] Lens ID: 196-647-636-046-465\n",
      "Rate limited for Lens ID 196-647-636-046-465. Waiting 1.0s before retry 1/5\n",
      "Processing [97/667] Lens ID: 022-368-816-035-657\n",
      "Rate limited for Lens ID 022-368-816-035-657. Waiting 1.0s before retry 1/5\n",
      "Processing [98/667] Lens ID: 056-125-081-859-344\n",
      "Rate limited for Lens ID 056-125-081-859-344. Waiting 1.0s before retry 1/5\n",
      "Processing [99/667] Lens ID: 169-680-939-300-278\n",
      "Rate limited for Lens ID 169-680-939-300-278. Waiting 1.0s before retry 1/5\n",
      "Processing [100/667] Lens ID: 098-668-532-982-152\n",
      "Rate limited for Lens ID 098-668-532-982-152. Waiting 1.0s before retry 1/5\n",
      "Progress: 100/667 processed (100 successful, 0 failed) - Est. 1.7 min elapsed\n",
      "Processing [101/667] Lens ID: 110-229-533-083-499\n",
      "Rate limited for Lens ID 110-229-533-083-499. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 110-229-533-083-499. Waiting 2.0s before retry 2/5\n",
      "Processing [102/667] Lens ID: 069-090-038-020-337\n",
      "Rate limited for Lens ID 069-090-038-020-337. Waiting 1.0s before retry 1/5\n",
      "Processing [103/667] Lens ID: 073-408-838-072-268\n",
      "Rate limited for Lens ID 073-408-838-072-268. Waiting 1.0s before retry 1/5\n",
      "Processing [104/667] Lens ID: 074-794-026-800-439\n",
      "Rate limited for Lens ID 074-794-026-800-439. Waiting 1.0s before retry 1/5\n",
      "Processing [105/667] Lens ID: 048-902-208-034-205\n",
      "Rate limited for Lens ID 048-902-208-034-205. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 048-902-208-034-205. Waiting 2.0s before retry 2/5\n",
      "Processing [106/667] Lens ID: 009-167-938-536-503\n",
      "Rate limited for Lens ID 009-167-938-536-503. Waiting 1.0s before retry 1/5\n",
      "Processing [107/667] Lens ID: 055-659-977-827-660\n",
      "Rate limited for Lens ID 055-659-977-827-660. Waiting 1.0s before retry 1/5\n",
      "Processing [108/667] Lens ID: 123-075-040-960-783\n",
      "Rate limited for Lens ID 123-075-040-960-783. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 123-075-040-960-783. Waiting 2.0s before retry 2/5\n",
      "Processing [109/667] Lens ID: 041-267-045-651-561\n",
      "Rate limited for Lens ID 041-267-045-651-561. Waiting 1.0s before retry 1/5\n",
      "Processing [110/667] Lens ID: 181-334-791-283-864\n",
      "Rate limited for Lens ID 181-334-791-283-864. Waiting 1.0s before retry 1/5\n",
      "Progress: 110/667 processed (110 successful, 0 failed) - Est. 1.8 min elapsed\n",
      "Processing [111/667] Lens ID: 186-752-019-985-16X\n",
      "Rate limited for Lens ID 186-752-019-985-16X. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 186-752-019-985-16X. Waiting 2.0s before retry 2/5\n",
      "Processing [112/667] Lens ID: 149-771-695-939-435\n",
      "Processing [113/667] Lens ID: 136-362-712-769-353\n",
      "Rate limited for Lens ID 136-362-712-769-353. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 136-362-712-769-353. Waiting 2.0s before retry 2/5\n",
      "Processing [114/667] Lens ID: 161-929-160-664-537\n",
      "Rate limited for Lens ID 161-929-160-664-537. Waiting 1.0s before retry 1/5\n",
      "Processing [115/667] Lens ID: 111-723-587-632-801\n",
      "Rate limited for Lens ID 111-723-587-632-801. Waiting 1.0s before retry 1/5\n",
      "Processing [116/667] Lens ID: 040-078-026-892-555\n",
      "Rate limited for Lens ID 040-078-026-892-555. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 040-078-026-892-555. Waiting 2.0s before retry 2/5\n",
      "Processing [117/667] Lens ID: 012-787-725-564-477\n",
      "Processing [118/667] Lens ID: 032-900-128-585-998\n",
      "Rate limited for Lens ID 032-900-128-585-998. Waiting 1.0s before retry 1/5\n",
      "Processing [119/667] Lens ID: 131-329-725-033-787\n",
      "Rate limited for Lens ID 131-329-725-033-787. Waiting 1.0s before retry 1/5\n",
      "Processing [120/667] Lens ID: 012-101-619-959-898\n",
      "Progress: 120/667 processed (120 successful, 0 failed) - Est. 2.0 min elapsed\n",
      "Processing [121/667] Lens ID: 126-889-028-969-613\n",
      "Processing [122/667] Lens ID: 057-617-328-540-149\n",
      "Rate limited for Lens ID 057-617-328-540-149. Waiting 1.0s before retry 1/5\n",
      "Processing [123/667] Lens ID: 174-702-175-033-864\n",
      "Rate limited for Lens ID 174-702-175-033-864. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 174-702-175-033-864. Waiting 2.0s before retry 2/5\n",
      "Processing [124/667] Lens ID: 126-142-714-480-003\n",
      "Rate limited for Lens ID 126-142-714-480-003. Waiting 1.0s before retry 1/5\n",
      "Processing [125/667] Lens ID: 143-925-944-319-706\n",
      "Processing [126/667] Lens ID: 174-772-373-456-95X\n",
      "Processing [127/667] Lens ID: 029-976-546-987-490\n",
      "Rate limited for Lens ID 029-976-546-987-490. Waiting 1.0s before retry 1/5\n",
      "Processing [128/667] Lens ID: 032-268-539-225-405\n",
      "Rate limited for Lens ID 032-268-539-225-405. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 032-268-539-225-405. Waiting 2.0s before retry 2/5\n",
      "Processing [129/667] Lens ID: 075-553-243-658-52X\n",
      "Rate limited for Lens ID 075-553-243-658-52X. Waiting 1.0s before retry 1/5\n",
      "Processing [130/667] Lens ID: 045-331-957-102-580\n",
      "Progress: 130/667 processed (130 successful, 0 failed) - Est. 2.2 min elapsed\n",
      "Processing [131/667] Lens ID: 148-796-935-158-844\n",
      "Rate limited for Lens ID 148-796-935-158-844. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 148-796-935-158-844. Waiting 2.0s before retry 2/5\n",
      "Processing [132/667] Lens ID: 111-861-065-579-690\n",
      "Processing [133/667] Lens ID: 000-554-462-651-276\n",
      "Rate limited for Lens ID 000-554-462-651-276. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 000-554-462-651-276. Waiting 2.0s before retry 2/5\n",
      "Processing [134/667] Lens ID: 074-562-482-841-215\n",
      "Processing [135/667] Lens ID: 175-225-286-855-26X\n",
      "Rate limited for Lens ID 175-225-286-855-26X. Waiting 1.0s before retry 1/5\n",
      "Processing [136/667] Lens ID: 031-817-700-226-66X\n",
      "Processing [137/667] Lens ID: 185-335-072-021-032\n",
      "Rate limited for Lens ID 185-335-072-021-032. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 185-335-072-021-032. Waiting 2.0s before retry 2/5\n",
      "Processing [138/667] Lens ID: 165-241-817-191-157\n",
      "Rate limited for Lens ID 165-241-817-191-157. Waiting 1.0s before retry 1/5\n",
      "Processing [139/667] Lens ID: 096-821-365-617-937\n",
      "Rate limited for Lens ID 096-821-365-617-937. Waiting 1.0s before retry 1/5\n",
      "Processing [140/667] Lens ID: 109-807-457-092-508\n",
      "Rate limited for Lens ID 109-807-457-092-508. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 109-807-457-092-508. Waiting 2.0s before retry 2/5\n",
      "Progress: 140/667 processed (140 successful, 0 failed) - Est. 2.3 min elapsed\n",
      "Processing [141/667] Lens ID: 092-162-148-933-560\n",
      "Rate limited for Lens ID 092-162-148-933-560. Waiting 1.0s before retry 1/5\n",
      "Processing [142/667] Lens ID: 191-878-066-324-772\n",
      "Processing [143/667] Lens ID: 039-589-230-992-691\n",
      "Rate limited for Lens ID 039-589-230-992-691. Waiting 1.0s before retry 1/5\n",
      "Processing [144/667] Lens ID: 001-241-719-428-977\n",
      "Rate limited for Lens ID 001-241-719-428-977. Waiting 1.0s before retry 1/5\n",
      "Processing [145/667] Lens ID: 100-071-445-713-497\n",
      "Rate limited for Lens ID 100-071-445-713-497. Waiting 1.0s before retry 1/5\n",
      "Processing [146/667] Lens ID: 041-043-104-908-468\n",
      "Rate limited for Lens ID 041-043-104-908-468. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 041-043-104-908-468. Waiting 2.0s before retry 2/5\n",
      "Processing [147/667] Lens ID: 153-409-573-023-19X\n",
      "Processing [148/667] Lens ID: 080-971-254-113-990\n",
      "Rate limited for Lens ID 080-971-254-113-990. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 080-971-254-113-990. Waiting 2.0s before retry 2/5\n",
      "Processing [149/667] Lens ID: 016-014-926-542-128\n",
      "Processing [150/667] Lens ID: 001-289-808-011-578\n",
      "Rate limited for Lens ID 001-289-808-011-578. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 001-289-808-011-578. Waiting 2.0s before retry 2/5\n",
      "Progress: 150/667 processed (150 successful, 0 failed) - Est. 2.5 min elapsed\n",
      "Processing [151/667] Lens ID: 009-514-124-140-300\n",
      "Rate limited for Lens ID 009-514-124-140-300. Waiting 1.0s before retry 1/5\n",
      "Processing [152/667] Lens ID: 119-036-102-260-103\n",
      "Rate limited for Lens ID 119-036-102-260-103. Waiting 1.0s before retry 1/5\n",
      "Processing [153/667] Lens ID: 054-864-170-571-170\n",
      "Rate limited for Lens ID 054-864-170-571-170. Waiting 1.0s before retry 1/5\n",
      "Processing [154/667] Lens ID: 096-701-266-299-236\n",
      "Processing [155/667] Lens ID: 192-186-543-718-862\n",
      "Rate limited for Lens ID 192-186-543-718-862. Waiting 1.0s before retry 1/5\n",
      "Processing [156/667] Lens ID: 128-522-643-059-680\n",
      "Rate limited for Lens ID 128-522-643-059-680. Waiting 1.0s before retry 1/5\n",
      "Processing [157/667] Lens ID: 159-694-715-655-832\n",
      "Rate limited for Lens ID 159-694-715-655-832. Waiting 1.0s before retry 1/5\n",
      "Processing [158/667] Lens ID: 162-763-359-340-299\n",
      "Rate limited for Lens ID 162-763-359-340-299. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 162-763-359-340-299. Waiting 2.0s before retry 2/5\n",
      "Processing [159/667] Lens ID: 012-340-650-595-947\n",
      "Rate limited for Lens ID 012-340-650-595-947. Waiting 1.0s before retry 1/5\n",
      "Processing [160/667] Lens ID: 105-130-112-764-64X\n",
      "Rate limited for Lens ID 105-130-112-764-64X. Waiting 1.0s before retry 1/5\n",
      "Progress: 160/667 processed (160 successful, 0 failed) - Est. 2.7 min elapsed\n",
      "Processing [161/667] Lens ID: 126-349-338-626-90X\n",
      "Rate limited for Lens ID 126-349-338-626-90X. Waiting 1.0s before retry 1/5\n",
      "Processing [162/667] Lens ID: 086-985-999-812-775\n",
      "Rate limited for Lens ID 086-985-999-812-775. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 086-985-999-812-775. Waiting 2.0s before retry 2/5\n",
      "Processing [163/667] Lens ID: 064-607-384-230-721\n",
      "Rate limited for Lens ID 064-607-384-230-721. Waiting 1.0s before retry 1/5\n",
      "Processing [164/667] Lens ID: 062-102-987-689-981\n",
      "Rate limited for Lens ID 062-102-987-689-981. Waiting 1.0s before retry 1/5\n",
      "Processing [165/667] Lens ID: 077-035-114-567-00X\n",
      "Rate limited for Lens ID 077-035-114-567-00X. Waiting 1.0s before retry 1/5\n",
      "Processing [166/667] Lens ID: 140-772-285-420-355\n",
      "Rate limited for Lens ID 140-772-285-420-355. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 140-772-285-420-355. Waiting 2.0s before retry 2/5\n",
      "Processing [167/667] Lens ID: 154-683-834-706-625\n",
      "Rate limited for Lens ID 154-683-834-706-625. Waiting 1.0s before retry 1/5\n",
      "Processing [168/667] Lens ID: 062-393-473-203-836\n",
      "Rate limited for Lens ID 062-393-473-203-836. Waiting 1.0s before retry 1/5\n",
      "Processing [169/667] Lens ID: 185-529-878-737-705\n",
      "Rate limited for Lens ID 185-529-878-737-705. Waiting 1.0s before retry 1/5\n",
      "Processing [170/667] Lens ID: 178-126-251-903-386\n",
      "Rate limited for Lens ID 178-126-251-903-386. Waiting 1.0s before retry 1/5\n",
      "Progress: 170/667 processed (170 successful, 0 failed) - Est. 2.8 min elapsed\n",
      "Processing [171/667] Lens ID: 076-935-992-098-080\n",
      "Rate limited for Lens ID 076-935-992-098-080. Waiting 1.0s before retry 1/5\n",
      "Processing [172/667] Lens ID: 199-183-650-348-255\n",
      "Rate limited for Lens ID 199-183-650-348-255. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 199-183-650-348-255. Waiting 2.0s before retry 2/5\n",
      "Processing [173/667] Lens ID: 037-158-247-218-312\n",
      "Processing [174/667] Lens ID: 089-023-938-035-580\n",
      "Rate limited for Lens ID 089-023-938-035-580. Waiting 1.0s before retry 1/5\n",
      "Processing [175/667] Lens ID: 181-675-149-556-795\n",
      "Rate limited for Lens ID 181-675-149-556-795. Waiting 1.0s before retry 1/5\n",
      "Processing [176/667] Lens ID: 156-222-027-872-943\n",
      "Rate limited for Lens ID 156-222-027-872-943. Waiting 1.0s before retry 1/5\n",
      "Processing [177/667] Lens ID: 022-291-571-076-318\n",
      "Rate limited for Lens ID 022-291-571-076-318. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 022-291-571-076-318. Waiting 2.0s before retry 2/5\n",
      "Processing [178/667] Lens ID: 028-274-802-753-181\n",
      "Rate limited for Lens ID 028-274-802-753-181. Waiting 1.0s before retry 1/5\n",
      "Processing [179/667] Lens ID: 105-738-780-538-344\n",
      "Rate limited for Lens ID 105-738-780-538-344. Waiting 1.0s before retry 1/5\n",
      "Processing [180/667] Lens ID: 063-628-123-520-874\n",
      "Rate limited for Lens ID 063-628-123-520-874. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 063-628-123-520-874. Waiting 2.0s before retry 2/5\n",
      "Progress: 180/667 processed (180 successful, 0 failed) - Est. 3.0 min elapsed\n",
      "Processing [181/667] Lens ID: 181-286-934-701-194\n",
      "Rate limited for Lens ID 181-286-934-701-194. Waiting 1.0s before retry 1/5\n",
      "Processing [182/667] Lens ID: 132-890-886-386-145\n",
      "Rate limited for Lens ID 132-890-886-386-145. Waiting 1.0s before retry 1/5\n",
      "Processing [183/667] Lens ID: 109-525-461-877-441\n",
      "Rate limited for Lens ID 109-525-461-877-441. Waiting 1.0s before retry 1/5\n",
      "Processing [184/667] Lens ID: 148-824-853-382-063\n",
      "Rate limited for Lens ID 148-824-853-382-063. Waiting 1.0s before retry 1/5\n",
      "Processing [185/667] Lens ID: 179-859-159-528-83X\n",
      "Processing [186/667] Lens ID: 093-608-748-879-262\n",
      "Rate limited for Lens ID 093-608-748-879-262. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 093-608-748-879-262. Waiting 2.0s before retry 2/5\n",
      "Processing [187/667] Lens ID: 157-566-973-556-686\n",
      "Processing [188/667] Lens ID: 022-740-811-298-229\n",
      "Rate limited for Lens ID 022-740-811-298-229. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 022-740-811-298-229. Waiting 2.0s before retry 2/5\n",
      "Processing [189/667] Lens ID: 063-655-598-876-245\n",
      "Rate limited for Lens ID 063-655-598-876-245. Waiting 1.0s before retry 1/5\n",
      "Processing [190/667] Lens ID: 172-666-143-097-590\n",
      "Rate limited for Lens ID 172-666-143-097-590. Waiting 1.0s before retry 1/5\n",
      "Progress: 190/667 processed (190 successful, 0 failed) - Est. 3.2 min elapsed\n",
      "Processing [191/667] Lens ID: 121-498-549-405-311\n",
      "Rate limited for Lens ID 121-498-549-405-311. Waiting 1.0s before retry 1/5\n",
      "Processing [192/667] Lens ID: 022-515-800-412-080\n",
      "Rate limited for Lens ID 022-515-800-412-080. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 022-515-800-412-080. Waiting 2.0s before retry 2/5\n",
      "Processing [193/667] Lens ID: 082-449-880-246-409\n",
      "Rate limited for Lens ID 082-449-880-246-409. Waiting 1.0s before retry 1/5\n",
      "Processing [194/667] Lens ID: 113-066-400-015-914\n",
      "Rate limited for Lens ID 113-066-400-015-914. Waiting 1.0s before retry 1/5\n",
      "Processing [195/667] Lens ID: 131-048-727-773-999\n",
      "Rate limited for Lens ID 131-048-727-773-999. Waiting 1.0s before retry 1/5\n",
      "Processing [196/667] Lens ID: 077-958-560-804-090\n",
      "Rate limited for Lens ID 077-958-560-804-090. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 077-958-560-804-090. Waiting 2.0s before retry 2/5\n",
      "Processing [197/667] Lens ID: 020-245-755-067-088\n",
      "Rate limited for Lens ID 020-245-755-067-088. Waiting 1.0s before retry 1/5\n",
      "Processing [198/667] Lens ID: 199-787-621-423-567\n",
      "Rate limited for Lens ID 199-787-621-423-567. Waiting 1.0s before retry 1/5\n",
      "Processing [199/667] Lens ID: 106-870-346-853-24X\n",
      "Rate limited for Lens ID 106-870-346-853-24X. Waiting 1.0s before retry 1/5\n",
      "Processing [200/667] Lens ID: 161-755-985-153-515\n",
      "Rate limited for Lens ID 161-755-985-153-515. Waiting 1.0s before retry 1/5\n",
      "Progress: 200/667 processed (200 successful, 0 failed) - Est. 3.3 min elapsed\n",
      "Processing [201/667] Lens ID: 098-684-445-247-395\n",
      "Rate limited for Lens ID 098-684-445-247-395. Waiting 1.0s before retry 1/5\n",
      "Processing [202/667] Lens ID: 000-551-039-856-879\n",
      "Rate limited for Lens ID 000-551-039-856-879. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 000-551-039-856-879. Waiting 2.0s before retry 2/5\n",
      "Processing [203/667] Lens ID: 124-240-737-837-913\n",
      "Rate limited for Lens ID 124-240-737-837-913. Waiting 1.0s before retry 1/5\n",
      "Processing [204/667] Lens ID: 135-375-908-584-963\n",
      "Rate limited for Lens ID 135-375-908-584-963. Waiting 1.0s before retry 1/5\n",
      "Processing [205/667] Lens ID: 126-553-812-091-526\n",
      "Rate limited for Lens ID 126-553-812-091-526. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 126-553-812-091-526. Waiting 2.0s before retry 2/5\n",
      "Processing [206/667] Lens ID: 054-618-604-959-620\n",
      "Rate limited for Lens ID 054-618-604-959-620. Waiting 1.0s before retry 1/5\n",
      "Processing [207/667] Lens ID: 170-077-327-596-839\n",
      "Rate limited for Lens ID 170-077-327-596-839. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 170-077-327-596-839. Waiting 2.0s before retry 2/5\n",
      "Processing [208/667] Lens ID: 087-419-617-502-617\n",
      "Processing [209/667] Lens ID: 027-579-930-534-750\n",
      "Rate limited for Lens ID 027-579-930-534-750. Waiting 1.0s before retry 1/5\n",
      "Processing [210/667] Lens ID: 194-396-141-250-847\n",
      "Rate limited for Lens ID 194-396-141-250-847. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 194-396-141-250-847. Waiting 2.0s before retry 2/5\n",
      "Progress: 210/667 processed (210 successful, 0 failed) - Est. 3.5 min elapsed\n",
      "Processing [211/667] Lens ID: 023-265-752-714-734\n",
      "Processing [212/667] Lens ID: 116-371-845-842-277\n",
      "Processing [213/667] Lens ID: 041-542-376-374-304\n",
      "Processing [214/667] Lens ID: 188-037-167-217-015\n",
      "Processing [215/667] Lens ID: 120-929-904-916-34X\n",
      "Processing [216/667] Lens ID: 092-278-970-166-460\n",
      "Processing [217/667] Lens ID: 085-224-492-019-185\n",
      "Processing [218/667] Lens ID: 134-660-218-404-722\n",
      "Processing [219/667] Lens ID: 105-218-862-901-849\n",
      "Processing [220/667] Lens ID: 027-686-604-026-316\n",
      "Progress: 220/667 processed (220 successful, 0 failed) - Est. 3.7 min elapsed\n",
      "Processing [221/667] Lens ID: 184-320-978-673-960\n",
      "Processing [222/667] Lens ID: 179-543-963-494-991\n",
      "Processing [223/667] Lens ID: 142-270-784-318-710\n",
      "Processing [224/667] Lens ID: 175-839-002-396-724\n",
      "Processing [225/667] Lens ID: 140-450-396-016-978\n",
      "Processing [226/667] Lens ID: 041-362-377-260-861\n",
      "Processing [227/667] Lens ID: 099-630-518-028-090\n",
      "Processing [228/667] Lens ID: 038-026-636-633-001\n",
      "Processing [229/667] Lens ID: 014-918-643-880-222\n",
      "Processing [230/667] Lens ID: 115-045-804-921-913\n",
      "Progress: 230/667 processed (230 successful, 0 failed) - Est. 3.8 min elapsed\n",
      "Processing [231/667] Lens ID: 142-156-093-926-937\n",
      "Processing [232/667] Lens ID: 045-631-529-784-292\n",
      "Processing [233/667] Lens ID: 033-750-252-590-925\n",
      "Processing [234/667] Lens ID: 188-494-753-816-719\n",
      "Processing [235/667] Lens ID: 173-895-850-497-61X\n",
      "Processing [236/667] Lens ID: 071-325-315-086-47X\n",
      "Processing [237/667] Lens ID: 116-827-458-034-440\n",
      "Rate limited for Lens ID 116-827-458-034-440. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 116-827-458-034-440. Waiting 2.0s before retry 2/5\n",
      "Processing [238/667] Lens ID: 016-300-851-315-170\n",
      "Rate limited for Lens ID 016-300-851-315-170. Waiting 1.0s before retry 1/5\n",
      "Processing [239/667] Lens ID: 002-876-159-586-795\n",
      "Rate limited for Lens ID 002-876-159-586-795. Waiting 1.0s before retry 1/5\n",
      "Processing [240/667] Lens ID: 093-387-705-321-836\n",
      "Rate limited for Lens ID 093-387-705-321-836. Waiting 1.0s before retry 1/5\n",
      "Progress: 240/667 processed (240 successful, 0 failed) - Est. 4.0 min elapsed\n",
      "Processing [241/667] Lens ID: 070-519-174-135-280\n",
      "Rate limited for Lens ID 070-519-174-135-280. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 070-519-174-135-280. Waiting 2.0s before retry 2/5\n",
      "Processing [242/667] Lens ID: 131-009-791-393-50X\n",
      "Rate limited for Lens ID 131-009-791-393-50X. Waiting 1.0s before retry 1/5\n",
      "Processing [243/667] Lens ID: 026-003-763-984-974\n",
      "Rate limited for Lens ID 026-003-763-984-974. Waiting 1.0s before retry 1/5\n",
      "Processing [244/667] Lens ID: 073-185-990-319-071\n",
      "Rate limited for Lens ID 073-185-990-319-071. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 073-185-990-319-071. Waiting 2.0s before retry 2/5\n",
      "Processing [245/667] Lens ID: 054-528-351-779-357\n",
      "Rate limited for Lens ID 054-528-351-779-357. Waiting 1.0s before retry 1/5\n",
      "Processing [246/667] Lens ID: 117-347-883-876-722\n",
      "Rate limited for Lens ID 117-347-883-876-722. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 117-347-883-876-722. Waiting 2.0s before retry 2/5\n",
      "Processing [247/667] Lens ID: 136-819-631-982-467\n",
      "Rate limited for Lens ID 136-819-631-982-467. Waiting 1.0s before retry 1/5\n",
      "Processing [248/667] Lens ID: 009-267-019-861-792\n",
      "Rate limited for Lens ID 009-267-019-861-792. Waiting 1.0s before retry 1/5\n",
      "Processing [249/667] Lens ID: 127-219-404-903-25X\n",
      "Rate limited for Lens ID 127-219-404-903-25X. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 127-219-404-903-25X. Waiting 2.0s before retry 2/5\n",
      "Processing [250/667] Lens ID: 073-496-956-751-416\n",
      "Progress: 250/667 processed (250 successful, 0 failed) - Est. 4.2 min elapsed\n",
      "Processing [251/667] Lens ID: 010-867-191-076-942\n",
      "Rate limited for Lens ID 010-867-191-076-942. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 010-867-191-076-942. Waiting 2.0s before retry 2/5\n",
      "Processing [252/667] Lens ID: 074-925-121-990-485\n",
      "Rate limited for Lens ID 074-925-121-990-485. Waiting 1.0s before retry 1/5\n",
      "Processing [253/667] Lens ID: 063-560-723-461-873\n",
      "Rate limited for Lens ID 063-560-723-461-873. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 063-560-723-461-873. Waiting 2.0s before retry 2/5\n",
      "Processing [254/667] Lens ID: 099-828-835-962-390\n",
      "Rate limited for Lens ID 099-828-835-962-390. Waiting 1.0s before retry 1/5\n",
      "Processing [255/667] Lens ID: 143-341-090-970-79X\n",
      "Rate limited for Lens ID 143-341-090-970-79X. Waiting 1.0s before retry 1/5\n",
      "Processing [256/667] Lens ID: 033-266-966-635-166\n",
      "Rate limited for Lens ID 033-266-966-635-166. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 033-266-966-635-166. Waiting 2.0s before retry 2/5\n",
      "Processing [257/667] Lens ID: 014-430-974-320-351\n",
      "Processing [258/667] Lens ID: 039-177-142-864-381\n",
      "Rate limited for Lens ID 039-177-142-864-381. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 039-177-142-864-381. Waiting 2.0s before retry 2/5\n",
      "Processing [259/667] Lens ID: 182-536-435-694-781\n",
      "Rate limited for Lens ID 182-536-435-694-781. Waiting 1.0s before retry 1/5\n",
      "Processing [260/667] Lens ID: 121-509-257-646-19X\n",
      "Rate limited for Lens ID 121-509-257-646-19X. Waiting 1.0s before retry 1/5\n",
      "Progress: 260/667 processed (260 successful, 0 failed) - Est. 4.3 min elapsed\n",
      "Processing [261/667] Lens ID: 117-984-734-032-624\n",
      "Rate limited for Lens ID 117-984-734-032-624. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 117-984-734-032-624. Waiting 2.0s before retry 2/5\n",
      "Processing [262/667] Lens ID: 012-734-854-974-705\n",
      "Processing [263/667] Lens ID: 044-556-076-379-396\n",
      "Rate limited for Lens ID 044-556-076-379-396. Waiting 1.0s before retry 1/5\n",
      "Processing [264/667] Lens ID: 176-833-196-541-086\n",
      "Rate limited for Lens ID 176-833-196-541-086. Waiting 1.0s before retry 1/5\n",
      "Processing [265/667] Lens ID: 161-297-145-452-023\n",
      "Rate limited for Lens ID 161-297-145-452-023. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 161-297-145-452-023. Waiting 2.0s before retry 2/5\n",
      "Processing [266/667] Lens ID: 182-021-309-518-119\n",
      "Processing [267/667] Lens ID: 153-605-886-962-452\n",
      "Rate limited for Lens ID 153-605-886-962-452. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 153-605-886-962-452. Waiting 2.0s before retry 2/5\n",
      "Processing [268/667] Lens ID: 052-345-265-721-154\n",
      "Processing [269/667] Lens ID: 127-972-121-087-379\n",
      "Rate limited for Lens ID 127-972-121-087-379. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 127-972-121-087-379. Waiting 2.0s before retry 2/5\n",
      "Processing [270/667] Lens ID: 104-696-916-951-797\n",
      "Rate limited for Lens ID 104-696-916-951-797. Waiting 1.0s before retry 1/5\n",
      "Progress: 270/667 processed (270 successful, 0 failed) - Est. 4.5 min elapsed\n",
      "Processing [271/667] Lens ID: 007-421-376-249-868\n",
      "Rate limited for Lens ID 007-421-376-249-868. Waiting 1.0s before retry 1/5\n",
      "Processing [272/667] Lens ID: 039-024-991-165-414\n",
      "Rate limited for Lens ID 039-024-991-165-414. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 039-024-991-165-414. Waiting 2.0s before retry 2/5\n",
      "Processing [273/667] Lens ID: 140-033-903-806-601\n",
      "Processing [274/667] Lens ID: 089-437-457-262-870\n",
      "Rate limited for Lens ID 089-437-457-262-870. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 089-437-457-262-870. Waiting 2.0s before retry 2/5\n",
      "Processing [275/667] Lens ID: 068-087-046-385-455\n",
      "Rate limited for Lens ID 068-087-046-385-455. Waiting 1.0s before retry 1/5\n",
      "Processing [276/667] Lens ID: 190-797-057-954-763\n",
      "Rate limited for Lens ID 190-797-057-954-763. Waiting 1.0s before retry 1/5\n",
      "Processing [277/667] Lens ID: 199-694-350-593-202\n",
      "Rate limited for Lens ID 199-694-350-593-202. Waiting 1.0s before retry 1/5\n",
      "Processing [278/667] Lens ID: 196-106-488-144-95X\n",
      "Rate limited for Lens ID 196-106-488-144-95X. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 196-106-488-144-95X. Waiting 2.0s before retry 2/5\n",
      "Processing [279/667] Lens ID: 156-544-898-148-936\n",
      "Processing [280/667] Lens ID: 114-457-429-860-796\n",
      "Rate limited for Lens ID 114-457-429-860-796. Waiting 1.0s before retry 1/5\n",
      "Progress: 280/667 processed (280 successful, 0 failed) - Est. 4.7 min elapsed\n",
      "Processing [281/667] Lens ID: 087-239-195-221-218\n",
      "Rate limited for Lens ID 087-239-195-221-218. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 087-239-195-221-218. Waiting 2.0s before retry 2/5\n",
      "Processing [282/667] Lens ID: 038-006-692-506-172\n",
      "Rate limited for Lens ID 038-006-692-506-172. Waiting 1.0s before retry 1/5\n",
      "Processing [283/667] Lens ID: 166-601-598-558-598\n",
      "Rate limited for Lens ID 166-601-598-558-598. Waiting 1.0s before retry 1/5\n",
      "Processing [284/667] Lens ID: 153-449-589-031-254\n",
      "Rate limited for Lens ID 153-449-589-031-254. Waiting 1.0s before retry 1/5\n",
      "Processing [285/667] Lens ID: 105-005-166-459-170\n",
      "Rate limited for Lens ID 105-005-166-459-170. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 105-005-166-459-170. Waiting 2.0s before retry 2/5\n",
      "Processing [286/667] Lens ID: 017-350-478-179-079\n",
      "Rate limited for Lens ID 017-350-478-179-079. Waiting 1.0s before retry 1/5\n",
      "Processing [287/667] Lens ID: 022-556-417-367-206\n",
      "Rate limited for Lens ID 022-556-417-367-206. Waiting 1.0s before retry 1/5\n",
      "Processing [288/667] Lens ID: 165-957-742-156-237\n",
      "Rate limited for Lens ID 165-957-742-156-237. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 165-957-742-156-237. Waiting 2.0s before retry 2/5\n",
      "Processing [289/667] Lens ID: 010-790-794-821-531\n",
      "Rate limited for Lens ID 010-790-794-821-531. Waiting 1.0s before retry 1/5\n",
      "Processing [290/667] Lens ID: 144-816-710-477-158\n",
      "Rate limited for Lens ID 144-816-710-477-158. Waiting 1.0s before retry 1/5\n",
      "Progress: 290/667 processed (290 successful, 0 failed) - Est. 4.8 min elapsed\n",
      "Processing [291/667] Lens ID: 004-876-614-918-732\n",
      "Rate limited for Lens ID 004-876-614-918-732. Waiting 1.0s before retry 1/5\n",
      "Processing [292/667] Lens ID: 102-413-636-103-376\n",
      "Rate limited for Lens ID 102-413-636-103-376. Waiting 1.0s before retry 1/5\n",
      "Processing [293/667] Lens ID: 147-783-753-464-016\n",
      "Rate limited for Lens ID 147-783-753-464-016. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 147-783-753-464-016. Waiting 2.0s before retry 2/5\n",
      "Processing [294/667] Lens ID: 169-261-340-302-617\n",
      "Rate limited for Lens ID 169-261-340-302-617. Waiting 1.0s before retry 1/5\n",
      "Processing [295/667] Lens ID: 083-494-198-659-672\n",
      "Rate limited for Lens ID 083-494-198-659-672. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 083-494-198-659-672. Waiting 2.0s before retry 2/5\n",
      "Processing [296/667] Lens ID: 111-805-690-071-191\n",
      "Rate limited for Lens ID 111-805-690-071-191. Waiting 1.0s before retry 1/5\n",
      "Processing [297/667] Lens ID: 190-645-607-668-911\n",
      "Rate limited for Lens ID 190-645-607-668-911. Waiting 1.0s before retry 1/5\n",
      "Processing [298/667] Lens ID: 172-286-036-261-75X\n",
      "Rate limited for Lens ID 172-286-036-261-75X. Waiting 1.0s before retry 1/5\n",
      "Processing [299/667] Lens ID: 006-953-619-009-166\n",
      "Rate limited for Lens ID 006-953-619-009-166. Waiting 1.0s before retry 1/5\n",
      "Processing [300/667] Lens ID: 035-588-092-733-236\n",
      "Progress: 300/667 processed (300 successful, 0 failed) - Est. 5.0 min elapsed\n",
      "Processing [301/667] Lens ID: 014-509-610-026-866\n",
      "Rate limited for Lens ID 014-509-610-026-866. Waiting 1.0s before retry 1/5\n",
      "Processing [302/667] Lens ID: 077-576-777-708-514\n",
      "Rate limited for Lens ID 077-576-777-708-514. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 077-576-777-708-514. Waiting 2.0s before retry 2/5\n",
      "Processing [303/667] Lens ID: 000-644-049-111-208\n",
      "Rate limited for Lens ID 000-644-049-111-208. Waiting 1.0s before retry 1/5\n",
      "Processing [304/667] Lens ID: 182-604-245-617-357\n",
      "Rate limited for Lens ID 182-604-245-617-357. Waiting 1.0s before retry 1/5\n",
      "Processing [305/667] Lens ID: 067-380-115-785-10X\n",
      "Rate limited for Lens ID 067-380-115-785-10X. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 067-380-115-785-10X. Waiting 2.0s before retry 2/5\n",
      "Processing [306/667] Lens ID: 122-350-005-178-523\n",
      "Processing [307/667] Lens ID: 031-108-058-961-584\n",
      "Rate limited for Lens ID 031-108-058-961-584. Waiting 1.0s before retry 1/5\n",
      "Processing [308/667] Lens ID: 189-836-233-892-586\n",
      "Rate limited for Lens ID 189-836-233-892-586. Waiting 1.0s before retry 1/5\n",
      "Processing [309/667] Lens ID: 023-590-131-826-580\n",
      "Rate limited for Lens ID 023-590-131-826-580. Waiting 1.0s before retry 1/5\n",
      "Processing [310/667] Lens ID: 007-501-630-649-526\n",
      "Rate limited for Lens ID 007-501-630-649-526. Waiting 1.0s before retry 1/5\n",
      "Progress: 310/667 processed (310 successful, 0 failed) - Est. 5.2 min elapsed\n",
      "Processing [311/667] Lens ID: 102-358-811-394-598\n",
      "Rate limited for Lens ID 102-358-811-394-598. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 102-358-811-394-598. Waiting 2.0s before retry 2/5\n",
      "Processing [312/667] Lens ID: 004-639-151-004-862\n",
      "Processing [313/667] Lens ID: 039-385-206-761-178\n",
      "Rate limited for Lens ID 039-385-206-761-178. Waiting 1.0s before retry 1/5\n",
      "Processing [314/667] Lens ID: 117-989-631-542-106\n",
      "Rate limited for Lens ID 117-989-631-542-106. Waiting 1.0s before retry 1/5\n",
      "Processing [315/667] Lens ID: 086-056-667-255-777\n",
      "Rate limited for Lens ID 086-056-667-255-777. Waiting 1.0s before retry 1/5\n",
      "Processing [316/667] Lens ID: 153-061-155-412-999\n",
      "Rate limited for Lens ID 153-061-155-412-999. Waiting 1.0s before retry 1/5\n",
      "Processing [317/667] Lens ID: 087-225-833-799-317\n",
      "Rate limited for Lens ID 087-225-833-799-317. Waiting 1.0s before retry 1/5\n",
      "Processing [318/667] Lens ID: 066-386-223-056-036\n",
      "Processing [319/667] Lens ID: 158-887-934-268-175\n",
      "Processing [320/667] Lens ID: 093-574-291-839-478\n",
      "Progress: 320/667 processed (320 successful, 0 failed) - Est. 5.3 min elapsed\n",
      "Processing [321/667] Lens ID: 055-373-853-024-563\n",
      "Processing [322/667] Lens ID: 160-136-435-048-666\n",
      "Processing [323/667] Lens ID: 090-626-322-638-242\n",
      "Rate limited for Lens ID 090-626-322-638-242. Waiting 1.0s before retry 1/5\n",
      "Processing [324/667] Lens ID: 148-161-186-574-795\n",
      "Rate limited for Lens ID 148-161-186-574-795. Waiting 1.0s before retry 1/5\n",
      "Processing [325/667] Lens ID: 076-206-742-796-29X\n",
      "Rate limited for Lens ID 076-206-742-796-29X. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 076-206-742-796-29X. Waiting 2.0s before retry 2/5\n",
      "Processing [326/667] Lens ID: 182-247-935-779-297\n",
      "Processing [327/667] Lens ID: 098-423-187-424-612\n",
      "Rate limited for Lens ID 098-423-187-424-612. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 098-423-187-424-612. Waiting 2.0s before retry 2/5\n",
      "Processing [328/667] Lens ID: 191-062-045-292-589\n",
      "Rate limited for Lens ID 191-062-045-292-589. Waiting 1.0s before retry 1/5\n",
      "Processing [329/667] Lens ID: 010-415-961-753-931\n",
      "Rate limited for Lens ID 010-415-961-753-931. Waiting 1.0s before retry 1/5\n",
      "Processing [330/667] Lens ID: 065-464-971-435-124\n",
      "Rate limited for Lens ID 065-464-971-435-124. Waiting 1.0s before retry 1/5\n",
      "Progress: 330/667 processed (330 successful, 0 failed) - Est. 5.5 min elapsed\n",
      "Processing [331/667] Lens ID: 052-622-069-472-464\n",
      "Rate limited for Lens ID 052-622-069-472-464. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 052-622-069-472-464. Waiting 2.0s before retry 2/5\n",
      "Processing [332/667] Lens ID: 051-115-089-213-053\n",
      "Rate limited for Lens ID 051-115-089-213-053. Waiting 1.0s before retry 1/5\n",
      "Processing [333/667] Lens ID: 010-228-832-264-011\n",
      "Rate limited for Lens ID 010-228-832-264-011. Waiting 1.0s before retry 1/5\n",
      "Processing [334/667] Lens ID: 133-732-756-622-43X\n",
      "Rate limited for Lens ID 133-732-756-622-43X. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 133-732-756-622-43X. Waiting 2.0s before retry 2/5\n",
      "Processing [335/667] Lens ID: 188-593-711-576-36X\n",
      "Rate limited for Lens ID 188-593-711-576-36X. Waiting 1.0s before retry 1/5\n",
      "Processing [336/667] Lens ID: 053-409-603-857-860\n",
      "Rate limited for Lens ID 053-409-603-857-860. Waiting 1.0s before retry 1/5\n",
      "Processing [337/667] Lens ID: 180-168-482-597-280\n",
      "Rate limited for Lens ID 180-168-482-597-280. Waiting 1.0s before retry 1/5\n",
      "Processing [338/667] Lens ID: 187-056-919-518-038\n",
      "Rate limited for Lens ID 187-056-919-518-038. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 187-056-919-518-038. Waiting 2.0s before retry 2/5\n",
      "Processing [339/667] Lens ID: 104-839-539-778-92X\n",
      "Rate limited for Lens ID 104-839-539-778-92X. Waiting 1.0s before retry 1/5\n",
      "Processing [340/667] Lens ID: 176-559-932-747-703\n",
      "Rate limited for Lens ID 176-559-932-747-703. Waiting 1.0s before retry 1/5\n",
      "Progress: 340/667 processed (340 successful, 0 failed) - Est. 5.7 min elapsed\n",
      "Processing [341/667] Lens ID: 024-548-162-466-351\n",
      "Rate limited for Lens ID 024-548-162-466-351. Waiting 1.0s before retry 1/5\n",
      "Processing [342/667] Lens ID: 146-782-366-944-748\n",
      "Rate limited for Lens ID 146-782-366-944-748. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 146-782-366-944-748. Waiting 2.0s before retry 2/5\n",
      "Processing [343/667] Lens ID: 047-206-467-812-408\n",
      "Rate limited for Lens ID 047-206-467-812-408. Waiting 1.0s before retry 1/5\n",
      "Processing [344/667] Lens ID: 163-896-133-499-155\n",
      "Rate limited for Lens ID 163-896-133-499-155. Waiting 1.0s before retry 1/5\n",
      "Processing [345/667] Lens ID: 126-380-070-074-061\n",
      "Rate limited for Lens ID 126-380-070-074-061. Waiting 1.0s before retry 1/5\n",
      "Processing [346/667] Lens ID: 090-566-372-228-442\n",
      "Rate limited for Lens ID 090-566-372-228-442. Waiting 1.0s before retry 1/5\n",
      "Processing [347/667] Lens ID: 035-108-985-475-662\n",
      "Rate limited for Lens ID 035-108-985-475-662. Waiting 1.0s before retry 1/5\n",
      "Processing [348/667] Lens ID: 062-822-294-697-335\n",
      "Rate limited for Lens ID 062-822-294-697-335. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 062-822-294-697-335. Waiting 2.0s before retry 2/5\n",
      "Processing [349/667] Lens ID: 142-732-397-575-884\n",
      "Processing [350/667] Lens ID: 066-908-190-635-589\n",
      "Rate limited for Lens ID 066-908-190-635-589. Waiting 1.0s before retry 1/5\n",
      "Progress: 350/667 processed (350 successful, 0 failed) - Est. 5.8 min elapsed\n",
      "Processing [351/667] Lens ID: 197-438-567-071-477\n",
      "Rate limited for Lens ID 197-438-567-071-477. Waiting 1.0s before retry 1/5\n",
      "Processing [352/667] Lens ID: 074-279-496-477-57X\n",
      "Rate limited for Lens ID 074-279-496-477-57X. Waiting 1.0s before retry 1/5\n",
      "Processing [353/667] Lens ID: 106-591-559-152-795\n",
      "Rate limited for Lens ID 106-591-559-152-795. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 106-591-559-152-795. Waiting 2.0s before retry 2/5\n",
      "Processing [354/667] Lens ID: 014-350-716-774-676\n",
      "Rate limited for Lens ID 014-350-716-774-676. Waiting 1.0s before retry 1/5\n",
      "Processing [355/667] Lens ID: 003-189-528-864-394\n",
      "Rate limited for Lens ID 003-189-528-864-394. Waiting 1.0s before retry 1/5\n",
      "Processing [356/667] Lens ID: 188-977-251-088-332\n",
      "Rate limited for Lens ID 188-977-251-088-332. Waiting 1.0s before retry 1/5\n",
      "Processing [357/667] Lens ID: 139-920-402-564-873\n",
      "Rate limited for Lens ID 139-920-402-564-873. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 139-920-402-564-873. Waiting 2.0s before retry 2/5\n",
      "Processing [358/667] Lens ID: 044-045-324-982-895\n",
      "Rate limited for Lens ID 044-045-324-982-895. Waiting 1.0s before retry 1/5\n",
      "Processing [359/667] Lens ID: 051-467-695-753-42X\n",
      "Rate limited for Lens ID 051-467-695-753-42X. Waiting 1.0s before retry 1/5\n",
      "Processing [360/667] Lens ID: 141-649-847-656-937\n",
      "Rate limited for Lens ID 141-649-847-656-937. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 141-649-847-656-937. Waiting 2.0s before retry 2/5\n",
      "Progress: 360/667 processed (360 successful, 0 failed) - Est. 6.0 min elapsed\n",
      "Processing [361/667] Lens ID: 099-685-836-466-393\n",
      "Processing [362/667] Lens ID: 150-236-386-396-829\n",
      "Rate limited for Lens ID 150-236-386-396-829. Waiting 1.0s before retry 1/5\n",
      "Processing [363/667] Lens ID: 154-964-465-280-649\n",
      "Rate limited for Lens ID 154-964-465-280-649. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 154-964-465-280-649. Waiting 2.0s before retry 2/5\n",
      "Processing [364/667] Lens ID: 162-269-822-288-063\n",
      "Rate limited for Lens ID 162-269-822-288-063. Waiting 1.0s before retry 1/5\n",
      "Processing [365/667] Lens ID: 062-552-411-006-947\n",
      "Rate limited for Lens ID 062-552-411-006-947. Waiting 1.0s before retry 1/5\n",
      "Processing [366/667] Lens ID: 123-836-263-374-259\n",
      "Rate limited for Lens ID 123-836-263-374-259. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 123-836-263-374-259. Waiting 2.0s before retry 2/5\n",
      "Processing [367/667] Lens ID: 077-984-765-929-208\n",
      "Processing [368/667] Lens ID: 123-468-519-821-248\n",
      "Rate limited for Lens ID 123-468-519-821-248. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 123-468-519-821-248. Waiting 2.0s before retry 2/5\n",
      "Processing [369/667] Lens ID: 085-762-875-402-921\n",
      "Processing [370/667] Lens ID: 033-183-750-376-982\n",
      "Rate limited for Lens ID 033-183-750-376-982. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 033-183-750-376-982. Waiting 2.0s before retry 2/5\n",
      "Progress: 370/667 processed (370 successful, 0 failed) - Est. 6.2 min elapsed\n",
      "Processing [371/667] Lens ID: 022-162-360-384-520\n",
      "Rate limited for Lens ID 022-162-360-384-520. Waiting 1.0s before retry 1/5\n",
      "Processing [372/667] Lens ID: 052-581-129-043-226\n",
      "Rate limited for Lens ID 052-581-129-043-226. Waiting 1.0s before retry 1/5\n",
      "Processing [373/667] Lens ID: 051-165-377-937-334\n",
      "Rate limited for Lens ID 051-165-377-937-334. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 051-165-377-937-334. Waiting 2.0s before retry 2/5\n",
      "Processing [374/667] Lens ID: 038-007-961-323-900\n",
      "Processing [375/667] Lens ID: 187-472-688-420-641\n",
      "Rate limited for Lens ID 187-472-688-420-641. Waiting 1.0s before retry 1/5\n",
      "Processing [376/667] Lens ID: 132-855-978-021-190\n",
      "Rate limited for Lens ID 132-855-978-021-190. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 132-855-978-021-190. Waiting 2.0s before retry 2/5\n",
      "Processing [377/667] Lens ID: 108-769-482-033-496\n",
      "Processing [378/667] Lens ID: 091-043-833-883-698\n",
      "Rate limited for Lens ID 091-043-833-883-698. Waiting 1.0s before retry 1/5\n",
      "Processing [379/667] Lens ID: 188-021-577-328-512\n",
      "Rate limited for Lens ID 188-021-577-328-512. Waiting 1.0s before retry 1/5\n",
      "Processing [380/667] Lens ID: 011-238-535-143-93X\n",
      "Rate limited for Lens ID 011-238-535-143-93X. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 011-238-535-143-93X. Waiting 2.0s before retry 2/5\n",
      "Progress: 380/667 processed (380 successful, 0 failed) - Est. 6.3 min elapsed\n",
      "Processing [381/667] Lens ID: 050-056-428-587-436\n",
      "Processing [382/667] Lens ID: 074-195-382-459-850\n",
      "Rate limited for Lens ID 074-195-382-459-850. Waiting 1.0s before retry 1/5\n",
      "Processing [383/667] Lens ID: 034-260-199-518-346\n",
      "Processing [384/667] Lens ID: 018-725-366-356-776\n",
      "Rate limited for Lens ID 018-725-366-356-776. Waiting 1.0s before retry 1/5\n",
      "Processing [385/667] Lens ID: 161-529-017-661-736\n",
      "Rate limited for Lens ID 161-529-017-661-736. Waiting 1.0s before retry 1/5\n",
      "Processing [386/667] Lens ID: 185-574-518-677-502\n",
      "Processing [387/667] Lens ID: 082-662-220-327-257\n",
      "Processing [388/667] Lens ID: 035-173-402-308-936\n",
      "Rate limited for Lens ID 035-173-402-308-936. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 035-173-402-308-936. Waiting 2.0s before retry 2/5\n",
      "Processing [389/667] Lens ID: 155-095-704-436-052\n",
      "Processing [390/667] Lens ID: 032-425-083-495-98X\n",
      "Progress: 390/667 processed (390 successful, 0 failed) - Est. 6.5 min elapsed\n",
      "Processing [391/667] Lens ID: 181-328-651-053-062\n",
      "Processing [392/667] Lens ID: 135-576-800-621-057\n",
      "Processing [393/667] Lens ID: 113-235-565-531-858\n",
      "Processing [394/667] Lens ID: 170-887-065-507-692\n",
      "Processing [395/667] Lens ID: 074-387-054-086-828\n",
      "Processing [396/667] Lens ID: 157-381-146-288-98X\n",
      "Processing [397/667] Lens ID: 046-252-356-059-40X\n",
      "Processing [398/667] Lens ID: 045-931-666-802-084\n",
      "Processing [399/667] Lens ID: 170-084-737-129-753\n",
      "Processing [400/667] Lens ID: 090-517-983-901-738\n",
      "Progress: 400/667 processed (400 successful, 0 failed) - Est. 6.7 min elapsed\n",
      "Processing [401/667] Lens ID: 196-750-588-679-211\n",
      "Processing [402/667] Lens ID: 044-954-851-066-694\n",
      "Rate limited for Lens ID 044-954-851-066-694. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 044-954-851-066-694. Waiting 2.0s before retry 2/5\n",
      "Processing [403/667] Lens ID: 047-266-996-173-706\n",
      "Processing [404/667] Lens ID: 059-642-246-456-231\n",
      "Rate limited for Lens ID 059-642-246-456-231. Waiting 1.0s before retry 1/5\n",
      "Processing [405/667] Lens ID: 049-034-097-007-720\n",
      "Rate limited for Lens ID 049-034-097-007-720. Waiting 1.0s before retry 1/5\n",
      "Processing [406/667] Lens ID: 199-935-290-588-552\n",
      "Rate limited for Lens ID 199-935-290-588-552. Waiting 1.0s before retry 1/5\n",
      "Processing [407/667] Lens ID: 117-849-331-331-716\n",
      "Rate limited for Lens ID 117-849-331-331-716. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 117-849-331-331-716. Waiting 2.0s before retry 2/5\n",
      "Processing [408/667] Lens ID: 083-019-126-205-222\n",
      "Processing [409/667] Lens ID: 150-165-817-287-347\n",
      "Processing [410/667] Lens ID: 136-721-600-960-526\n",
      "Rate limited for Lens ID 136-721-600-960-526. Waiting 1.0s before retry 1/5\n",
      "Progress: 410/667 processed (410 successful, 0 failed) - Est. 6.8 min elapsed\n",
      "Processing [411/667] Lens ID: 183-616-665-551-483\n",
      "Rate limited for Lens ID 183-616-665-551-483. Waiting 1.0s before retry 1/5\n",
      "Processing [412/667] Lens ID: 115-129-732-209-123\n",
      "Rate limited for Lens ID 115-129-732-209-123. Waiting 1.0s before retry 1/5\n",
      "Processing [413/667] Lens ID: 136-334-857-347-727\n",
      "Processing [414/667] Lens ID: 108-880-417-444-059\n",
      "Processing [415/667] Lens ID: 055-529-994-044-494\n",
      "Rate limited for Lens ID 055-529-994-044-494. Waiting 1.0s before retry 1/5\n",
      "Processing [416/667] Lens ID: 084-579-866-748-478\n",
      "Rate limited for Lens ID 084-579-866-748-478. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 084-579-866-748-478. Waiting 2.0s before retry 2/5\n",
      "Processing [417/667] Lens ID: 062-070-699-633-031\n",
      "Processing [418/667] Lens ID: 027-061-069-369-850\n",
      "Rate limited for Lens ID 027-061-069-369-850. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 027-061-069-369-850. Waiting 2.0s before retry 2/5\n",
      "Processing [419/667] Lens ID: 184-633-635-665-659\n",
      "Processing [420/667] Lens ID: 159-240-023-647-405\n",
      "Rate limited for Lens ID 159-240-023-647-405. Waiting 1.0s before retry 1/5\n",
      "Progress: 420/667 processed (420 successful, 0 failed) - Est. 7.0 min elapsed\n",
      "Processing [421/667] Lens ID: 187-105-244-646-442\n",
      "Rate limited for Lens ID 187-105-244-646-442. Waiting 1.0s before retry 1/5\n",
      "Processing [422/667] Lens ID: 144-945-855-184-007\n",
      "Rate limited for Lens ID 144-945-855-184-007. Waiting 1.0s before retry 1/5\n",
      "Processing [423/667] Lens ID: 118-029-397-314-567\n",
      "Rate limited for Lens ID 118-029-397-314-567. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 118-029-397-314-567. Waiting 2.0s before retry 2/5\n",
      "Processing [424/667] Lens ID: 108-198-029-315-886\n",
      "Rate limited for Lens ID 108-198-029-315-886. Waiting 1.0s before retry 1/5\n",
      "Processing [425/667] Lens ID: 196-401-567-329-110\n",
      "Rate limited for Lens ID 196-401-567-329-110. Waiting 1.0s before retry 1/5\n",
      "Processing [426/667] Lens ID: 133-881-205-838-233\n",
      "Rate limited for Lens ID 133-881-205-838-233. Waiting 1.0s before retry 1/5\n",
      "Processing [427/667] Lens ID: 106-485-381-895-225\n",
      "Rate limited for Lens ID 106-485-381-895-225. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 106-485-381-895-225. Waiting 2.0s before retry 2/5\n",
      "Processing [428/667] Lens ID: 179-817-900-923-379\n",
      "Rate limited for Lens ID 179-817-900-923-379. Waiting 1.0s before retry 1/5\n",
      "Processing [429/667] Lens ID: 023-556-697-865-889\n",
      "Rate limited for Lens ID 023-556-697-865-889. Waiting 1.0s before retry 1/5\n",
      "Processing [430/667] Lens ID: 154-091-843-122-067\n",
      "Rate limited for Lens ID 154-091-843-122-067. Waiting 1.0s before retry 1/5\n",
      "Progress: 430/667 processed (430 successful, 0 failed) - Est. 7.2 min elapsed\n",
      "Processing [431/667] Lens ID: 124-479-582-931-896\n",
      "Rate limited for Lens ID 124-479-582-931-896. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 124-479-582-931-896. Waiting 2.0s before retry 2/5\n",
      "Processing [432/667] Lens ID: 002-880-662-690-727\n",
      "Rate limited for Lens ID 002-880-662-690-727. Waiting 1.0s before retry 1/5\n",
      "Processing [433/667] Lens ID: 080-708-625-568-68X\n",
      "Rate limited for Lens ID 080-708-625-568-68X. Waiting 1.0s before retry 1/5\n",
      "Processing [434/667] Lens ID: 059-399-519-070-055\n",
      "Rate limited for Lens ID 059-399-519-070-055. Waiting 1.0s before retry 1/5\n",
      "Processing [435/667] Lens ID: 160-698-190-751-568\n",
      "Rate limited for Lens ID 160-698-190-751-568. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 160-698-190-751-568. Waiting 2.0s before retry 2/5\n",
      "Processing [436/667] Lens ID: 133-624-877-624-783\n",
      "Processing [437/667] Lens ID: 199-196-890-917-616\n",
      "Rate limited for Lens ID 199-196-890-917-616. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 199-196-890-917-616. Waiting 2.0s before retry 2/5\n",
      "Processing [438/667] Lens ID: 041-104-409-382-045\n",
      "Processing [439/667] Lens ID: 108-872-776-782-068\n",
      "Rate limited for Lens ID 108-872-776-782-068. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 108-872-776-782-068. Waiting 2.0s before retry 2/5\n",
      "Processing [440/667] Lens ID: 130-890-196-879-61X\n",
      "Rate limited for Lens ID 130-890-196-879-61X. Waiting 1.0s before retry 1/5\n",
      "Progress: 440/667 processed (440 successful, 0 failed) - Est. 7.3 min elapsed\n",
      "Processing [441/667] Lens ID: 169-922-756-053-146\n",
      "Rate limited for Lens ID 169-922-756-053-146. Waiting 1.0s before retry 1/5\n",
      "Processing [442/667] Lens ID: 029-951-734-161-142\n",
      "Processing [443/667] Lens ID: 154-366-341-333-868\n",
      "Processing [444/667] Lens ID: 141-339-678-378-177\n",
      "Processing [445/667] Lens ID: 004-924-032-754-567\n",
      "Processing [446/667] Lens ID: 172-319-067-242-453\n",
      "Processing [447/667] Lens ID: 059-504-599-314-209\n",
      "Processing [448/667] Lens ID: 027-001-614-499-454\n",
      "Processing [449/667] Lens ID: 198-517-686-757-22X\n",
      "Rate limited for Lens ID 198-517-686-757-22X. Waiting 1.0s before retry 1/5\n",
      "Processing [450/667] Lens ID: 137-779-641-915-674\n",
      "Rate limited for Lens ID 137-779-641-915-674. Waiting 1.0s before retry 1/5\n",
      "Progress: 450/667 processed (450 successful, 0 failed) - Est. 7.5 min elapsed\n",
      "Processing [451/667] Lens ID: 025-147-504-723-303\n",
      "Rate limited for Lens ID 025-147-504-723-303. Waiting 1.0s before retry 1/5\n",
      "Processing [452/667] Lens ID: 186-048-024-296-044\n",
      "Rate limited for Lens ID 186-048-024-296-044. Waiting 1.0s before retry 1/5\n",
      "Processing [453/667] Lens ID: 110-396-062-183-730\n",
      "Rate limited for Lens ID 110-396-062-183-730. Waiting 1.0s before retry 1/5\n",
      "Processing [454/667] Lens ID: 118-010-542-401-457\n",
      "Rate limited for Lens ID 118-010-542-401-457. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 118-010-542-401-457. Waiting 2.0s before retry 2/5\n",
      "Processing [455/667] Lens ID: 136-784-105-625-374\n",
      "Rate limited for Lens ID 136-784-105-625-374. Waiting 1.0s before retry 1/5\n",
      "Processing [456/667] Lens ID: 067-631-164-243-44X\n",
      "Rate limited for Lens ID 067-631-164-243-44X. Waiting 1.0s before retry 1/5\n",
      "Processing [457/667] Lens ID: 151-302-212-782-606\n",
      "Processing [458/667] Lens ID: 123-223-542-608-589\n",
      "Rate limited for Lens ID 123-223-542-608-589. Waiting 1.0s before retry 1/5\n",
      "Processing [459/667] Lens ID: 002-177-926-412-727\n",
      "Rate limited for Lens ID 002-177-926-412-727. Waiting 1.0s before retry 1/5\n",
      "Processing [460/667] Lens ID: 057-405-156-046-237\n",
      "Rate limited for Lens ID 057-405-156-046-237. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 057-405-156-046-237. Waiting 2.0s before retry 2/5\n",
      "Progress: 460/667 processed (460 successful, 0 failed) - Est. 7.7 min elapsed\n",
      "Processing [461/667] Lens ID: 139-638-413-989-106\n",
      "Processing [462/667] Lens ID: 175-054-502-818-348\n",
      "Rate limited for Lens ID 175-054-502-818-348. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 175-054-502-818-348. Waiting 2.0s before retry 2/5\n",
      "Processing [463/667] Lens ID: 179-123-115-381-90X\n",
      "Processing [464/667] Lens ID: 111-609-428-980-631\n",
      "Processing [465/667] Lens ID: 121-088-526-695-30X\n",
      "Rate limited for Lens ID 121-088-526-695-30X. Waiting 1.0s before retry 1/5\n",
      "Processing [466/667] Lens ID: 036-173-771-840-748\n",
      "Rate limited for Lens ID 036-173-771-840-748. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 036-173-771-840-748. Waiting 2.0s before retry 2/5\n",
      "Processing [467/667] Lens ID: 101-481-097-296-145\n",
      "Processing [468/667] Lens ID: 182-767-489-851-920\n",
      "Rate limited for Lens ID 182-767-489-851-920. Waiting 1.0s before retry 1/5\n",
      "Processing [469/667] Lens ID: 142-346-344-882-930\n",
      "Processing [470/667] Lens ID: 140-572-640-697-863\n",
      "Progress: 470/667 processed (470 successful, 0 failed) - Est. 7.8 min elapsed\n",
      "Processing [471/667] Lens ID: 139-464-959-674-854\n",
      "Rate limited for Lens ID 139-464-959-674-854. Waiting 1.0s before retry 1/5\n",
      "Processing [472/667] Lens ID: 169-441-583-318-574\n",
      "Processing [473/667] Lens ID: 090-676-911-937-617\n",
      "Processing [474/667] Lens ID: 101-213-668-161-981\n",
      "Processing [475/667] Lens ID: 152-030-851-499-196\n",
      "Processing [476/667] Lens ID: 190-117-532-562-549\n",
      "Processing [477/667] Lens ID: 108-382-996-428-595\n",
      "Processing [478/667] Lens ID: 046-411-719-440-599\n",
      "Processing [479/667] Lens ID: 025-767-222-243-050\n",
      "Processing [480/667] Lens ID: 104-834-551-747-031\n",
      "Progress: 480/667 processed (480 successful, 0 failed) - Est. 8.0 min elapsed\n",
      "Processing [481/667] Lens ID: 019-396-340-452-243\n",
      "Processing [482/667] Lens ID: 085-436-254-291-057\n",
      "Processing [483/667] Lens ID: 075-166-071-298-547\n",
      "Processing [484/667] Lens ID: 039-922-031-382-045\n",
      "Processing [485/667] Lens ID: 104-831-588-807-479\n",
      "Processing [486/667] Lens ID: 192-722-269-215-619\n",
      "Processing [487/667] Lens ID: 168-788-888-227-24X\n",
      "Processing [488/667] Lens ID: 191-876-460-760-610\n",
      "Processing [489/667] Lens ID: 130-481-789-807-841\n",
      "Processing [490/667] Lens ID: 084-783-781-088-472\n",
      "Rate limited for Lens ID 084-783-781-088-472. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 084-783-781-088-472. Waiting 2.0s before retry 2/5\n",
      "Progress: 490/667 processed (490 successful, 0 failed) - Est. 8.2 min elapsed\n",
      "Processing [491/667] Lens ID: 196-557-021-684-98X\n",
      "Processing [492/667] Lens ID: 168-377-472-024-434\n",
      "Rate limited for Lens ID 168-377-472-024-434. Waiting 1.0s before retry 1/5\n",
      "Processing [493/667] Lens ID: 097-230-147-819-508\n",
      "Processing [494/667] Lens ID: 165-884-370-654-504\n",
      "Processing [495/667] Lens ID: 175-337-774-629-516\n",
      "Processing [496/667] Lens ID: 185-160-791-286-190\n",
      "Processing [497/667] Lens ID: 104-705-326-454-266\n",
      "Rate limited for Lens ID 104-705-326-454-266. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 104-705-326-454-266. Waiting 2.0s before retry 2/5\n",
      "Processing [498/667] Lens ID: 158-879-448-169-219\n",
      "Processing [499/667] Lens ID: 021-382-421-165-451\n",
      "Processing [500/667] Lens ID: 035-513-494-375-092\n",
      "Progress: 500/667 processed (500 successful, 0 failed) - Est. 8.3 min elapsed\n",
      "Processing [501/667] Lens ID: 166-084-382-086-517\n",
      "Rate limited for Lens ID 166-084-382-086-517. Waiting 1.0s before retry 1/5\n",
      "Processing [502/667] Lens ID: 146-320-903-404-194\n",
      "Rate limited for Lens ID 146-320-903-404-194. Waiting 1.0s before retry 1/5\n",
      "Processing [503/667] Lens ID: 094-369-473-781-696\n",
      "Rate limited for Lens ID 094-369-473-781-696. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 094-369-473-781-696. Waiting 2.0s before retry 2/5\n",
      "Processing [504/667] Lens ID: 157-924-235-494-222\n",
      "Rate limited for Lens ID 157-924-235-494-222. Waiting 1.0s before retry 1/5\n",
      "Processing [505/667] Lens ID: 025-635-593-546-830\n",
      "Processing [506/667] Lens ID: 116-835-229-588-01X\n",
      "Rate limited for Lens ID 116-835-229-588-01X. Waiting 1.0s before retry 1/5\n",
      "Processing [507/667] Lens ID: 102-417-092-882-495\n",
      "Rate limited for Lens ID 102-417-092-882-495. Waiting 1.0s before retry 1/5\n",
      "Processing [508/667] Lens ID: 022-953-362-574-29X\n",
      "Rate limited for Lens ID 022-953-362-574-29X. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 022-953-362-574-29X. Waiting 2.0s before retry 2/5\n",
      "Processing [509/667] Lens ID: 182-045-319-534-59X\n",
      "Processing [510/667] Lens ID: 192-586-311-363-276\n",
      "Rate limited for Lens ID 192-586-311-363-276. Waiting 1.0s before retry 1/5\n",
      "Progress: 510/667 processed (510 successful, 0 failed) - Est. 8.5 min elapsed\n",
      "Processing [511/667] Lens ID: 035-961-451-891-408\n",
      "Rate limited for Lens ID 035-961-451-891-408. Waiting 1.0s before retry 1/5\n",
      "Processing [512/667] Lens ID: 019-860-269-598-923\n",
      "Rate limited for Lens ID 019-860-269-598-923. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 019-860-269-598-923. Waiting 2.0s before retry 2/5\n",
      "Processing [513/667] Lens ID: 090-323-946-857-971\n",
      "Processing [514/667] Lens ID: 192-813-724-793-917\n",
      "Rate limited for Lens ID 192-813-724-793-917. Waiting 1.0s before retry 1/5\n",
      "Processing [515/667] Lens ID: 027-652-790-587-92X\n",
      "Processing [516/667] Lens ID: 041-668-086-786-996\n",
      "Processing [517/667] Lens ID: 074-327-754-177-259\n",
      "Rate limited for Lens ID 074-327-754-177-259. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 074-327-754-177-259. Waiting 2.0s before retry 2/5\n",
      "Processing [518/667] Lens ID: 010-090-759-416-162\n",
      "Processing [519/667] Lens ID: 059-981-074-643-79X\n",
      "Rate limited for Lens ID 059-981-074-643-79X. Waiting 1.0s before retry 1/5\n",
      "Processing [520/667] Lens ID: 092-649-582-800-933\n",
      "Rate limited for Lens ID 092-649-582-800-933. Waiting 1.0s before retry 1/5\n",
      "Progress: 520/667 processed (520 successful, 0 failed) - Est. 8.7 min elapsed\n",
      "Processing [521/667] Lens ID: 156-755-255-606-569\n",
      "Processing [522/667] Lens ID: 197-095-250-985-420\n",
      "Rate limited for Lens ID 197-095-250-985-420. Waiting 1.0s before retry 1/5\n",
      "Processing [523/667] Lens ID: 157-414-018-604-19X\n",
      "Processing [524/667] Lens ID: 173-174-139-072-118\n",
      "Processing [525/667] Lens ID: 122-610-447-883-041\n",
      "Rate limited for Lens ID 122-610-447-883-041. Waiting 1.0s before retry 1/5\n",
      "Processing [526/667] Lens ID: 188-623-509-868-662\n",
      "Rate limited for Lens ID 188-623-509-868-662. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 188-623-509-868-662. Waiting 2.0s before retry 2/5\n",
      "Processing [527/667] Lens ID: 047-148-638-280-176\n",
      "Rate limited for Lens ID 047-148-638-280-176. Waiting 1.0s before retry 1/5\n",
      "Processing [528/667] Lens ID: 030-386-153-783-88X\n",
      "Rate limited for Lens ID 030-386-153-783-88X. Waiting 1.0s before retry 1/5\n",
      "Processing [529/667] Lens ID: 195-131-671-444-668\n",
      "Rate limited for Lens ID 195-131-671-444-668. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 195-131-671-444-668. Waiting 2.0s before retry 2/5\n",
      "Processing [530/667] Lens ID: 123-438-789-390-479\n",
      "Rate limited for Lens ID 123-438-789-390-479. Waiting 1.0s before retry 1/5\n",
      "Progress: 530/667 processed (530 successful, 0 failed) - Est. 8.8 min elapsed\n",
      "Processing [531/667] Lens ID: 038-556-992-896-279\n",
      "Rate limited for Lens ID 038-556-992-896-279. Waiting 1.0s before retry 1/5\n",
      "Processing [532/667] Lens ID: 047-534-075-006-290\n",
      "Rate limited for Lens ID 047-534-075-006-290. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 047-534-075-006-290. Waiting 2.0s before retry 2/5\n",
      "Processing [533/667] Lens ID: 051-786-376-412-976\n",
      "Processing [534/667] Lens ID: 070-917-389-318-598\n",
      "Rate limited for Lens ID 070-917-389-318-598. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 070-917-389-318-598. Waiting 2.0s before retry 2/5\n",
      "Processing [535/667] Lens ID: 192-010-666-122-04X\n",
      "Rate limited for Lens ID 192-010-666-122-04X. Waiting 1.0s before retry 1/5\n",
      "Processing [536/667] Lens ID: 176-209-529-587-885\n",
      "Rate limited for Lens ID 176-209-529-587-885. Waiting 1.0s before retry 1/5\n",
      "Processing [537/667] Lens ID: 014-143-781-289-974\n",
      "Rate limited for Lens ID 014-143-781-289-974. Waiting 1.0s before retry 1/5\n",
      "Processing [538/667] Lens ID: 054-801-105-273-208\n",
      "Processing [539/667] Lens ID: 154-052-040-538-42X\n",
      "Rate limited for Lens ID 154-052-040-538-42X. Waiting 1.0s before retry 1/5\n",
      "Processing [540/667] Lens ID: 148-267-425-294-72X\n",
      "Rate limited for Lens ID 148-267-425-294-72X. Waiting 1.0s before retry 1/5\n",
      "Progress: 540/667 processed (540 successful, 0 failed) - Est. 9.0 min elapsed\n",
      "Processing [541/667] Lens ID: 161-382-530-134-79X\n",
      "Rate limited for Lens ID 161-382-530-134-79X. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 161-382-530-134-79X. Waiting 2.0s before retry 2/5\n",
      "Processing [542/667] Lens ID: 033-164-148-639-82X\n",
      "Rate limited for Lens ID 033-164-148-639-82X. Waiting 1.0s before retry 1/5\n",
      "Processing [543/667] Lens ID: 098-610-600-168-872\n",
      "Rate limited for Lens ID 098-610-600-168-872. Waiting 1.0s before retry 1/5\n",
      "Processing [544/667] Lens ID: 134-731-463-275-341\n",
      "Rate limited for Lens ID 134-731-463-275-341. Waiting 1.0s before retry 1/5\n",
      "Processing [545/667] Lens ID: 067-984-669-805-288\n",
      "Rate limited for Lens ID 067-984-669-805-288. Waiting 1.0s before retry 1/5\n",
      "Processing [546/667] Lens ID: 194-106-719-074-520\n",
      "Rate limited for Lens ID 194-106-719-074-520. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 194-106-719-074-520. Waiting 2.0s before retry 2/5\n",
      "Processing [547/667] Lens ID: 198-362-755-573-384\n",
      "Rate limited for Lens ID 198-362-755-573-384. Waiting 1.0s before retry 1/5\n",
      "Processing [548/667] Lens ID: 057-809-783-315-10X\n",
      "Rate limited for Lens ID 057-809-783-315-10X. Waiting 1.0s before retry 1/5\n",
      "Processing [549/667] Lens ID: 143-024-387-598-774\n",
      "Rate limited for Lens ID 143-024-387-598-774. Waiting 1.0s before retry 1/5\n",
      "Processing [550/667] Lens ID: 007-126-905-721-573\n",
      "Rate limited for Lens ID 007-126-905-721-573. Waiting 1.0s before retry 1/5\n",
      "Progress: 550/667 processed (550 successful, 0 failed) - Est. 9.2 min elapsed\n",
      "Processing [551/667] Lens ID: 175-148-572-654-972\n",
      "Rate limited for Lens ID 175-148-572-654-972. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 175-148-572-654-972. Waiting 2.0s before retry 2/5\n",
      "Processing [552/667] Lens ID: 081-582-559-895-96X\n",
      "Rate limited for Lens ID 081-582-559-895-96X. Waiting 1.0s before retry 1/5\n",
      "Processing [553/667] Lens ID: 148-468-144-730-573\n",
      "Rate limited for Lens ID 148-468-144-730-573. Waiting 1.0s before retry 1/5\n",
      "Processing [554/667] Lens ID: 151-244-732-659-49X\n",
      "Rate limited for Lens ID 151-244-732-659-49X. Waiting 1.0s before retry 1/5\n",
      "Processing [555/667] Lens ID: 029-248-311-267-194\n",
      "Rate limited for Lens ID 029-248-311-267-194. Waiting 1.0s before retry 1/5\n",
      "Processing [556/667] Lens ID: 039-861-614-932-225\n",
      "Rate limited for Lens ID 039-861-614-932-225. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 039-861-614-932-225. Waiting 2.0s before retry 2/5\n",
      "Processing [557/667] Lens ID: 100-609-339-598-896\n",
      "Processing [558/667] Lens ID: 104-287-418-271-767\n",
      "Rate limited for Lens ID 104-287-418-271-767. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 104-287-418-271-767. Waiting 2.0s before retry 2/5\n",
      "Processing [559/667] Lens ID: 063-635-174-984-498\n",
      "Rate limited for Lens ID 063-635-174-984-498. Waiting 1.0s before retry 1/5\n",
      "Processing [560/667] Lens ID: 153-466-989-714-999\n",
      "Progress: 560/667 processed (560 successful, 0 failed) - Est. 9.3 min elapsed\n",
      "Processing [561/667] Lens ID: 145-998-341-890-516\n",
      "Rate limited for Lens ID 145-998-341-890-516. Waiting 1.0s before retry 1/5\n",
      "Processing [562/667] Lens ID: 046-637-369-926-530\n",
      "Rate limited for Lens ID 046-637-369-926-530. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 046-637-369-926-530. Waiting 2.0s before retry 2/5\n",
      "Processing [563/667] Lens ID: 075-146-614-407-175\n",
      "Rate limited for Lens ID 075-146-614-407-175. Waiting 1.0s before retry 1/5\n",
      "Processing [564/667] Lens ID: 088-023-572-144-347\n",
      "Processing [565/667] Lens ID: 014-417-462-061-441\n",
      "Processing [566/667] Lens ID: 118-882-669-355-900\n",
      "Rate limited for Lens ID 118-882-669-355-900. Waiting 1.0s before retry 1/5\n",
      "Processing [567/667] Lens ID: 102-277-156-370-48X\n",
      "Rate limited for Lens ID 102-277-156-370-48X. Waiting 1.0s before retry 1/5\n",
      "Processing [568/667] Lens ID: 109-317-648-072-006\n",
      "Rate limited for Lens ID 109-317-648-072-006. Waiting 1.0s before retry 1/5\n",
      "Processing [569/667] Lens ID: 170-842-269-115-165\n",
      "Processing [570/667] Lens ID: 127-360-270-877-81X\n",
      "Rate limited for Lens ID 127-360-270-877-81X. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 127-360-270-877-81X. Waiting 2.0s before retry 2/5\n",
      "Progress: 570/667 processed (570 successful, 0 failed) - Est. 9.5 min elapsed\n",
      "Processing [571/667] Lens ID: 063-867-572-652-643\n",
      "Rate limited for Lens ID 063-867-572-652-643. Waiting 1.0s before retry 1/5\n",
      "Processing [572/667] Lens ID: 175-444-277-823-514\n",
      "Rate limited for Lens ID 175-444-277-823-514. Waiting 1.0s before retry 1/5\n",
      "Processing [573/667] Lens ID: 126-283-888-708-214\n",
      "Rate limited for Lens ID 126-283-888-708-214. Waiting 1.0s before retry 1/5\n",
      "Processing [574/667] Lens ID: 072-146-618-856-219\n",
      "Rate limited for Lens ID 072-146-618-856-219. Waiting 1.0s before retry 1/5\n",
      "Processing [575/667] Lens ID: 099-585-554-490-645\n",
      "Rate limited for Lens ID 099-585-554-490-645. Waiting 1.0s before retry 1/5\n",
      "Processing [576/667] Lens ID: 007-846-758-300-992\n",
      "Rate limited for Lens ID 007-846-758-300-992. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 007-846-758-300-992. Waiting 2.0s before retry 2/5\n",
      "Processing [577/667] Lens ID: 199-811-731-956-724\n",
      "Processing [578/667] Lens ID: 006-624-306-595-099\n",
      "Rate limited for Lens ID 006-624-306-595-099. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 006-624-306-595-099. Waiting 2.0s before retry 2/5\n",
      "Processing [579/667] Lens ID: 141-206-717-392-141\n",
      "Processing [580/667] Lens ID: 148-349-461-832-694\n",
      "Progress: 580/667 processed (580 successful, 0 failed) - Est. 9.7 min elapsed\n",
      "Processing [581/667] Lens ID: 088-769-424-336-962\n",
      "Processing [582/667] Lens ID: 160-944-727-648-167\n",
      "Processing [583/667] Lens ID: 194-434-578-291-515\n",
      "Processing [584/667] Lens ID: 000-152-677-120-075\n",
      "Processing [585/667] Lens ID: 099-601-677-696-579\n",
      "Processing [586/667] Lens ID: 147-547-997-895-15X\n",
      "Processing [587/667] Lens ID: 154-496-517-931-817\n",
      "Processing [588/667] Lens ID: 144-578-038-341-488\n",
      "Processing [589/667] Lens ID: 019-910-078-190-629\n",
      "Processing [590/667] Lens ID: 173-343-207-157-557\n",
      "Progress: 590/667 processed (590 successful, 0 failed) - Est. 9.8 min elapsed\n",
      "Processing [591/667] Lens ID: 053-601-310-222-917\n",
      "Processing [592/667] Lens ID: 188-333-305-881-456\n",
      "Processing [593/667] Lens ID: 144-809-285-945-751\n",
      "Processing [594/667] Lens ID: 063-530-109-806-440\n",
      "Processing [595/667] Lens ID: 005-666-763-856-839\n",
      "Processing [596/667] Lens ID: 017-138-129-876-230\n",
      "Rate limited for Lens ID 017-138-129-876-230. Waiting 1.0s before retry 1/5\n",
      "Processing [597/667] Lens ID: 068-043-442-380-475\n",
      "Rate limited for Lens ID 068-043-442-380-475. Waiting 1.0s before retry 1/5\n",
      "Processing [598/667] Lens ID: 152-355-924-468-848\n",
      "Rate limited for Lens ID 152-355-924-468-848. Waiting 1.0s before retry 1/5\n",
      "Processing [599/667] Lens ID: 187-847-409-002-841\n",
      "Rate limited for Lens ID 187-847-409-002-841. Waiting 1.0s before retry 1/5\n",
      "Processing [600/667] Lens ID: 107-880-197-484-967\n",
      "Rate limited for Lens ID 107-880-197-484-967. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 107-880-197-484-967. Waiting 2.0s before retry 2/5\n",
      "Progress: 600/667 processed (600 successful, 0 failed) - Est. 10.0 min elapsed\n",
      "Processing [601/667] Lens ID: 196-449-894-096-337\n",
      "Processing [602/667] Lens ID: 047-751-888-209-301\n",
      "Rate limited for Lens ID 047-751-888-209-301. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 047-751-888-209-301. Waiting 2.0s before retry 2/5\n",
      "Processing [603/667] Lens ID: 068-144-882-104-776\n",
      "Rate limited for Lens ID 068-144-882-104-776. Waiting 1.0s before retry 1/5\n",
      "Processing [604/667] Lens ID: 190-936-207-257-507\n",
      "Rate limited for Lens ID 190-936-207-257-507. Waiting 1.0s before retry 1/5\n",
      "Processing [605/667] Lens ID: 167-566-131-301-524\n",
      "Rate limited for Lens ID 167-566-131-301-524. Waiting 1.0s before retry 1/5\n",
      "Processing [606/667] Lens ID: 110-643-705-085-620\n",
      "Rate limited for Lens ID 110-643-705-085-620. Waiting 1.0s before retry 1/5\n",
      "Processing [607/667] Lens ID: 021-883-642-933-923\n",
      "Rate limited for Lens ID 021-883-642-933-923. Waiting 1.0s before retry 1/5\n",
      "Processing [608/667] Lens ID: 168-114-367-016-788\n",
      "Rate limited for Lens ID 168-114-367-016-788. Waiting 1.0s before retry 1/5\n",
      "Processing [609/667] Lens ID: 133-138-790-055-772\n",
      "Rate limited for Lens ID 133-138-790-055-772. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 133-138-790-055-772. Waiting 2.0s before retry 2/5\n",
      "Processing [610/667] Lens ID: 086-574-286-090-534\n",
      "Progress: 610/667 processed (610 successful, 0 failed) - Est. 10.2 min elapsed\n",
      "Processing [611/667] Lens ID: 100-317-222-451-474\n",
      "Processing [612/667] Lens ID: 076-715-179-326-859\n",
      "Processing [613/667] Lens ID: 106-639-292-158-249\n",
      "Processing [614/667] Lens ID: 156-289-246-308-425\n",
      "Processing [615/667] Lens ID: 060-953-668-643-444\n",
      "Rate limited for Lens ID 060-953-668-643-444. Waiting 1.0s before retry 1/5\n",
      "Processing [616/667] Lens ID: 130-610-074-312-966\n",
      "Rate limited for Lens ID 130-610-074-312-966. Waiting 1.0s before retry 1/5\n",
      "Processing [617/667] Lens ID: 004-203-580-589-363\n",
      "Rate limited for Lens ID 004-203-580-589-363. Waiting 1.0s before retry 1/5\n",
      "Processing [618/667] Lens ID: 150-447-330-472-28X\n",
      "Rate limited for Lens ID 150-447-330-472-28X. Waiting 1.0s before retry 1/5\n",
      "Processing [619/667] Lens ID: 195-408-105-820-795\n",
      "Rate limited for Lens ID 195-408-105-820-795. Waiting 1.0s before retry 1/5\n",
      "Processing [620/667] Lens ID: 043-605-959-100-979\n",
      "Rate limited for Lens ID 043-605-959-100-979. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 043-605-959-100-979. Waiting 2.0s before retry 2/5\n",
      "Progress: 620/667 processed (620 successful, 0 failed) - Est. 10.3 min elapsed\n",
      "Processing [621/667] Lens ID: 178-959-552-439-990\n",
      "Rate limited for Lens ID 178-959-552-439-990. Waiting 1.0s before retry 1/5\n",
      "Processing [622/667] Lens ID: 118-017-360-569-672\n",
      "Rate limited for Lens ID 118-017-360-569-672. Waiting 1.0s before retry 1/5\n",
      "Processing [623/667] Lens ID: 191-432-894-947-645\n",
      "Rate limited for Lens ID 191-432-894-947-645. Waiting 1.0s before retry 1/5\n",
      "Processing [624/667] Lens ID: 026-040-568-655-473\n",
      "Rate limited for Lens ID 026-040-568-655-473. Waiting 1.0s before retry 1/5\n",
      "Processing [625/667] Lens ID: 137-263-675-367-082\n",
      "Rate limited for Lens ID 137-263-675-367-082. Waiting 1.0s before retry 1/5\n",
      "Processing [626/667] Lens ID: 009-208-440-609-259\n",
      "Rate limited for Lens ID 009-208-440-609-259. Waiting 1.0s before retry 1/5\n",
      "Processing [627/667] Lens ID: 183-398-107-952-394\n",
      "Rate limited for Lens ID 183-398-107-952-394. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 183-398-107-952-394. Waiting 2.0s before retry 2/5\n",
      "Processing [628/667] Lens ID: 037-124-820-840-257\n",
      "Rate limited for Lens ID 037-124-820-840-257. Waiting 1.0s before retry 1/5\n",
      "Processing [629/667] Lens ID: 166-209-741-514-533\n",
      "Rate limited for Lens ID 166-209-741-514-533. Waiting 1.0s before retry 1/5\n",
      "Processing [630/667] Lens ID: 009-098-732-754-779\n",
      "Rate limited for Lens ID 009-098-732-754-779. Waiting 1.0s before retry 1/5\n",
      "Progress: 630/667 processed (630 successful, 0 failed) - Est. 10.5 min elapsed\n",
      "Processing [631/667] Lens ID: 045-603-964-182-773\n",
      "Rate limited for Lens ID 045-603-964-182-773. Waiting 1.0s before retry 1/5\n",
      "Processing [632/667] Lens ID: 155-375-822-702-004\n",
      "Processing [633/667] Lens ID: 020-498-612-514-202\n",
      "Processing [634/667] Lens ID: 077-962-993-149-804\n",
      "Processing [635/667] Lens ID: 146-623-536-823-415\n",
      "Rate limited for Lens ID 146-623-536-823-415. Waiting 1.0s before retry 1/5\n",
      "Processing [636/667] Lens ID: 056-862-760-542-656\n",
      "Rate limited for Lens ID 056-862-760-542-656. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 056-862-760-542-656. Waiting 2.0s before retry 2/5\n",
      "Processing [637/667] Lens ID: 051-651-442-641-868\n",
      "Processing [638/667] Lens ID: 091-738-444-989-203\n",
      "Processing [639/667] Lens ID: 054-823-927-077-588\n",
      "Processing [640/667] Lens ID: 189-411-182-498-218\n",
      "Rate limited for Lens ID 189-411-182-498-218. Waiting 1.0s before retry 1/5\n",
      "Progress: 640/667 processed (640 successful, 0 failed) - Est. 10.7 min elapsed\n",
      "Processing [641/667] Lens ID: 148-411-415-090-903\n",
      "Processing [642/667] Lens ID: 146-218-171-797-816\n",
      "Rate limited for Lens ID 146-218-171-797-816. Waiting 1.0s before retry 1/5\n",
      "Processing [643/667] Lens ID: 139-953-245-967-126\n",
      "Rate limited for Lens ID 139-953-245-967-126. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 139-953-245-967-126. Waiting 2.0s before retry 2/5\n",
      "Processing [644/667] Lens ID: 004-109-111-936-894\n",
      "Processing [645/667] Lens ID: 151-552-527-834-02X\n",
      "Rate limited for Lens ID 151-552-527-834-02X. Waiting 1.0s before retry 1/5\n",
      "Processing [646/667] Lens ID: 141-548-245-375-641\n",
      "Rate limited for Lens ID 141-548-245-375-641. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 141-548-245-375-641. Waiting 2.0s before retry 2/5\n",
      "Processing [647/667] Lens ID: 153-365-008-723-60X\n",
      "Processing [648/667] Lens ID: 163-654-550-199-573\n",
      "Rate limited for Lens ID 163-654-550-199-573. Waiting 1.0s before retry 1/5\n",
      "Processing [649/667] Lens ID: 111-777-939-519-68X\n",
      "Rate limited for Lens ID 111-777-939-519-68X. Waiting 1.0s before retry 1/5\n",
      "Processing [650/667] Lens ID: 133-605-858-278-383\n",
      "Rate limited for Lens ID 133-605-858-278-383. Waiting 1.0s before retry 1/5\n",
      "Progress: 650/667 processed (650 successful, 0 failed) - Est. 10.8 min elapsed\n",
      "Processing [651/667] Lens ID: 141-468-546-111-359\n",
      "Rate limited for Lens ID 141-468-546-111-359. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 141-468-546-111-359. Waiting 2.0s before retry 2/5\n",
      "Processing [652/667] Lens ID: 104-523-406-829-585\n",
      "Processing [653/667] Lens ID: 057-954-266-808-003\n",
      "Rate limited for Lens ID 057-954-266-808-003. Waiting 1.0s before retry 1/5\n",
      "Rate limited for Lens ID 057-954-266-808-003. Waiting 2.0s before retry 2/5\n",
      "Processing [654/667] Lens ID: 151-861-053-049-204\n",
      "Processing [655/667] Lens ID: 124-397-744-900-883\n",
      "Processing [656/667] Lens ID: 069-816-774-283-119\n",
      "Processing [657/667] Lens ID: 059-243-980-923-078\n",
      "Processing [658/667] Lens ID: 164-453-592-705-759\n",
      "Processing [659/667] Lens ID: 110-205-395-356-308\n",
      "Processing [660/667] Lens ID: 039-521-201-094-074\n",
      "Progress: 660/667 processed (660 successful, 0 failed) - Est. 11.0 min elapsed\n",
      "Processing [661/667] Lens ID: 105-569-879-718-236\n",
      "Processing [662/667] Lens ID: 120-447-377-906-059\n",
      "Processing [663/667] Lens ID: 125-854-461-858-061\n",
      "Processing [664/667] Lens ID: 064-061-744-662-703\n",
      "Processing [665/667] Lens ID: 116-864-765-045-29X\n",
      "Processing [666/667] Lens ID: 056-572-752-855-040\n",
      "Processing [667/667] Lens ID: 147-161-553-114-808\n",
      "\n",
      "--- Processing Complete ---\n",
      "Total patents processed: 667\n",
      "Successful extractions: 667\n",
      "Failed extractions: 0\n",
      "JSONL file saved as: 'patents_data.jsonl'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "API_TOKEN = \"QKooD88tnEbnJNTnQVnyHOia3y8aBhHPw18hOq9R9NC2Eo2yW9kx\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Lens.org API URL\n",
    "api_url = \"https://api.lens.org/patent/search\"\n",
    "\n",
    "def extract_patent_data(lens_id: str, api_url: str, headers: Dict[str, str], max_retries: int = 5) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Extracts the required patent attributes for a given Lens ID with retry logic for rate limiting.\n",
    "    Returns a dictionary with the extracted data or None if unsuccessful after all retries.\n",
    "    \"\"\"\n",
    "    query_body = {\n",
    "        \"query\": {\n",
    "            \"terms\": {\n",
    "                \"lens_id\": [lens_id]\n",
    "            }\n",
    "        },\n",
    "        \"size\": 1\n",
    "    }\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(api_url, headers=headers, data=json.dumps(query_body))\n",
    "            \n",
    "            # Handle 429 (Too Many Requests) with exponential backoff\n",
    "            if response.status_code == 429:\n",
    "                wait_time = (2 ** attempt) * 1.0  # 1s, 2s, 4s, 8s, 16s\n",
    "                print(f\"Rate limited for Lens ID {lens_id}. Waiting {wait_time}s before retry {attempt + 1}/{max_retries}\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "            \n",
    "            response.raise_for_status()\n",
    "\n",
    "            data = response.json()\n",
    "            if not data or \"data\" not in data or len(data[\"data\"]) == 0:\n",
    "                print(f\"Warning: No patent found for Lens ID {lens_id}\")\n",
    "                return None\n",
    "\n",
    "            patent = data[\"data\"][0]\n",
    "            \n",
    "            # Extract all the required attributes (based on your original checking logic)\n",
    "            extracted_data = {\n",
    "                \"lens_id\": patent.get(\"lens_id\"),\n",
    "                \"jurisdiction\": patent.get(\"jurisdiction\"),\n",
    "                \"date_published\": patent.get(\"date_published\"),\n",
    "                \"biblio\": patent.get(\"biblio\"),\n",
    "                \"legal_status\": patent.get(\"legal_status\"),\n",
    "                \"abstract\": patent.get(\"abstract\"),\n",
    "                \"claims\": patent.get(\"claims\"),\n",
    "                \"description\": patent.get(\"description\"),\n",
    "                \"families\": patent.get(\"families\")\n",
    "            }\n",
    "            \n",
    "            return extracted_data\n",
    "\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if response.status_code == 429:\n",
    "                # This will be handled by the 429 check above\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"HTTP Error for Lens ID {lens_id}: {e}\")\n",
    "                return None\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"API Request Failed for Lens ID {lens_id} (attempt {attempt + 1}): {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = (2 ** attempt) * 0.5\n",
    "                print(f\"Retrying in {wait_time}s...\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "            return None\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Failed to decode JSON response for Lens ID {lens_id}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error for Lens ID {lens_id}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    print(f\"Failed to extract data for Lens ID {lens_id} after {max_retries} attempts\")\n",
    "    return None\n",
    "\n",
    "def create_jsonl_from_patents(csv_file_path: str, output_file: str, api_url: str, headers: Dict[str, str], delay: float = 0.1):\n",
    "    \"\"\"\n",
    "    Reads patent Lens IDs from CSV and creates a JSONL file with extracted patent data.\n",
    "    \n",
    "    Args:\n",
    "        csv_file_path: Path to the CSV file containing Lens IDs\n",
    "        output_file: Path for the output JSONL file\n",
    "        api_url: API endpoint URL\n",
    "        headers: Request headers\n",
    "        delay: Delay between API requests to avoid rate limiting\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        if 'Lens ID' not in df.columns:\n",
    "            print(f\"Error: '{csv_file_path}' does not contain a 'Lens ID' column.\")\n",
    "            return\n",
    "        \n",
    "        lens_ids = df['Lens ID'].tolist()\n",
    "        total_patents = len(lens_ids)\n",
    "        \n",
    "        print(f\"Processing {total_patents} patents from '{csv_file_path}'...\")\n",
    "        print(f\"Output will be saved to '{output_file}'\")\n",
    "        \n",
    "        successful_extractions = 0\n",
    "        failed_extractions = 0\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            for i, lens_id in enumerate(lens_ids, 1):\n",
    "                print(f\"Processing [{i}/{total_patents}] Lens ID: {lens_id}\")\n",
    "                \n",
    "                patent_data = extract_patent_data(str(lens_id), api_url, headers)\n",
    "                \n",
    "                if patent_data:\n",
    "                    # Write as a single line in JSONL format\n",
    "                    json.dump(patent_data, f, ensure_ascii=False)\n",
    "                    f.write('\\n')\n",
    "                    successful_extractions += 1\n",
    "                else:\n",
    "                    failed_extractions += 1\n",
    "                \n",
    "                # Add delay to avoid overwhelming the API - IMPORTANT!\n",
    "                if delay > 0:\n",
    "                    time.sleep(delay)\n",
    "                    \n",
    "                # Show progress more frequently to know it's still working\n",
    "                if i % 10 == 0:\n",
    "                    elapsed_time = (i * delay) / 60  # Rough estimate in minutes\n",
    "                    print(f\"Progress: {i}/{total_patents} processed ({successful_extractions} successful, {failed_extractions} failed) - Est. {elapsed_time:.1f} min elapsed\")\n",
    "        \n",
    "        print(f\"\\n--- Processing Complete ---\")\n",
    "        print(f\"Total patents processed: {total_patents}\")\n",
    "        print(f\"Successful extractions: {successful_extractions}\")\n",
    "        print(f\"Failed extractions: {failed_extractions}\")\n",
    "        print(f\"JSONL file saved as: '{output_file}'\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{csv_file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# --- Main script execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file_path = 'lens-export.csv'\n",
    "    output_file = 'patents_data.jsonl'\n",
    "    \n",
    "    # Make sure to set your API URL\n",
    "    if api_url == \"YOUR_API_URL_HERE\":\n",
    "        print(\"Error: Please set the correct API URL in the 'api_url' variable.\")\n",
    "    else:\n",
    "        create_jsonl_from_patents(\n",
    "            csv_file_path=csv_file_path,\n",
    "            output_file=output_file,\n",
    "            api_url=api_url,\n",
    "            headers=headers,\n",
    "                            delay=1.0  # 1 second delay between requests to avoid rate limiting\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a36846a-ffa3-448c-a152-bf69d83c903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Patent 1 ---\n",
      "lens_id: <class 'str'>\n",
      "jurisdiction: <class 'str'>\n",
      "date_published: <class 'str'>\n",
      "biblio: <class 'dict'>\n",
      "legal_status: <class 'dict'>\n",
      "abstract: <class 'list'>\n",
      "claims: <class 'list'>\n",
      "description: <class 'dict'>\n",
      "families: <class 'dict'>\n",
      "\n",
      "--- Patent 2 ---\n",
      "lens_id: <class 'str'>\n",
      "jurisdiction: <class 'str'>\n",
      "date_published: <class 'str'>\n",
      "biblio: <class 'dict'>\n",
      "legal_status: <class 'dict'>\n",
      "abstract: <class 'list'>\n",
      "claims: <class 'list'>\n",
      "description: <class 'dict'>\n",
      "families: <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Path to your JSONL file\n",
    "file_path = 'patents_data.jsonl'\n",
    "\n",
    "# Read just the first 2 lines to inspect structure\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    for i in range(2):\n",
    "        line = f.readline()\n",
    "        data = json.loads(line)\n",
    "        print(f\"\\n--- Patent {i+1} ---\")\n",
    "        for key in data:\n",
    "            print(f\"{key}: {type(data[key])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79745326-7d01-4820-a063-8c9ac6136691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys:\n",
      "lens_id: <class 'str'>\n",
      "jurisdiction: <class 'str'>\n",
      "date_published: <class 'str'>\n",
      "biblio: <class 'dict'>\n",
      "legal_status: <class 'dict'>\n",
      "abstract: <class 'list'>\n",
      "claims: <class 'list'>\n",
      "description: <class 'dict'>\n",
      "families: <class 'dict'>\n",
      "\n",
      "--- Exploring `biblio` ---\n",
      "biblio.publication_reference: <class 'dict'>\n",
      "biblio.publication_reference.jurisdiction: <class 'str'>\n",
      "biblio.publication_reference.doc_number: <class 'str'>\n",
      "biblio.publication_reference.kind: <class 'str'>\n",
      "biblio.publication_reference.date: <class 'str'>\n",
      "biblio.application_reference: <class 'dict'>\n",
      "biblio.application_reference.jurisdiction: <class 'str'>\n",
      "biblio.application_reference.doc_number: <class 'str'>\n",
      "biblio.application_reference.kind: <class 'str'>\n",
      "biblio.application_reference.date: <class 'str'>\n",
      "biblio.priority_claims: <class 'dict'>\n",
      "biblio.priority_claims.claims: <class 'list'>\n",
      "biblio.priority_claims.earliest_claim: <class 'dict'>\n",
      "biblio.priority_claims.earliest_claim.date: <class 'str'>\n",
      "biblio.invention_title: <class 'list'>\n",
      "biblio.parties: <class 'dict'>\n",
      "biblio.parties.examiners: <class 'dict'>\n",
      "biblio.parties.examiners.primary_examiner: <class 'dict'>\n",
      "biblio.parties.examiners.primary_examiner.department: <class 'str'>\n",
      "biblio.parties.examiners.primary_examiner.extracted_name: <class 'dict'>\n",
      "biblio.parties.examiners.primary_examiner.extracted_name.value: <class 'str'>\n",
      "biblio.parties.applicants: <class 'list'>\n",
      "biblio.parties.inventors: <class 'list'>\n",
      "biblio.parties.agents: <class 'list'>\n",
      "biblio.classifications_ipcr: <class 'dict'>\n",
      "biblio.classifications_ipcr.classifications: <class 'list'>\n",
      "biblio.classifications_cpc: <class 'dict'>\n",
      "biblio.classifications_cpc.classifications: <class 'list'>\n",
      "biblio.references_cited: <class 'dict'>\n",
      "biblio.references_cited.citations: <class 'list'>\n",
      "biblio.references_cited.patent_count: <class 'int'>\n",
      "biblio.cited_by: <class 'dict'>\n",
      "\n",
      "--- Exploring `legal_status` ---\n",
      "legal_status.granted: <class 'bool'>\n",
      "legal_status.grant_date: <class 'str'>\n",
      "legal_status.anticipated_term_date: <class 'str'>\n",
      "legal_status.has_disclaimer: <class 'bool'>\n",
      "legal_status.calculation_log: <class 'list'>\n",
      "legal_status.patent_status: <class 'str'>\n",
      "\n",
      "--- Exploring `description` ---\n",
      "description.text: <class 'str'>\n",
      "description.lang: <class 'str'>\n",
      "\n",
      "--- Exploring `families` ---\n",
      "families.simple_family: <class 'dict'>\n",
      "families.simple_family.members: <class 'list'>\n",
      "families.simple_family.size: <class 'int'>\n",
      "families.extended_family: <class 'dict'>\n",
      "families.extended_family.members: <class 'list'>\n",
      "families.extended_family.size: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def explore_nested_keys(d, prefix=''):\n",
    "    \"\"\"Recursively prints keys and types in nested dictionaries.\"\"\"\n",
    "    for k, v in d.items():\n",
    "        full_key = f\"{prefix}.{k}\" if prefix else k\n",
    "        print(f\"{full_key}: {type(v)}\")\n",
    "        if isinstance(v, dict):\n",
    "            explore_nested_keys(v, prefix=full_key)\n",
    "\n",
    "# Read one patent for full inspection\n",
    "file_path = 'patents_data.jsonl'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    line = f.readline()\n",
    "    data = json.loads(line)\n",
    "\n",
    "print(\"Top-level keys:\")\n",
    "for key in data:\n",
    "    print(f\"{key}: {type(data[key])}\")\n",
    "\n",
    "# Now expand the nested dictionary fields\n",
    "print(\"\\n--- Exploring `biblio` ---\")\n",
    "explore_nested_keys(data['biblio'], prefix='biblio')\n",
    "\n",
    "print(\"\\n--- Exploring `legal_status` ---\")\n",
    "explore_nested_keys(data['legal_status'], prefix='legal_status')\n",
    "\n",
    "print(\"\\n--- Exploring `description` ---\")\n",
    "explore_nested_keys(data['description'], prefix='description')\n",
    "\n",
    "print(\"\\n--- Exploring `families` ---\")\n",
    "explore_nested_keys(data['families'], prefix='families')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6be478e1-0204-4092-af10-44eae9dcde3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = 'patents_data.jsonl'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        patent = json.loads(line)\n",
    "        biblio = patent.get('biblio', {})\n",
    "        priority_claims = biblio.get('priority_claims', [])\n",
    "\n",
    "        if isinstance(priority_claims, list) and priority_claims:\n",
    "            print(\"🔍 Keys in one priority_claims entry:\")\n",
    "            for key in priority_claims[0]:\n",
    "                print(f\"- {key}\")\n",
    "            break  # Only inspect the first valid example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e087c52-071e-4747-a587-bd36bf0db3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priority claims keys:\n",
      "['claims', 'earliest_claim']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the first line to get the structure and keys\n",
    "with open('patents_data.jsonl', 'r') as file:\n",
    "    first_line = file.readline().strip()\n",
    "    data = json.loads(first_line)\n",
    "    \n",
    "    # Navigate to priority_claims\n",
    "    if 'biblio' in data and 'priority_claims' in data['biblio']:\n",
    "        priority_claims = data['biblio']['priority_claims']\n",
    "        \n",
    "        if isinstance(priority_claims, dict):\n",
    "            print(\"Priority claims keys:\")\n",
    "            print(list(priority_claims.keys()))\n",
    "        elif isinstance(priority_claims, list):\n",
    "            print(f\"Priority claims is a list with {len(priority_claims)} items\")\n",
    "            if priority_claims and isinstance(priority_claims[0], dict):\n",
    "                print(\"Keys in priority claims items:\")\n",
    "                print(list(priority_claims[0].keys()))\n",
    "        else:\n",
    "            print(f\"Priority claims is of type: {type(priority_claims)}\")\n",
    "    else:\n",
    "        print(\"Priority claims not found in the expected structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36e64bca-6e87-4712-afdf-6a1669d1de9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified file saved as 'patents_data_modified.jsonl'\n",
      "Original 'claims' key removed from biblio -> priority_claims\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the original file and write to a new file without the claims\n",
    "with open('patents_data.jsonl', 'r') as infile, open('patents_data_modified.jsonl', 'w') as outfile:\n",
    "    for line in infile:\n",
    "        data = json.loads(line.strip())\n",
    "        \n",
    "        # Navigate to priority_claims and remove claims if it exists\n",
    "        if 'biblio' in data and 'priority_claims' in data['biblio']:\n",
    "            priority_claims = data['biblio']['priority_claims']\n",
    "            \n",
    "            if isinstance(priority_claims, dict) and 'claims' in priority_claims:\n",
    "                del priority_claims['claims']\n",
    "            elif isinstance(priority_claims, list):\n",
    "                for item in priority_claims:\n",
    "                    if isinstance(item, dict) and 'claims' in item:\n",
    "                        del item['claims']\n",
    "        \n",
    "        # Write the modified data to the new file\n",
    "        outfile.write(json.dumps(data) + '\\n')\n",
    "\n",
    "print(\"Modified file saved as 'patents_data_modified.jsonl'\")\n",
    "print(\"Original 'claims' key removed from biblio -> priority_claims\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26a45c80-6d83-4440-b4cb-458c6ea43022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 667 lines\n",
      "Removed 'jurisdiction' key from patents_data.jsonl\n",
      "File has been updated in place\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read all lines, modify them, and write back\n",
    "modified_lines = []\n",
    "\n",
    "with open('patents_data.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())\n",
    "        \n",
    "        # Remove jurisdiction key if it exists\n",
    "        if 'jurisdiction' in data:\n",
    "            del data['jurisdiction']\n",
    "        \n",
    "        modified_lines.append(json.dumps(data))\n",
    "\n",
    "# Write back to the same file\n",
    "with open('patents_data.jsonl', 'w') as file:\n",
    "    for line in modified_lines:\n",
    "        file.write(line + '\\n')\n",
    "\n",
    "print(f\"Processed {len(modified_lines)} lines\")\n",
    "print(\"Removed 'jurisdiction' key from patents_data.jsonl\")\n",
    "print(\"File has been updated in place\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44a1faa5-b2db-4852-aaec-19a7d223a1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPLETE STRUCTURE OF patents_data.jsonl ===\n",
      "\n",
      "ALL KEYS AND NESTED PATHS:\n",
      "--------------------------------------------------\n",
      "abstract                                           [list]\n",
      "abstract[0].lang                                   [str]\n",
      "abstract[0].text                                   [str]\n",
      "biblio                                             [dict]\n",
      "biblio.classifications_cpc                         [dict]\n",
      "biblio.classifications_cpc.classifications         [list]\n",
      "biblio.classifications_cpc.classifications[0].classification_symbol_position [str]\n",
      "biblio.classifications_cpc.classifications[0].classification_value [str]\n",
      "biblio.classifications_cpc.classifications[0].symbol [str]\n",
      "biblio.invention_title                             [list]\n",
      "biblio.invention_title[0].lang                     [str]\n",
      "biblio.invention_title[0].text                     [str]\n",
      "biblio.priority_claims                             [dict]\n",
      "biblio.priority_claims.earliest_claim              [dict]\n",
      "biblio.priority_claims.earliest_claim.date         [str]\n",
      "claims                                             [list]\n",
      "claims[0].claims                                   [list]\n",
      "claims[0].claims[0].claim_text                     [list]\n",
      "claims[0].lang                                     [str]\n",
      "date_published                                     [str]\n",
      "description                                        [dict]\n",
      "description.lang                                   [str]\n",
      "description.text                                   [str]\n",
      "families                                           [dict]\n",
      "families.extended_family                           [dict]\n",
      "families.extended_family.members                   [list]\n",
      "families.extended_family.members[0].document_id    [dict]\n",
      "families.extended_family.members[0].document_id.date [str]\n",
      "families.extended_family.members[0].document_id.doc_number [str]\n",
      "families.extended_family.members[0].document_id.jurisdiction [str]\n",
      "families.extended_family.members[0].document_id.kind [str]\n",
      "families.extended_family.members[0].lens_id        [str]\n",
      "families.extended_family.size                      [int]\n",
      "families.simple_family                             [dict]\n",
      "families.simple_family.members                     [list]\n",
      "families.simple_family.members[0].document_id      [dict]\n",
      "families.simple_family.members[0].document_id.date [str]\n",
      "families.simple_family.members[0].document_id.doc_number [str]\n",
      "families.simple_family.members[0].document_id.jurisdiction [str]\n",
      "families.simple_family.members[0].document_id.kind [str]\n",
      "families.simple_family.members[0].lens_id          [str]\n",
      "families.simple_family.size                        [int]\n",
      "legal_status                                       [dict]\n",
      "legal_status.anticipated_term_date                 [str]\n",
      "legal_status.calculation_log                       [list]\n",
      "legal_status.grant_date                            [str]\n",
      "legal_status.granted                               [bool]\n",
      "legal_status.has_disclaimer                        [bool]\n",
      "legal_status.patent_status                         [str]\n",
      "lens_id                                            [str]\n",
      "\n",
      "Total number of unique paths: 50\n",
      "\n",
      "=== GROUPED BY TOP-LEVEL KEYS ===\n",
      "\n",
      "ABSTRACT:\n",
      "  (root)                                   [list]\n",
      "      [0].lang                                 [str]\n",
      "      [0].text                                 [str]\n",
      "\n",
      "BIBLIO:\n",
      "  (root)                                   [dict]\n",
      "    classifications_cpc                      [dict]\n",
      "      classifications_cpc.classifications      [list]\n",
      "          classifications_cpc.classifications[0].classification_symbol_position [str]\n",
      "          classifications_cpc.classifications[0].classification_value [str]\n",
      "          classifications_cpc.classifications[0].symbol [str]\n",
      "    invention_title                          [list]\n",
      "        invention_title[0].lang                  [str]\n",
      "        invention_title[0].text                  [str]\n",
      "    priority_claims                          [dict]\n",
      "      priority_claims.earliest_claim           [dict]\n",
      "        priority_claims.earliest_claim.date      [str]\n",
      "\n",
      "CLAIMS:\n",
      "  (root)                                   [list]\n",
      "      [0].                                     [list]\n",
      "          [0].[0].claim_text                       [list]\n",
      "      [0].lang                                 [str]\n",
      "\n",
      "DATE_PUBLISHED:\n",
      "  (root)                                   [str]\n",
      "\n",
      "DESCRIPTION:\n",
      "  (root)                                   [dict]\n",
      "    lang                                     [str]\n",
      "    text                                     [str]\n",
      "\n",
      "FAMILIES:\n",
      "  (root)                                   [dict]\n",
      "    extended_family                          [dict]\n",
      "      extended_family.members                  [list]\n",
      "          extended_family.members[0].document_id   [dict]\n",
      "            extended_family.members[0].document_id.date [str]\n",
      "            extended_family.members[0].document_id.doc_number [str]\n",
      "            extended_family.members[0].document_id.jurisdiction [str]\n",
      "            extended_family.members[0].document_id.kind [str]\n",
      "          extended_family.members[0].lens_id       [str]\n",
      "      extended_family.size                     [int]\n",
      "    simple_family                            [dict]\n",
      "      simple_family.members                    [list]\n",
      "          simple_family.members[0].document_id     [dict]\n",
      "            simple_family.members[0].document_id.date [str]\n",
      "            simple_family.members[0].document_id.doc_number [str]\n",
      "            simple_family.members[0].document_id.jurisdiction [str]\n",
      "            simple_family.members[0].document_id.kind [str]\n",
      "          simple_family.members[0].lens_id         [str]\n",
      "      simple_family.size                       [int]\n",
      "\n",
      "LEGAL_STATUS:\n",
      "  (root)                                   [dict]\n",
      "    anticipated_term_date                    [str]\n",
      "    calculation_log                          [list]\n",
      "    grant_date                               [str]\n",
      "    granted                                  [bool]\n",
      "    has_disclaimer                           [bool]\n",
      "    patent_status                            [str]\n",
      "\n",
      "LENS_ID:\n",
      "  (root)                                   [str]\n",
      "\n",
      "=== CHECKING CONSISTENCY ACROSS MULTIPLE LINES ===\n",
      "⚠ Found 2 different structures in the first 5 lines\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def explore_structure(obj, path=\"\", all_paths=None):\n",
    "    \"\"\"Recursively explore the structure of a JSON object\"\"\"\n",
    "    if all_paths is None:\n",
    "        all_paths = set()\n",
    "    \n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            current_path = f\"{path}.{key}\" if path else key\n",
    "            all_paths.add(current_path)\n",
    "            \n",
    "            # Recursively explore nested structures\n",
    "            if isinstance(value, (dict, list)):\n",
    "                explore_structure(value, current_path, all_paths)\n",
    "    \n",
    "    elif isinstance(obj, list) and obj:\n",
    "        # For lists, explore the first item to understand the structure\n",
    "        current_path = f\"{path}[0]\" if path else \"[0]\"\n",
    "        explore_structure(obj[0], current_path, all_paths)\n",
    "    \n",
    "    return all_paths\n",
    "\n",
    "def get_value_types(obj, path=\"\", type_info=None):\n",
    "    \"\"\"Get type information for each path\"\"\"\n",
    "    if type_info is None:\n",
    "        type_info = {}\n",
    "    \n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            current_path = f\"{path}.{key}\" if path else key\n",
    "            type_info[current_path] = type(value).__name__\n",
    "            \n",
    "            if isinstance(value, (dict, list)):\n",
    "                get_value_types(value, current_path, type_info)\n",
    "    \n",
    "    elif isinstance(obj, list) and obj:\n",
    "        current_path = f\"{path}[0]\" if path else \"[0]\"\n",
    "        type_info[current_path] = f\"list[{type(obj[0]).__name__}]\"\n",
    "        get_value_types(obj[0], current_path, type_info)\n",
    "    \n",
    "    return type_info\n",
    "\n",
    "# Read the first line to understand the structure\n",
    "with open('patents_data.jsonl', 'r') as file:\n",
    "    first_line = file.readline().strip()\n",
    "    data = json.loads(first_line)\n",
    "\n",
    "print(\"=== COMPLETE STRUCTURE OF patents_data.jsonl ===\\n\")\n",
    "\n",
    "# Get all paths and their types\n",
    "all_paths = explore_structure(data)\n",
    "type_info = get_value_types(data)\n",
    "\n",
    "# Sort paths for better readability\n",
    "sorted_paths = sorted(all_paths)\n",
    "\n",
    "print(\"ALL KEYS AND NESTED PATHS:\")\n",
    "print(\"-\" * 50)\n",
    "for path in sorted_paths:\n",
    "    data_type = type_info.get(path, \"unknown\")\n",
    "    print(f\"{path:<50} [{data_type}]\")\n",
    "\n",
    "print(f\"\\nTotal number of unique paths: {len(sorted_paths)}\")\n",
    "\n",
    "# Group by top-level keys\n",
    "print(\"\\n=== GROUPED BY TOP-LEVEL KEYS ===\")\n",
    "top_level_groups = defaultdict(list)\n",
    "for path in sorted_paths:\n",
    "    top_key = path.split('.')[0].split('[')[0]\n",
    "    top_level_groups[top_key].append(path)\n",
    "\n",
    "for top_key, paths in sorted(top_level_groups.items()):\n",
    "    print(f\"\\n{top_key.upper()}:\")\n",
    "    for path in paths:\n",
    "        data_type = type_info.get(path, \"unknown\")\n",
    "        indent = \"  \" * (path.count('.') + path.count('['))\n",
    "        display_path = path.replace(f\"{top_key}.\", \"\").replace(f\"{top_key}\", \"\")\n",
    "        if display_path.startswith('.'):\n",
    "            display_path = display_path[1:]\n",
    "        print(f\"  {indent}{display_path or '(root)':<40} [{data_type}]\")\n",
    "\n",
    "# Sample a few more lines to check consistency\n",
    "print(\"\\n=== CHECKING CONSISTENCY ACROSS MULTIPLE LINES ===\")\n",
    "unique_structures = set()\n",
    "with open('patents_data.jsonl', 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if i >= 5:  # Check first 5 lines\n",
    "            break\n",
    "        data = json.loads(line.strip())\n",
    "        paths = tuple(sorted(explore_structure(data)))\n",
    "        unique_structures.add(paths)\n",
    "\n",
    "if len(unique_structures) == 1:\n",
    "    print(\"✓ All checked lines have the same structure\")\n",
    "else:\n",
    "    print(f\"⚠ Found {len(unique_structures)} different structures in the first 5 lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fef2828c-2d2d-4a9b-aef2-688df07de8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DETAILED STRUCTURE COMPARISON ===\n",
      "\n",
      "Line 1: 50 total paths\n",
      "Line 2: 49 total paths\n",
      "Line 3: 50 total paths\n",
      "Line 4: 49 total paths\n",
      "Line 5: 49 total paths\n",
      "Line 6: 49 total paths\n",
      "Line 7: 49 total paths\n",
      "Line 8: 49 total paths\n",
      "Line 9: 49 total paths\n",
      "Line 10: 49 total paths\n",
      "\n",
      "Found 10 unique structures:\n",
      "Structure 1: Lines [1] (1 lines)\n",
      "Structure 2: Lines [2] (1 lines)\n",
      "Structure 3: Lines [3] (1 lines)\n",
      "Structure 4: Lines [4] (1 lines)\n",
      "Structure 5: Lines [5] (1 lines)\n",
      "Structure 6: Lines [6] (1 lines)\n",
      "Structure 7: Lines [7] (1 lines)\n",
      "Structure 8: Lines [8] (1 lines)\n",
      "Structure 9: Lines [9] (1 lines)\n",
      "Structure 10: Lines [10] (1 lines)\n",
      "\n",
      "=== COMPARING DIFFERENT STRUCTURES ===\n",
      "\n",
      "Structure 1 vs Structure 2:\n",
      "Structure 1 has 50 paths\n",
      "Structure 2 has 49 paths\n",
      "\n",
      "Paths ONLY in Structure 1:\n",
      "  - legal_status.has_disclaimer\n",
      "\n",
      "Structure 1 vs Structure 3:\n",
      "Structure 1 has 50 paths\n",
      "Structure 3 has 50 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 1 vs Structure 4:\n",
      "Structure 1 has 50 paths\n",
      "Structure 4 has 49 paths\n",
      "\n",
      "Paths ONLY in Structure 1:\n",
      "  - legal_status.has_disclaimer\n",
      "\n",
      "Structure 1 vs Structure 5:\n",
      "Structure 1 has 50 paths\n",
      "Structure 5 has 49 paths\n",
      "\n",
      "Paths ONLY in Structure 1:\n",
      "  - legal_status.has_disclaimer\n",
      "\n",
      "Structure 1 vs Structure 6:\n",
      "Structure 1 has 50 paths\n",
      "Structure 6 has 49 paths\n",
      "\n",
      "Paths ONLY in Structure 1:\n",
      "  - legal_status.has_disclaimer\n",
      "\n",
      "Structure 1 vs Structure 7:\n",
      "Structure 1 has 50 paths\n",
      "Structure 7 has 49 paths\n",
      "\n",
      "Paths ONLY in Structure 1:\n",
      "  - legal_status.has_disclaimer\n",
      "\n",
      "Structure 1 vs Structure 8:\n",
      "Structure 1 has 50 paths\n",
      "Structure 8 has 49 paths\n",
      "\n",
      "Paths ONLY in Structure 1:\n",
      "  - legal_status.has_disclaimer\n",
      "\n",
      "Structure 1 vs Structure 9:\n",
      "Structure 1 has 50 paths\n",
      "Structure 9 has 49 paths\n",
      "\n",
      "Paths ONLY in Structure 1:\n",
      "  - legal_status.has_disclaimer\n",
      "\n",
      "Structure 1 vs Structure 10:\n",
      "Structure 1 has 50 paths\n",
      "Structure 10 has 49 paths\n",
      "\n",
      "Paths ONLY in Structure 1:\n",
      "  - legal_status.has_disclaimer\n",
      "\n",
      "Structure 2 vs Structure 3:\n",
      "Structure 2 has 49 paths\n",
      "Structure 3 has 50 paths\n",
      "\n",
      "Paths ONLY in Structure 3:\n",
      "  - legal_status.has_disclaimer\n",
      "\n",
      "Structure 2 vs Structure 4:\n",
      "Structure 2 has 49 paths\n",
      "Structure 4 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 2 vs Structure 5:\n",
      "Structure 2 has 49 paths\n",
      "Structure 5 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 2 vs Structure 6:\n",
      "Structure 2 has 49 paths\n",
      "Structure 6 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 2 vs Structure 7:\n",
      "Structure 2 has 49 paths\n",
      "Structure 7 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 2 vs Structure 8:\n",
      "Structure 2 has 49 paths\n",
      "Structure 8 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 2 vs Structure 9:\n",
      "Structure 2 has 49 paths\n",
      "Structure 9 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 2 vs Structure 10:\n",
      "Structure 2 has 49 paths\n",
      "Structure 10 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 3 vs Structure 4:\n",
      "Structure 3 has 50 paths\n",
      "Structure 4 has 49 paths\n",
      "\n",
      "Paths ONLY in Structure 3:\n",
      "  - legal_status.has_disclaimer\n",
      "\n",
      "Structure 3 vs Structure 5:\n",
      "Structure 3 has 50 paths\n",
      "Structure 5 has 49 paths\n",
      "\n",
      "Paths ONLY in Structure 3:\n",
      "  - legal_status.has_disclaimer\n",
      "\n",
      "Structure 3 vs Structure 6:\n",
      "Structure 3 has 50 paths\n",
      "Structure 6 has 49 paths\n",
      "\n",
      "Paths ONLY in Structure 3:\n",
      "  - legal_status.has_disclaimer\n",
      "\n",
      "Structure 3 vs Structure 7:\n",
      "Structure 3 has 50 paths\n",
      "Structure 7 has 49 paths\n",
      "\n",
      "Paths ONLY in Structure 3:\n",
      "  - legal_status.has_disclaimer\n",
      "\n",
      "Structure 3 vs Structure 8:\n",
      "Structure 3 has 50 paths\n",
      "Structure 8 has 49 paths\n",
      "\n",
      "Paths ONLY in Structure 3:\n",
      "  - legal_status.has_disclaimer\n",
      "\n",
      "Structure 3 vs Structure 9:\n",
      "Structure 3 has 50 paths\n",
      "Structure 9 has 49 paths\n",
      "\n",
      "Paths ONLY in Structure 3:\n",
      "  - legal_status.has_disclaimer\n",
      "\n",
      "Structure 3 vs Structure 10:\n",
      "Structure 3 has 50 paths\n",
      "Structure 10 has 49 paths\n",
      "\n",
      "Paths ONLY in Structure 3:\n",
      "  - legal_status.has_disclaimer\n",
      "\n",
      "Structure 4 vs Structure 5:\n",
      "Structure 4 has 49 paths\n",
      "Structure 5 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 4 vs Structure 6:\n",
      "Structure 4 has 49 paths\n",
      "Structure 6 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 4 vs Structure 7:\n",
      "Structure 4 has 49 paths\n",
      "Structure 7 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 4 vs Structure 8:\n",
      "Structure 4 has 49 paths\n",
      "Structure 8 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 4 vs Structure 9:\n",
      "Structure 4 has 49 paths\n",
      "Structure 9 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 4 vs Structure 10:\n",
      "Structure 4 has 49 paths\n",
      "Structure 10 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 5 vs Structure 6:\n",
      "Structure 5 has 49 paths\n",
      "Structure 6 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 5 vs Structure 7:\n",
      "Structure 5 has 49 paths\n",
      "Structure 7 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 5 vs Structure 8:\n",
      "Structure 5 has 49 paths\n",
      "Structure 8 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 5 vs Structure 9:\n",
      "Structure 5 has 49 paths\n",
      "Structure 9 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 5 vs Structure 10:\n",
      "Structure 5 has 49 paths\n",
      "Structure 10 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 6 vs Structure 7:\n",
      "Structure 6 has 49 paths\n",
      "Structure 7 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 6 vs Structure 8:\n",
      "Structure 6 has 49 paths\n",
      "Structure 8 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 6 vs Structure 9:\n",
      "Structure 6 has 49 paths\n",
      "Structure 9 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 6 vs Structure 10:\n",
      "Structure 6 has 49 paths\n",
      "Structure 10 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 7 vs Structure 8:\n",
      "Structure 7 has 49 paths\n",
      "Structure 8 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 7 vs Structure 9:\n",
      "Structure 7 has 49 paths\n",
      "Structure 9 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 7 vs Structure 10:\n",
      "Structure 7 has 49 paths\n",
      "Structure 10 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 8 vs Structure 9:\n",
      "Structure 8 has 49 paths\n",
      "Structure 9 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 8 vs Structure 10:\n",
      "Structure 8 has 49 paths\n",
      "Structure 10 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "Structure 9 vs Structure 10:\n",
      "Structure 9 has 49 paths\n",
      "Structure 10 has 49 paths\n",
      "  → Structures are identical!\n",
      "\n",
      "=== CHECKING FOR EMPTY/NULL VALUES ===\n",
      "\n",
      "Line 1 - Empty/null values:\n",
      "  None found\n",
      "\n",
      "Line 2 - Empty/null values:\n",
      "  None found\n",
      "\n",
      "Line 3 - Empty/null values:\n",
      "  None found\n",
      "\n",
      "Line 4 - Empty/null values:\n",
      "  None found\n",
      "\n",
      "Line 5 - Empty/null values:\n",
      "  None found\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6f5985d-122a-4866-a637-62d90220d3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPLETE STRUCTURE OF patents_data.jsonl ===\n",
      "\n",
      "ALL KEYS AND NESTED PATHS:\n",
      "--------------------------------------------------\n",
      "abstract                                           [list]\n",
      "abstract[0].lang                                   [str]\n",
      "abstract[0].text                                   [str]\n",
      "biblio                                             [dict]\n",
      "biblio.application_reference                       [dict]\n",
      "biblio.application_reference.date                  [str]\n",
      "biblio.application_reference.doc_number            [str]\n",
      "biblio.application_reference.jurisdiction          [str]\n",
      "biblio.application_reference.kind                  [str]\n",
      "biblio.cited_by                                    [dict]\n",
      "biblio.classifications_cpc                         [dict]\n",
      "biblio.classifications_cpc.classifications         [list]\n",
      "biblio.classifications_cpc.classifications[0].classification_symbol_position [str]\n",
      "biblio.classifications_cpc.classifications[0].classification_value [str]\n",
      "biblio.classifications_cpc.classifications[0].symbol [str]\n",
      "biblio.classifications_ipcr                        [dict]\n",
      "biblio.classifications_ipcr.classifications        [list]\n",
      "biblio.classifications_ipcr.classifications[0].classification_symbol_position [str]\n",
      "biblio.classifications_ipcr.classifications[0].classification_value [str]\n",
      "biblio.classifications_ipcr.classifications[0].symbol [str]\n",
      "biblio.invention_title                             [list]\n",
      "biblio.invention_title[0].lang                     [str]\n",
      "biblio.invention_title[0].text                     [str]\n",
      "biblio.parties                                     [dict]\n",
      "biblio.parties.agents                              [list]\n",
      "biblio.parties.agents[0].extracted_name            [dict]\n",
      "biblio.parties.agents[0].extracted_name.value      [str]\n",
      "biblio.parties.applicants                          [list]\n",
      "biblio.parties.applicants[0].extracted_name        [dict]\n",
      "biblio.parties.applicants[0].extracted_name.value  [str]\n",
      "biblio.parties.applicants[0].residence             [str]\n",
      "biblio.parties.examiners                           [dict]\n",
      "biblio.parties.examiners.primary_examiner          [dict]\n",
      "biblio.parties.examiners.primary_examiner.department [str]\n",
      "biblio.parties.examiners.primary_examiner.extracted_name [dict]\n",
      "biblio.parties.examiners.primary_examiner.extracted_name.value [str]\n",
      "biblio.parties.inventors                           [list]\n",
      "biblio.parties.inventors[0].extracted_name         [dict]\n",
      "biblio.parties.inventors[0].extracted_name.value   [str]\n",
      "biblio.parties.inventors[0].residence              [str]\n",
      "biblio.parties.inventors[0].sequence               [int]\n",
      "biblio.priority_claims                             [dict]\n",
      "biblio.priority_claims.claims                      [list]\n",
      "biblio.priority_claims.claims[0].date              [str]\n",
      "biblio.priority_claims.claims[0].doc_number        [str]\n",
      "biblio.priority_claims.claims[0].jurisdiction      [str]\n",
      "biblio.priority_claims.claims[0].kind              [str]\n",
      "biblio.priority_claims.claims[0].sequence          [int]\n",
      "biblio.priority_claims.earliest_claim              [dict]\n",
      "biblio.priority_claims.earliest_claim.date         [str]\n",
      "biblio.publication_reference                       [dict]\n",
      "biblio.publication_reference.date                  [str]\n",
      "biblio.publication_reference.doc_number            [str]\n",
      "biblio.publication_reference.jurisdiction          [str]\n",
      "biblio.publication_reference.kind                  [str]\n",
      "biblio.references_cited                            [dict]\n",
      "biblio.references_cited.citations                  [list]\n",
      "biblio.references_cited.citations[0].cited_phase   [str]\n",
      "biblio.references_cited.citations[0].patcit        [dict]\n",
      "biblio.references_cited.citations[0].patcit.document_id [dict]\n",
      "biblio.references_cited.citations[0].patcit.document_id.date [str]\n",
      "biblio.references_cited.citations[0].patcit.document_id.doc_number [str]\n",
      "biblio.references_cited.citations[0].patcit.document_id.jurisdiction [str]\n",
      "biblio.references_cited.citations[0].patcit.document_id.kind [str]\n",
      "biblio.references_cited.citations[0].patcit.lens_id [str]\n",
      "biblio.references_cited.citations[0].sequence      [int]\n",
      "biblio.references_cited.patent_count               [int]\n",
      "claims                                             [list]\n",
      "claims[0].claims                                   [list]\n",
      "claims[0].claims[0].claim_text                     [list]\n",
      "claims[0].lang                                     [str]\n",
      "date_published                                     [str]\n",
      "description                                        [dict]\n",
      "description.lang                                   [str]\n",
      "description.text                                   [str]\n",
      "families                                           [dict]\n",
      "families.extended_family                           [dict]\n",
      "families.extended_family.members                   [list]\n",
      "families.extended_family.members[0].document_id    [dict]\n",
      "families.extended_family.members[0].document_id.date [str]\n",
      "families.extended_family.members[0].document_id.doc_number [str]\n",
      "families.extended_family.members[0].document_id.jurisdiction [str]\n",
      "families.extended_family.members[0].document_id.kind [str]\n",
      "families.extended_family.members[0].lens_id        [str]\n",
      "families.extended_family.size                      [int]\n",
      "families.simple_family                             [dict]\n",
      "families.simple_family.members                     [list]\n",
      "families.simple_family.members[0].document_id      [dict]\n",
      "families.simple_family.members[0].document_id.date [str]\n",
      "families.simple_family.members[0].document_id.doc_number [str]\n",
      "families.simple_family.members[0].document_id.jurisdiction [str]\n",
      "families.simple_family.members[0].document_id.kind [str]\n",
      "families.simple_family.members[0].lens_id          [str]\n",
      "families.simple_family.size                        [int]\n",
      "jurisdiction                                       [str]\n",
      "legal_status                                       [dict]\n",
      "legal_status.anticipated_term_date                 [str]\n",
      "legal_status.calculation_log                       [list]\n",
      "legal_status.grant_date                            [str]\n",
      "legal_status.granted                               [bool]\n",
      "legal_status.has_disclaimer                        [bool]\n",
      "legal_status.patent_status                         [str]\n",
      "lens_id                                            [str]\n",
      "\n",
      "Total number of unique paths: 103\n",
      "\n",
      "=== GROUPED BY TOP-LEVEL KEYS ===\n",
      "\n",
      "ABSTRACT:\n",
      "  (root)                                   [list]\n",
      "      [0].lang                                 [str]\n",
      "      [0].text                                 [str]\n",
      "\n",
      "BIBLIO:\n",
      "  (root)                                   [dict]\n",
      "    application_reference                    [dict]\n",
      "      application_reference.date               [str]\n",
      "      application_reference.doc_number         [str]\n",
      "      application_reference.jurisdiction       [str]\n",
      "      application_reference.kind               [str]\n",
      "    cited_by                                 [dict]\n",
      "    classifications_cpc                      [dict]\n",
      "      classifications_cpc.classifications      [list]\n",
      "          classifications_cpc.classifications[0].classification_symbol_position [str]\n",
      "          classifications_cpc.classifications[0].classification_value [str]\n",
      "          classifications_cpc.classifications[0].symbol [str]\n",
      "    classifications_ipcr                     [dict]\n",
      "      classifications_ipcr.classifications     [list]\n",
      "          classifications_ipcr.classifications[0].classification_symbol_position [str]\n",
      "          classifications_ipcr.classifications[0].classification_value [str]\n",
      "          classifications_ipcr.classifications[0].symbol [str]\n",
      "    invention_title                          [list]\n",
      "        invention_title[0].lang                  [str]\n",
      "        invention_title[0].text                  [str]\n",
      "    parties                                  [dict]\n",
      "      parties.agents                           [list]\n",
      "          parties.agents[0].extracted_name         [dict]\n",
      "            parties.agents[0].extracted_name.value   [str]\n",
      "      parties.applicants                       [list]\n",
      "          parties.applicants[0].extracted_name     [dict]\n",
      "            parties.applicants[0].extracted_name.value [str]\n",
      "          parties.applicants[0].residence          [str]\n",
      "      parties.examiners                        [dict]\n",
      "        parties.examiners.primary_examiner       [dict]\n",
      "          parties.examiners.primary_examiner.department [str]\n",
      "          parties.examiners.primary_examiner.extracted_name [dict]\n",
      "            parties.examiners.primary_examiner.extracted_name.value [str]\n",
      "      parties.inventors                        [list]\n",
      "          parties.inventors[0].extracted_name      [dict]\n",
      "            parties.inventors[0].extracted_name.value [str]\n",
      "          parties.inventors[0].residence           [str]\n",
      "          parties.inventors[0].sequence            [int]\n",
      "    priority_claims                          [dict]\n",
      "      priority_claims.claims                   [list]\n",
      "          priority_claims.claims[0].date           [str]\n",
      "          priority_claims.claims[0].doc_number     [str]\n",
      "          priority_claims.claims[0].jurisdiction   [str]\n",
      "          priority_claims.claims[0].kind           [str]\n",
      "          priority_claims.claims[0].sequence       [int]\n",
      "      priority_claims.earliest_claim           [dict]\n",
      "        priority_claims.earliest_claim.date      [str]\n",
      "    publication_reference                    [dict]\n",
      "      publication_reference.date               [str]\n",
      "      publication_reference.doc_number         [str]\n",
      "      publication_reference.jurisdiction       [str]\n",
      "      publication_reference.kind               [str]\n",
      "    references_cited                         [dict]\n",
      "      references_cited.citations               [list]\n",
      "          references_cited.citations[0].cited_phase [str]\n",
      "          references_cited.citations[0].patcit     [dict]\n",
      "            references_cited.citations[0].patcit.document_id [dict]\n",
      "              references_cited.citations[0].patcit.document_id.date [str]\n",
      "              references_cited.citations[0].patcit.document_id.doc_number [str]\n",
      "              references_cited.citations[0].patcit.document_id.jurisdiction [str]\n",
      "              references_cited.citations[0].patcit.document_id.kind [str]\n",
      "            references_cited.citations[0].patcit.lens_id [str]\n",
      "          references_cited.citations[0].sequence   [int]\n",
      "      references_cited.patent_count            [int]\n",
      "\n",
      "CLAIMS:\n",
      "  (root)                                   [list]\n",
      "      [0].                                     [list]\n",
      "          [0].[0].claim_text                       [list]\n",
      "      [0].lang                                 [str]\n",
      "\n",
      "DATE_PUBLISHED:\n",
      "  (root)                                   [str]\n",
      "\n",
      "DESCRIPTION:\n",
      "  (root)                                   [dict]\n",
      "    lang                                     [str]\n",
      "    text                                     [str]\n",
      "\n",
      "FAMILIES:\n",
      "  (root)                                   [dict]\n",
      "    extended_family                          [dict]\n",
      "      extended_family.members                  [list]\n",
      "          extended_family.members[0].document_id   [dict]\n",
      "            extended_family.members[0].document_id.date [str]\n",
      "            extended_family.members[0].document_id.doc_number [str]\n",
      "            extended_family.members[0].document_id.jurisdiction [str]\n",
      "            extended_family.members[0].document_id.kind [str]\n",
      "          extended_family.members[0].lens_id       [str]\n",
      "      extended_family.size                     [int]\n",
      "    simple_family                            [dict]\n",
      "      simple_family.members                    [list]\n",
      "          simple_family.members[0].document_id     [dict]\n",
      "            simple_family.members[0].document_id.date [str]\n",
      "            simple_family.members[0].document_id.doc_number [str]\n",
      "            simple_family.members[0].document_id.jurisdiction [str]\n",
      "            simple_family.members[0].document_id.kind [str]\n",
      "          simple_family.members[0].lens_id         [str]\n",
      "      simple_family.size                       [int]\n",
      "\n",
      "JURISDICTION:\n",
      "  (root)                                   [str]\n",
      "\n",
      "LEGAL_STATUS:\n",
      "  (root)                                   [dict]\n",
      "    anticipated_term_date                    [str]\n",
      "    calculation_log                          [list]\n",
      "    grant_date                               [str]\n",
      "    granted                                  [bool]\n",
      "    has_disclaimer                           [bool]\n",
      "    patent_status                            [str]\n",
      "\n",
      "LENS_ID:\n",
      "  (root)                                   [str]\n",
      "\n",
      "=== CHECKING CONSISTENCY ACROSS MULTIPLE LINES ===\n",
      "⚠ Found 5 different structures in the first 5 lines\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def explore_structure(obj, path=\"\", all_paths=None):\n",
    "    \"\"\"Recursively explore the structure of a JSON object\"\"\"\n",
    "    if all_paths is None:\n",
    "        all_paths = set()\n",
    "    \n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            current_path = f\"{path}.{key}\" if path else key\n",
    "            all_paths.add(current_path)\n",
    "            \n",
    "            # Recursively explore nested structures\n",
    "            if isinstance(value, (dict, list)):\n",
    "                explore_structure(value, current_path, all_paths)\n",
    "    \n",
    "    elif isinstance(obj, list) and obj:\n",
    "        # For lists, explore the first item to understand the structure\n",
    "        current_path = f\"{path}[0]\" if path else \"[0]\"\n",
    "        explore_structure(obj[0], current_path, all_paths)\n",
    "    \n",
    "    return all_paths\n",
    "\n",
    "def get_value_types(obj, path=\"\", type_info=None):\n",
    "    \"\"\"Get type information for each path\"\"\"\n",
    "    if type_info is None:\n",
    "        type_info = {}\n",
    "    \n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            current_path = f\"{path}.{key}\" if path else key\n",
    "            type_info[current_path] = type(value).__name__\n",
    "            \n",
    "            if isinstance(value, (dict, list)):\n",
    "                get_value_types(value, current_path, type_info)\n",
    "    \n",
    "    elif isinstance(obj, list) and obj:\n",
    "        current_path = f\"{path}[0]\" if path else \"[0]\"\n",
    "        type_info[current_path] = f\"list[{type(obj[0]).__name__}]\"\n",
    "        get_value_types(obj[0], current_path, type_info)\n",
    "    \n",
    "    return type_info\n",
    "\n",
    "# Read the first line to understand the structure\n",
    "with open('patents_data - Copy.jsonl', 'r', encoding='utf-8') as file:\n",
    "    first_line = file.readline().strip()\n",
    "    data = json.loads(first_line)\n",
    "\n",
    "print(\"=== COMPLETE STRUCTURE OF patents_data.jsonl ===\\n\")\n",
    "\n",
    "# Get all paths and their types\n",
    "all_paths = explore_structure(data)\n",
    "type_info = get_value_types(data)\n",
    "\n",
    "# Sort paths for better readability\n",
    "sorted_paths = sorted(all_paths)\n",
    "\n",
    "print(\"ALL KEYS AND NESTED PATHS:\")\n",
    "print(\"-\" * 50)\n",
    "for path in sorted_paths:\n",
    "    data_type = type_info.get(path, \"unknown\")\n",
    "    print(f\"{path:<50} [{data_type}]\")\n",
    "\n",
    "print(f\"\\nTotal number of unique paths: {len(sorted_paths)}\")\n",
    "\n",
    "# Group by top-level keys\n",
    "print(\"\\n=== GROUPED BY TOP-LEVEL KEYS ===\")\n",
    "top_level_groups = defaultdict(list)\n",
    "for path in sorted_paths:\n",
    "    top_key = path.split('.')[0].split('[')[0]\n",
    "    top_level_groups[top_key].append(path)\n",
    "\n",
    "for top_key, paths in sorted(top_level_groups.items()):\n",
    "    print(f\"\\n{top_key.upper()}:\")\n",
    "    for path in paths:\n",
    "        data_type = type_info.get(path, \"unknown\")\n",
    "        indent = \"  \" * (path.count('.') + path.count('['))\n",
    "        display_path = path.replace(f\"{top_key}.\", \"\").replace(f\"{top_key}\", \"\")\n",
    "        if display_path.startswith('.'):\n",
    "            display_path = display_path[1:]\n",
    "        print(f\"  {indent}{display_path or '(root)':<40} [{data_type}]\")\n",
    "\n",
    "# Sample a few more lines to check consistency\n",
    "print(\"\\n=== CHECKING CONSISTENCY ACROSS MULTIPLE LINES ===\")\n",
    "unique_structures = set()\n",
    "with open('patents_data - Copy.jsonl', 'r', encoding='utf-8') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if i >= 5:  # Check first 5 lines\n",
    "            break\n",
    "        data = json.loads(line.strip())\n",
    "        paths = tuple(sorted(explore_structure(data)))\n",
    "        unique_structures.add(paths)\n",
    "\n",
    "if len(unique_structures) == 1:\n",
    "    print(\"✓ All checked lines have the same structure\")\n",
    "else:\n",
    "    print(f\"⚠ Found {len(unique_structures)} different structures in the first 5 lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2144be8c-3f66-4202-bd1f-b6e632ee59fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1: Copied parties key\n",
      "Line 2: Copied parties key\n",
      "Line 3: Copied parties key\n",
      "Line 4: Copied parties key\n",
      "Line 5: Copied parties key\n",
      "Line 6: Copied parties key\n",
      "Line 7: Copied parties key\n",
      "Line 8: Copied parties key\n",
      "Line 9: Copied parties key\n",
      "Line 10: Copied parties key\n",
      "Line 11: Copied parties key\n",
      "Line 12: Copied parties key\n",
      "Line 13: Copied parties key\n",
      "Line 14: Copied parties key\n",
      "Line 15: Copied parties key\n",
      "Line 16: Copied parties key\n",
      "Line 17: Copied parties key\n",
      "Line 18: Copied parties key\n",
      "Line 19: Copied parties key\n",
      "Line 20: Copied parties key\n",
      "Line 21: Copied parties key\n",
      "Line 22: Copied parties key\n",
      "Line 23: Copied parties key\n",
      "Line 24: Copied parties key\n",
      "Line 25: Copied parties key\n",
      "Line 26: Copied parties key\n",
      "Line 27: Copied parties key\n",
      "Line 28: Copied parties key\n",
      "Line 29: Copied parties key\n",
      "Line 30: Copied parties key\n",
      "Line 31: Copied parties key\n",
      "Line 32: Copied parties key\n",
      "Line 33: Copied parties key\n",
      "Line 34: Copied parties key\n",
      "Line 35: Copied parties key\n",
      "Line 36: Copied parties key\n",
      "Line 37: Copied parties key\n",
      "Line 38: Copied parties key\n",
      "Line 39: Copied parties key\n",
      "Line 40: Copied parties key\n",
      "Line 41: Copied parties key\n",
      "Line 42: Copied parties key\n",
      "Line 43: Copied parties key\n",
      "Line 44: Copied parties key\n",
      "Line 45: Copied parties key\n",
      "Line 46: Copied parties key\n",
      "Line 47: Copied parties key\n",
      "Line 48: Copied parties key\n",
      "Line 49: Copied parties key\n",
      "Line 50: Copied parties key\n",
      "Line 51: Copied parties key\n",
      "Line 52: Copied parties key\n",
      "Line 53: Copied parties key\n",
      "Line 54: Copied parties key\n",
      "Line 55: Copied parties key\n",
      "Line 56: Copied parties key\n",
      "Line 57: Copied parties key\n",
      "Line 58: Copied parties key\n",
      "Line 59: Copied parties key\n",
      "Line 60: Copied parties key\n",
      "Line 61: Copied parties key\n",
      "Line 62: Copied parties key\n",
      "Line 63: Copied parties key\n",
      "Line 64: Copied parties key\n",
      "Line 65: Copied parties key\n",
      "Line 66: Copied parties key\n",
      "Line 67: Copied parties key\n",
      "Line 68: Copied parties key\n",
      "Line 69: Copied parties key\n",
      "Line 70: Copied parties key\n",
      "Line 71: Copied parties key\n",
      "Line 72: Copied parties key\n",
      "Line 73: Copied parties key\n",
      "Line 74: Copied parties key\n",
      "Line 75: Copied parties key\n",
      "Line 76: Copied parties key\n",
      "Line 77: Copied parties key\n",
      "Line 78: Copied parties key\n",
      "Line 79: Copied parties key\n",
      "Line 80: Copied parties key\n",
      "Line 81: Copied parties key\n",
      "Line 82: Copied parties key\n",
      "Line 83: Copied parties key\n",
      "Line 84: Copied parties key\n",
      "Line 85: Copied parties key\n",
      "Line 86: Copied parties key\n",
      "Line 87: Copied parties key\n",
      "Line 88: Copied parties key\n",
      "Line 89: Copied parties key\n",
      "Line 90: Copied parties key\n",
      "Line 91: Copied parties key\n",
      "Line 92: Copied parties key\n",
      "Line 93: Copied parties key\n",
      "Line 94: Copied parties key\n",
      "Line 95: Copied parties key\n",
      "Line 96: Copied parties key\n",
      "Line 97: Copied parties key\n",
      "Line 98: Copied parties key\n",
      "Line 99: Copied parties key\n",
      "Line 100: Copied parties key\n",
      "Line 101: Copied parties key\n",
      "Line 102: Copied parties key\n",
      "Line 103: Copied parties key\n",
      "Line 104: Copied parties key\n",
      "Line 105: Copied parties key\n",
      "Line 106: Copied parties key\n",
      "Line 107: Copied parties key\n",
      "Line 108: Copied parties key\n",
      "Line 109: Copied parties key\n",
      "Line 110: Copied parties key\n",
      "Line 111: Copied parties key\n",
      "Line 112: Copied parties key\n",
      "Line 113: Copied parties key\n",
      "Line 114: Copied parties key\n",
      "Line 115: Copied parties key\n",
      "Line 116: Copied parties key\n",
      "Line 117: Copied parties key\n",
      "Line 118: Copied parties key\n",
      "Line 119: Copied parties key\n",
      "Line 120: Copied parties key\n",
      "Line 121: Copied parties key\n",
      "Line 122: Copied parties key\n",
      "Line 123: Copied parties key\n",
      "Line 124: Copied parties key\n",
      "Line 125: Copied parties key\n",
      "Line 126: Copied parties key\n",
      "Line 127: Copied parties key\n",
      "Line 128: Copied parties key\n",
      "Line 129: Copied parties key\n",
      "Line 130: Copied parties key\n",
      "Line 131: Copied parties key\n",
      "Line 132: Copied parties key\n",
      "Line 133: Copied parties key\n",
      "Line 134: Copied parties key\n",
      "Line 135: Copied parties key\n",
      "Line 136: Copied parties key\n",
      "Line 137: Copied parties key\n",
      "Line 138: Copied parties key\n",
      "Line 139: Copied parties key\n",
      "Line 140: Copied parties key\n",
      "Line 141: Copied parties key\n",
      "Line 142: Copied parties key\n",
      "Line 143: Copied parties key\n",
      "Line 144: Copied parties key\n",
      "Line 145: Copied parties key\n",
      "Line 146: Copied parties key\n",
      "Line 147: Copied parties key\n",
      "Line 148: Copied parties key\n",
      "Line 149: Copied parties key\n",
      "Line 150: Copied parties key\n",
      "Line 151: Copied parties key\n",
      "Line 152: Copied parties key\n",
      "Line 153: Copied parties key\n",
      "Line 154: Copied parties key\n",
      "Line 155: Copied parties key\n",
      "Line 156: Copied parties key\n",
      "Line 157: Copied parties key\n",
      "Line 158: Copied parties key\n",
      "Line 159: Copied parties key\n",
      "Line 160: Copied parties key\n",
      "Line 161: Copied parties key\n",
      "Line 162: Copied parties key\n",
      "Line 163: Copied parties key\n",
      "Line 164: Copied parties key\n",
      "Line 165: Copied parties key\n",
      "Line 166: Copied parties key\n",
      "Line 167: Copied parties key\n",
      "Line 168: Copied parties key\n",
      "Line 169: Copied parties key\n",
      "Line 170: Copied parties key\n",
      "Line 171: Copied parties key\n",
      "Line 172: Copied parties key\n",
      "Line 173: Copied parties key\n",
      "Line 174: Copied parties key\n",
      "Line 175: Copied parties key\n",
      "Line 176: Copied parties key\n",
      "Line 177: Copied parties key\n",
      "Line 178: Copied parties key\n",
      "Line 179: Copied parties key\n",
      "Line 180: Copied parties key\n",
      "Line 181: Copied parties key\n",
      "Line 182: Copied parties key\n",
      "Line 183: Copied parties key\n",
      "Line 184: Copied parties key\n",
      "Line 185: Copied parties key\n",
      "Line 186: Copied parties key\n",
      "Line 187: Copied parties key\n",
      "Line 188: Copied parties key\n",
      "Line 189: Copied parties key\n",
      "Line 190: Copied parties key\n",
      "Line 191: Copied parties key\n",
      "Line 192: Copied parties key\n",
      "Line 193: Copied parties key\n",
      "Line 194: Copied parties key\n",
      "Line 195: Copied parties key\n",
      "Line 196: Copied parties key\n",
      "Line 197: Copied parties key\n",
      "Line 198: Copied parties key\n",
      "Line 199: Copied parties key\n",
      "Line 200: Copied parties key\n",
      "Line 201: Copied parties key\n",
      "Line 202: Copied parties key\n",
      "Line 203: Copied parties key\n",
      "Line 204: Copied parties key\n",
      "Line 205: Copied parties key\n",
      "Line 206: Copied parties key\n",
      "Line 207: Copied parties key\n",
      "Line 208: Copied parties key\n",
      "Line 209: Copied parties key\n",
      "Line 210: Copied parties key\n",
      "Line 211: Copied parties key\n",
      "Line 212: Copied parties key\n",
      "Line 213: Copied parties key\n",
      "Line 214: Copied parties key\n",
      "Line 215: Copied parties key\n",
      "Line 216: Copied parties key\n",
      "Line 217: Copied parties key\n",
      "Line 218: Copied parties key\n",
      "Line 219: Copied parties key\n",
      "Line 220: Copied parties key\n",
      "Line 221: Copied parties key\n",
      "Line 222: Copied parties key\n",
      "Line 223: Copied parties key\n",
      "Line 224: Copied parties key\n",
      "Line 225: Copied parties key\n",
      "Line 226: Copied parties key\n",
      "Line 227: Copied parties key\n",
      "Line 228: Copied parties key\n",
      "Line 229: Copied parties key\n",
      "Line 230: Copied parties key\n",
      "Line 231: Copied parties key\n",
      "Line 232: Copied parties key\n",
      "Line 233: Copied parties key\n",
      "Line 234: Copied parties key\n",
      "Line 235: Copied parties key\n",
      "Line 236: Copied parties key\n",
      "Line 237: Copied parties key\n",
      "Line 238: Copied parties key\n",
      "Line 239: Copied parties key\n",
      "Line 240: Copied parties key\n",
      "Line 241: Copied parties key\n",
      "Line 242: Copied parties key\n",
      "Line 243: Copied parties key\n",
      "Line 244: Copied parties key\n",
      "Line 245: Copied parties key\n",
      "Line 246: Copied parties key\n",
      "Line 247: Copied parties key\n",
      "Line 248: Copied parties key\n",
      "Line 249: Copied parties key\n",
      "Line 250: Copied parties key\n",
      "Line 251: Copied parties key\n",
      "Line 252: Copied parties key\n",
      "Line 253: Copied parties key\n",
      "Line 254: Copied parties key\n",
      "Line 255: Copied parties key\n",
      "Line 256: Copied parties key\n",
      "Line 257: Copied parties key\n",
      "Line 258: Copied parties key\n",
      "Line 259: Copied parties key\n",
      "Line 260: Copied parties key\n",
      "Line 261: Copied parties key\n",
      "Line 262: Copied parties key\n",
      "Line 263: Copied parties key\n",
      "Line 264: Copied parties key\n",
      "Line 265: Copied parties key\n",
      "Line 266: Copied parties key\n",
      "Line 267: Copied parties key\n",
      "Line 268: Copied parties key\n",
      "Line 269: Copied parties key\n",
      "Line 270: Copied parties key\n",
      "Line 271: Copied parties key\n",
      "Line 272: Copied parties key\n",
      "Line 273: Copied parties key\n",
      "Line 274: Copied parties key\n",
      "Line 275: Copied parties key\n",
      "Line 276: Copied parties key\n",
      "Line 277: Copied parties key\n",
      "Line 278: Copied parties key\n",
      "Line 279: Copied parties key\n",
      "Line 280: Copied parties key\n",
      "Line 281: Copied parties key\n",
      "Line 282: Copied parties key\n",
      "Line 283: Copied parties key\n",
      "Line 284: Copied parties key\n",
      "Line 285: Copied parties key\n",
      "Line 286: Copied parties key\n",
      "Line 287: Copied parties key\n",
      "Line 288: Copied parties key\n",
      "Line 289: Copied parties key\n",
      "Line 290: Copied parties key\n",
      "Line 291: Copied parties key\n",
      "Line 292: Copied parties key\n",
      "Line 293: Copied parties key\n",
      "Line 294: Copied parties key\n",
      "Line 295: Copied parties key\n",
      "Line 296: Copied parties key\n",
      "Line 297: Copied parties key\n",
      "Line 298: Copied parties key\n",
      "Line 299: Copied parties key\n",
      "Line 300: Copied parties key\n",
      "Line 301: Copied parties key\n",
      "Line 302: Copied parties key\n",
      "Line 303: Copied parties key\n",
      "Line 304: Copied parties key\n",
      "Line 305: Copied parties key\n",
      "Line 306: Copied parties key\n",
      "Line 307: Copied parties key\n",
      "Line 308: Copied parties key\n",
      "Line 309: Copied parties key\n",
      "Line 310: Copied parties key\n",
      "Line 311: Copied parties key\n",
      "Line 312: Copied parties key\n",
      "Line 313: Copied parties key\n",
      "Line 314: Copied parties key\n",
      "Line 315: Copied parties key\n",
      "Line 316: Copied parties key\n",
      "Line 317: Copied parties key\n",
      "Line 318: Copied parties key\n",
      "Line 319: Copied parties key\n",
      "Line 320: Copied parties key\n",
      "Line 321: Copied parties key\n",
      "Line 322: Copied parties key\n",
      "Line 323: Copied parties key\n",
      "Line 324: Copied parties key\n",
      "Line 325: Copied parties key\n",
      "Line 326: Copied parties key\n",
      "Line 327: Copied parties key\n",
      "Line 328: Copied parties key\n",
      "Line 329: Copied parties key\n",
      "Line 330: Copied parties key\n",
      "Line 331: Copied parties key\n",
      "Line 332: Copied parties key\n",
      "Line 333: Copied parties key\n",
      "Line 334: Copied parties key\n",
      "Line 335: Copied parties key\n",
      "Line 336: Copied parties key\n",
      "Line 337: Copied parties key\n",
      "Line 338: Copied parties key\n",
      "Line 339: Copied parties key\n",
      "Line 340: Copied parties key\n",
      "Line 341: Copied parties key\n",
      "Line 342: Copied parties key\n",
      "Line 343: Copied parties key\n",
      "Line 344: Copied parties key\n",
      "Line 345: Copied parties key\n",
      "Line 346: Copied parties key\n",
      "Line 347: Copied parties key\n",
      "Line 348: Copied parties key\n",
      "Line 349: Copied parties key\n",
      "Line 350: Copied parties key\n",
      "Line 351: Copied parties key\n",
      "Line 352: Copied parties key\n",
      "Line 353: Copied parties key\n",
      "Line 354: Copied parties key\n",
      "Line 355: Copied parties key\n",
      "Line 356: Copied parties key\n",
      "Line 357: Copied parties key\n",
      "Line 358: Copied parties key\n",
      "Line 359: Copied parties key\n",
      "Line 360: Copied parties key\n",
      "Line 361: Copied parties key\n",
      "Line 362: Copied parties key\n",
      "Line 363: Copied parties key\n",
      "Line 364: Copied parties key\n",
      "Line 365: Copied parties key\n",
      "Line 366: Copied parties key\n",
      "Line 367: Copied parties key\n",
      "Line 368: Copied parties key\n",
      "Line 369: Copied parties key\n",
      "Line 370: Copied parties key\n",
      "Line 371: Copied parties key\n",
      "Line 372: Copied parties key\n",
      "Line 373: Copied parties key\n",
      "Line 374: Copied parties key\n",
      "Line 375: Copied parties key\n",
      "Line 376: Copied parties key\n",
      "Line 377: Copied parties key\n",
      "Line 378: Copied parties key\n",
      "Line 379: Copied parties key\n",
      "Line 380: Copied parties key\n",
      "Line 381: Copied parties key\n",
      "Line 382: Copied parties key\n",
      "Line 383: Copied parties key\n",
      "Line 384: Copied parties key\n",
      "Line 385: Copied parties key\n",
      "Line 386: Copied parties key\n",
      "Line 387: Copied parties key\n",
      "Line 388: Copied parties key\n",
      "Line 389: Copied parties key\n",
      "Line 390: Copied parties key\n",
      "Line 391: Copied parties key\n",
      "Line 392: Copied parties key\n",
      "Line 393: Copied parties key\n",
      "Line 394: Copied parties key\n",
      "Line 395: Copied parties key\n",
      "Line 396: Copied parties key\n",
      "Line 397: Copied parties key\n",
      "Line 398: Copied parties key\n",
      "Line 399: Copied parties key\n",
      "Line 400: Copied parties key\n",
      "Line 401: Copied parties key\n",
      "Line 402: Copied parties key\n",
      "Line 403: Copied parties key\n",
      "Line 404: Copied parties key\n",
      "Line 405: Copied parties key\n",
      "Line 406: Copied parties key\n",
      "Line 407: Copied parties key\n",
      "Line 408: Copied parties key\n",
      "Line 409: Copied parties key\n",
      "Line 410: Copied parties key\n",
      "Line 411: Copied parties key\n",
      "Line 412: Copied parties key\n",
      "Line 413: Copied parties key\n",
      "Line 414: Copied parties key\n",
      "Line 415: Copied parties key\n",
      "Line 416: Copied parties key\n",
      "Line 417: Copied parties key\n",
      "Line 418: Copied parties key\n",
      "Line 419: Copied parties key\n",
      "Line 420: Copied parties key\n",
      "Line 421: Copied parties key\n",
      "Line 422: Copied parties key\n",
      "Line 423: Copied parties key\n",
      "Line 424: Copied parties key\n",
      "Line 425: Copied parties key\n",
      "Line 426: Copied parties key\n",
      "Line 427: Copied parties key\n",
      "Line 428: Copied parties key\n",
      "Line 429: Copied parties key\n",
      "Line 430: Copied parties key\n",
      "Line 431: Copied parties key\n",
      "Line 432: Copied parties key\n",
      "Line 433: Copied parties key\n",
      "Line 434: Copied parties key\n",
      "Line 435: Copied parties key\n",
      "Line 436: Copied parties key\n",
      "Line 437: Copied parties key\n",
      "Line 438: Copied parties key\n",
      "Line 439: Copied parties key\n",
      "Line 440: Copied parties key\n",
      "Line 441: Copied parties key\n",
      "Line 442: Copied parties key\n",
      "Line 443: Copied parties key\n",
      "Line 444: Copied parties key\n",
      "Line 445: Copied parties key\n",
      "Line 446: Copied parties key\n",
      "Line 447: Copied parties key\n",
      "Line 448: Copied parties key\n",
      "Line 449: Copied parties key\n",
      "Line 450: Copied parties key\n",
      "Line 451: Copied parties key\n",
      "Line 452: Copied parties key\n",
      "Line 453: Copied parties key\n",
      "Line 454: Copied parties key\n",
      "Line 455: Copied parties key\n",
      "Line 456: Copied parties key\n",
      "Line 457: Copied parties key\n",
      "Line 458: Copied parties key\n",
      "Line 459: Copied parties key\n",
      "Line 460: Copied parties key\n",
      "Line 461: Copied parties key\n",
      "Line 462: Copied parties key\n",
      "Line 463: Copied parties key\n",
      "Line 464: Copied parties key\n",
      "Line 465: Copied parties key\n",
      "Line 466: Copied parties key\n",
      "Line 467: Copied parties key\n",
      "Line 468: Copied parties key\n",
      "Line 469: Copied parties key\n",
      "Line 470: Copied parties key\n",
      "Line 471: Copied parties key\n",
      "Line 472: Copied parties key\n",
      "Line 473: Copied parties key\n",
      "Line 474: Copied parties key\n",
      "Line 475: Copied parties key\n",
      "Line 476: Copied parties key\n",
      "Line 477: Copied parties key\n",
      "Line 478: Copied parties key\n",
      "Line 479: Copied parties key\n",
      "Line 480: Copied parties key\n",
      "Line 481: Copied parties key\n",
      "Line 482: Copied parties key\n",
      "Line 483: Copied parties key\n",
      "Line 484: Copied parties key\n",
      "Line 485: Copied parties key\n",
      "Line 486: Copied parties key\n",
      "Line 487: Copied parties key\n",
      "Line 488: Copied parties key\n",
      "Line 489: Copied parties key\n",
      "Line 490: Copied parties key\n",
      "Line 491: Copied parties key\n",
      "Line 492: Copied parties key\n",
      "Line 493: Copied parties key\n",
      "Line 494: Copied parties key\n",
      "Line 495: Copied parties key\n",
      "Line 496: Copied parties key\n",
      "Line 497: Copied parties key\n",
      "Line 498: Copied parties key\n",
      "Line 499: Copied parties key\n",
      "Line 500: Copied parties key\n",
      "Line 501: Copied parties key\n",
      "Line 502: Copied parties key\n",
      "Line 503: Copied parties key\n",
      "Line 504: Copied parties key\n",
      "Line 505: Copied parties key\n",
      "Line 506: Copied parties key\n",
      "Line 507: Copied parties key\n",
      "Line 508: Copied parties key\n",
      "Line 509: Copied parties key\n",
      "Line 510: Copied parties key\n",
      "Line 511: Copied parties key\n",
      "Line 512: Copied parties key\n",
      "Line 513: Copied parties key\n",
      "Line 514: Copied parties key\n",
      "Line 515: Copied parties key\n",
      "Line 516: Copied parties key\n",
      "Line 517: Copied parties key\n",
      "Line 518: Copied parties key\n",
      "Line 519: Copied parties key\n",
      "Line 520: Copied parties key\n",
      "Line 521: Copied parties key\n",
      "Line 522: Copied parties key\n",
      "Line 523: Copied parties key\n",
      "Line 524: Copied parties key\n",
      "Line 525: Copied parties key\n",
      "Line 526: Copied parties key\n",
      "Line 527: Copied parties key\n",
      "Line 528: Copied parties key\n",
      "Line 529: Copied parties key\n",
      "Line 530: Copied parties key\n",
      "Line 531: Copied parties key\n",
      "Line 532: Copied parties key\n",
      "Line 533: Copied parties key\n",
      "Line 534: Copied parties key\n",
      "Line 535: Copied parties key\n",
      "Line 536: Copied parties key\n",
      "Line 537: Copied parties key\n",
      "Line 538: Copied parties key\n",
      "Line 539: Copied parties key\n",
      "Line 540: Copied parties key\n",
      "Line 541: Copied parties key\n",
      "Line 542: Copied parties key\n",
      "Line 543: Copied parties key\n",
      "Line 544: Copied parties key\n",
      "Line 545: Copied parties key\n",
      "Line 546: Copied parties key\n",
      "Line 547: Copied parties key\n",
      "Line 548: Copied parties key\n",
      "Line 549: Copied parties key\n",
      "Line 550: Copied parties key\n",
      "Line 551: Copied parties key\n",
      "Line 552: Copied parties key\n",
      "Line 553: Copied parties key\n",
      "Line 554: Copied parties key\n",
      "Line 555: Copied parties key\n",
      "Line 556: Copied parties key\n",
      "Line 557: Copied parties key\n",
      "Line 558: Copied parties key\n",
      "Line 559: Copied parties key\n",
      "Line 560: Copied parties key\n",
      "Line 561: Copied parties key\n",
      "Line 562: Copied parties key\n",
      "Line 563: Copied parties key\n",
      "Line 564: Copied parties key\n",
      "Line 565: Copied parties key\n",
      "Line 566: Copied parties key\n",
      "Line 567: Copied parties key\n",
      "Line 568: Copied parties key\n",
      "Line 569: Copied parties key\n",
      "Line 570: Copied parties key\n",
      "Line 571: Copied parties key\n",
      "Line 572: Copied parties key\n",
      "Line 573: Copied parties key\n",
      "Line 574: Copied parties key\n",
      "Line 575: Copied parties key\n",
      "Line 576: Copied parties key\n",
      "Line 577: Copied parties key\n",
      "Line 578: Copied parties key\n",
      "Line 579: Copied parties key\n",
      "Line 580: Copied parties key\n",
      "Line 581: Copied parties key\n",
      "Line 582: Copied parties key\n",
      "Line 583: Copied parties key\n",
      "Line 584: Copied parties key\n",
      "Line 585: Copied parties key\n",
      "Line 586: Copied parties key\n",
      "Line 587: Copied parties key\n",
      "Line 588: Copied parties key\n",
      "Line 589: Copied parties key\n",
      "Line 590: Copied parties key\n",
      "Line 591: Copied parties key\n",
      "Line 592: Copied parties key\n",
      "Line 593: Copied parties key\n",
      "Line 594: Copied parties key\n",
      "Line 595: Copied parties key\n",
      "Line 596: Copied parties key\n",
      "Line 597: Copied parties key\n",
      "Line 598: Copied parties key\n",
      "Line 599: Copied parties key\n",
      "Line 600: Copied parties key\n",
      "Line 601: Copied parties key\n",
      "Line 602: Copied parties key\n",
      "Line 603: Copied parties key\n",
      "Line 604: Copied parties key\n",
      "Line 605: Copied parties key\n",
      "Line 606: Copied parties key\n",
      "Line 607: Copied parties key\n",
      "Line 608: Copied parties key\n",
      "Line 609: Copied parties key\n",
      "Line 610: Copied parties key\n",
      "Line 611: Copied parties key\n",
      "Line 612: Copied parties key\n",
      "Line 613: Copied parties key\n",
      "Line 614: Copied parties key\n",
      "Line 615: Copied parties key\n",
      "Line 616: Copied parties key\n",
      "Line 617: Copied parties key\n",
      "Line 618: Copied parties key\n",
      "Line 619: Copied parties key\n",
      "Line 620: Copied parties key\n",
      "Line 621: Copied parties key\n",
      "Line 622: Copied parties key\n",
      "Line 623: Copied parties key\n",
      "Line 624: Copied parties key\n",
      "Line 625: Copied parties key\n",
      "Line 626: Copied parties key\n",
      "Line 627: Copied parties key\n",
      "Line 628: Copied parties key\n",
      "Line 629: Copied parties key\n",
      "Line 630: Copied parties key\n",
      "Line 631: Copied parties key\n",
      "Line 632: Copied parties key\n",
      "Line 633: Copied parties key\n",
      "Line 634: Copied parties key\n",
      "Line 635: Copied parties key\n",
      "Line 636: Copied parties key\n",
      "Line 637: Copied parties key\n",
      "Line 638: Copied parties key\n",
      "Line 639: Copied parties key\n",
      "Line 640: Copied parties key\n",
      "Line 641: Copied parties key\n",
      "Line 642: Copied parties key\n",
      "Line 643: Copied parties key\n",
      "Line 644: Copied parties key\n",
      "Line 645: Copied parties key\n",
      "Line 646: Copied parties key\n",
      "Line 647: Copied parties key\n",
      "Line 648: Copied parties key\n",
      "Line 649: Copied parties key\n",
      "Line 650: Copied parties key\n",
      "Line 651: Copied parties key\n",
      "Line 652: Copied parties key\n",
      "Line 653: Copied parties key\n",
      "Line 654: Copied parties key\n",
      "Line 655: Copied parties key\n",
      "Line 656: Copied parties key\n",
      "Line 657: Copied parties key\n",
      "Line 658: Copied parties key\n",
      "Line 659: Copied parties key\n",
      "Line 660: Copied parties key\n",
      "Line 661: Copied parties key\n",
      "Line 662: Copied parties key\n",
      "Line 663: Copied parties key\n",
      "Line 664: Copied parties key\n",
      "Line 665: Copied parties key\n",
      "Line 666: Copied parties key\n",
      "Line 667: Copied parties key\n",
      "\n",
      "Processed 667 lines\n",
      "Added 'parties' key to patents_data.jsonl from patents_data - Copy.jsonl\n",
      "File has been updated successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read both files line by line and merge the parties key\n",
    "modified_lines = []\n",
    "\n",
    "with open('patents_data - Copy.jsonl', 'r', encoding='utf-8') as copy_file, \\\n",
    "     open('patents_data1.jsonl', 'r', encoding='utf-8') as main_file:\n",
    "    \n",
    "    copy_lines = copy_file.readlines()\n",
    "    main_lines = main_file.readlines()\n",
    "    \n",
    "    # Check if files have the same number of lines\n",
    "    if len(copy_lines) != len(main_lines):\n",
    "        print(f\"Warning: Files have different number of lines!\")\n",
    "        print(f\"Copy file: {len(copy_lines)} lines\")\n",
    "        print(f\"Main file: {len(main_lines)} lines\")\n",
    "    \n",
    "    # Process each line pair\n",
    "    for i, (copy_line, main_line) in enumerate(zip(copy_lines, main_lines)):\n",
    "        try:\n",
    "            copy_data = json.loads(copy_line.strip())\n",
    "            main_data = json.loads(main_line.strip())\n",
    "            \n",
    "            # Copy the parties key from copy file to main file\n",
    "            if 'biblio' in copy_data and 'parties' in copy_data['biblio']:\n",
    "                if 'biblio' not in main_data:\n",
    "                    main_data['biblio'] = {}\n",
    "                \n",
    "                main_data['biblio']['parties'] = copy_data['biblio']['parties']\n",
    "                print(f\"Line {i+1}: Copied parties key\")\n",
    "            else:\n",
    "                print(f\"Line {i+1}: No parties key found in copy file\")\n",
    "            \n",
    "            modified_lines.append(json.dumps(main_data))\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Line {i+1}: JSON decode error - {e}\")\n",
    "            # Keep the original line if there's an error\n",
    "            modified_lines.append(main_line.strip())\n",
    "        except Exception as e:\n",
    "            print(f\"Line {i+1}: Error - {e}\")\n",
    "            modified_lines.append(main_line.strip())\n",
    "\n",
    "# Write the modified data back to patents_data.jsonl\n",
    "with open('patents_data1.jsonl', 'w', encoding='utf-8') as file:\n",
    "    for line in modified_lines:\n",
    "        file.write(line + '\\n')\n",
    "\n",
    "print(f\"\\nProcessed {len(modified_lines)} lines\")\n",
    "print(\"Added 'parties' key to patents_data.jsonl from patents_data - Copy.jsonl\")\n",
    "print(\"File has been updated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9d33aab-6ed8-4d1e-b690-a57b41b00abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPLETE STRUCTURE OF patents_data.jsonl ===\n",
      "\n",
      "=== GROUPED BY TOP-LEVEL KEYS ===\n",
      "\n",
      "ABSTRACT:\n",
      "  (root)                                   [list]\n",
      "      [0].lang                                 [str]\n",
      "      [0].text                                 [str]\n",
      "\n",
      "BIBLIO:\n",
      "  (root)                                   [dict]\n",
      "    classifications_cpc                      [dict]\n",
      "      classifications_cpc.classifications      [list]\n",
      "          classifications_cpc.classifications[0].classification_symbol_position [str]\n",
      "          classifications_cpc.classifications[0].classification_value [str]\n",
      "          classifications_cpc.classifications[0].symbol [str]\n",
      "    invention_title                          [list]\n",
      "        invention_title[0].lang                  [str]\n",
      "        invention_title[0].text                  [str]\n",
      "    parties                                  [dict]\n",
      "      parties.agents                           [list]\n",
      "          parties.agents[0].extracted_name         [dict]\n",
      "            parties.agents[0].extracted_name.value   [str]\n",
      "      parties.applicants                       [list]\n",
      "          parties.applicants[0].extracted_name     [dict]\n",
      "            parties.applicants[0].extracted_name.value [str]\n",
      "          parties.applicants[0].residence          [str]\n",
      "      parties.examiners                        [dict]\n",
      "        parties.examiners.primary_examiner       [dict]\n",
      "          parties.examiners.primary_examiner.department [str]\n",
      "          parties.examiners.primary_examiner.extracted_name [dict]\n",
      "            parties.examiners.primary_examiner.extracted_name.value [str]\n",
      "      parties.inventors                        [list]\n",
      "          parties.inventors[0].extracted_name      [dict]\n",
      "            parties.inventors[0].extracted_name.value [str]\n",
      "          parties.inventors[0].residence           [str]\n",
      "          parties.inventors[0].sequence            [int]\n",
      "    priority_claims                          [dict]\n",
      "      priority_claims.earliest_claim           [dict]\n",
      "        priority_claims.earliest_claim.date      [str]\n",
      "\n",
      "CLAIMS:\n",
      "  (root)                                   [list]\n",
      "      [0].                                     [list]\n",
      "          [0].[0].claim_text                       [list]\n",
      "      [0].lang                                 [str]\n",
      "\n",
      "DATE_PUBLISHED:\n",
      "  (root)                                   [str]\n",
      "\n",
      "DESCRIPTION:\n",
      "  (root)                                   [dict]\n",
      "    lang                                     [str]\n",
      "    text                                     [str]\n",
      "\n",
      "FAMILIES:\n",
      "  (root)                                   [dict]\n",
      "    extended_family                          [dict]\n",
      "      extended_family.members                  [list]\n",
      "          extended_family.members[0].document_id   [dict]\n",
      "            extended_family.members[0].document_id.date [str]\n",
      "            extended_family.members[0].document_id.doc_number [str]\n",
      "            extended_family.members[0].document_id.jurisdiction [str]\n",
      "            extended_family.members[0].document_id.kind [str]\n",
      "          extended_family.members[0].lens_id       [str]\n",
      "      extended_family.size                     [int]\n",
      "    simple_family                            [dict]\n",
      "      simple_family.members                    [list]\n",
      "          simple_family.members[0].document_id     [dict]\n",
      "            simple_family.members[0].document_id.date [str]\n",
      "            simple_family.members[0].document_id.doc_number [str]\n",
      "            simple_family.members[0].document_id.jurisdiction [str]\n",
      "            simple_family.members[0].document_id.kind [str]\n",
      "          simple_family.members[0].lens_id         [str]\n",
      "      simple_family.size                       [int]\n",
      "\n",
      "LEGAL_STATUS:\n",
      "  (root)                                   [dict]\n",
      "    anticipated_term_date                    [str]\n",
      "    calculation_log                          [list]\n",
      "    grant_date                               [str]\n",
      "    granted                                  [bool]\n",
      "    has_disclaimer                           [bool]\n",
      "    patent_status                            [str]\n",
      "\n",
      "LENS_ID:\n",
      "  (root)                                   [str]\n",
      "\n",
      "Total number of unique paths: 68\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def explore_structure(obj, path=\"\", all_paths=None):\n",
    "    \"\"\"Recursively explore the structure of a JSON object\"\"\"\n",
    "    if all_paths is None:\n",
    "        all_paths = set()\n",
    "    \n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            current_path = f\"{path}.{key}\" if path else key\n",
    "            all_paths.add(current_path)\n",
    "            \n",
    "            # Recursively explore nested structures\n",
    "            if isinstance(value, (dict, list)):\n",
    "                explore_structure(value, current_path, all_paths)\n",
    "    \n",
    "    elif isinstance(obj, list) and obj:\n",
    "        # For lists, explore the first item to understand the structure\n",
    "        current_path = f\"{path}[0]\" if path else \"[0]\"\n",
    "        explore_structure(obj[0], current_path, all_paths)\n",
    "    \n",
    "    return all_paths\n",
    "\n",
    "def get_value_types(obj, path=\"\", type_info=None):\n",
    "    \"\"\"Get type information for each path\"\"\"\n",
    "    if type_info is None:\n",
    "        type_info = {}\n",
    "    \n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            current_path = f\"{path}.{key}\" if path else key\n",
    "            type_info[current_path] = type(value).__name__\n",
    "            \n",
    "            if isinstance(value, (dict, list)):\n",
    "                get_value_types(value, current_path, type_info)\n",
    "    \n",
    "    elif isinstance(obj, list) and obj:\n",
    "        current_path = f\"{path}[0]\" if path else \"[0]\"\n",
    "        type_info[current_path] = f\"list[{type(obj[0]).__name__}]\"\n",
    "        get_value_types(obj[0], current_path, type_info)\n",
    "    \n",
    "    return type_info\n",
    "\n",
    "# Read the first line to understand the structure\n",
    "with open('patents_data1.jsonl', 'r', encoding='utf-8') as file:\n",
    "    first_line = file.readline().strip()\n",
    "    data = json.loads(first_line)\n",
    "\n",
    "print(\"=== COMPLETE STRUCTURE OF patents_data.jsonl ===\\n\")\n",
    "\n",
    "# Get all paths and their types\n",
    "all_paths = explore_structure(data)\n",
    "type_info = get_value_types(data)\n",
    "\n",
    "# Sort paths for better readability\n",
    "sorted_paths = sorted(all_paths)\n",
    "\n",
    "# Group by top-level keys\n",
    "print(\"=== GROUPED BY TOP-LEVEL KEYS ===\")\n",
    "top_level_groups = defaultdict(list)\n",
    "for path in sorted_paths:\n",
    "    top_key = path.split('.')[0].split('[')[0]\n",
    "    top_level_groups[top_key].append(path)\n",
    "\n",
    "for top_key, paths in sorted(top_level_groups.items()):\n",
    "    print(f\"\\n{top_key.upper()}:\")\n",
    "    for path in paths:\n",
    "        data_type = type_info.get(path, \"unknown\")\n",
    "        indent = \"  \" * (path.count('.') + path.count('['))\n",
    "        display_path = path.replace(f\"{top_key}.\", \"\").replace(f\"{top_key}\", \"\")\n",
    "        if display_path.startswith('.'):\n",
    "            display_path = display_path[1:]\n",
    "        print(f\"  {indent}{display_path or '(root)':<40} [{data_type}]\")\n",
    "\n",
    "print(f\"\\nTotal number of unique paths: {len(sorted_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98acd4ee-e1b4-4686-a270-57b08ba4158e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREVIEW MODE - Showing what changes will be made:\n",
      "============================================================\n",
      "=== PREVIEW OF RESTRUCTURING (First 2 lines) ===\n",
      "\n",
      "--- LINE 1 ---\n",
      "BEFORE (relevant keys):\n",
      "  Top-level keys: ['lens_id', 'date_published', 'biblio', 'legal_status', 'abstract', 'claims', 'description', 'families']\n",
      "  biblio keys: ['priority_claims', 'invention_title', 'classifications_cpc', 'parties']\n",
      "  Keys to extract from biblio: ['classifications_cpc', 'invention_title', 'parties', 'priority_claims']\n",
      "\n",
      "AFTER:\n",
      "  Top-level keys: ['lens_id', 'date_published', 'biblio', 'legal_status', 'abstract', 'claims', 'description', 'families', 'classifications_cpc', 'invention_title', 'parties', 'priority_claims']\n",
      "  classifications_cpc: {dict with keys: ['classifications']}\n",
      "  invention_title: [list with 1 items]\n",
      "  parties: {dict with keys: ['examiners', 'applicants', 'inventors', 'agents']}\n",
      "  priority_claims: {dict with keys: ['earliest_claim']}\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- LINE 2 ---\n",
      "BEFORE (relevant keys):\n",
      "  Top-level keys: ['lens_id', 'date_published', 'biblio', 'legal_status', 'abstract', 'claims', 'description', 'families']\n",
      "  biblio keys: ['priority_claims', 'invention_title', 'classifications_cpc', 'parties']\n",
      "  Keys to extract from biblio: ['classifications_cpc', 'invention_title', 'parties', 'priority_claims']\n",
      "\n",
      "AFTER:\n",
      "  Top-level keys: ['lens_id', 'date_published', 'biblio', 'legal_status', 'abstract', 'claims', 'description', 'families', 'classifications_cpc', 'invention_title', 'parties', 'priority_claims']\n",
      "  classifications_cpc: {dict with keys: ['classifications']}\n",
      "  invention_title: [list with 1 items]\n",
      "  parties: {dict with keys: ['examiners', 'applicants', 'inventors', 'agents', 'owners_all']}\n",
      "  priority_claims: {dict with keys: ['earliest_claim']}\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to proceed with restructuring the entire file? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing patents_data1.jsonl...\n",
      "Output will be saved to patents_data1_restructured.jsonl\n",
      "\n",
      "Processing complete!\n",
      "Successfully processed: 667 records\n",
      "Errors encountered: 0 records\n",
      "Output saved to: patents_data1_restructured.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Dict, Any\n",
    "\n",
    "def restructure_patent_data(input_file: str, output_file: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Restructure patent data by moving specific keys from 'biblio' to top level.\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to input JSONL file\n",
    "        output_file: Path to output JSONL file (defaults to input_file with '_restructured' suffix)\n",
    "    \"\"\"\n",
    "    if output_file is None:\n",
    "        name, ext = os.path.splitext(input_file)\n",
    "        output_file = f\"{name}_restructured{ext}\"\n",
    "    \n",
    "    # Keys to extract from biblio and move to top level\n",
    "    keys_to_extract = ['classifications_cpc', 'invention_title', 'parties', 'priority_claims']\n",
    "    \n",
    "    processed_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    print(f\"Processing {input_file}...\")\n",
    "    print(f\"Output will be saved to {output_file}\")\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, \\\n",
    "         open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        \n",
    "        for line_num, line in enumerate(infile, 1):\n",
    "            try:\n",
    "                line = line.strip()\n",
    "                if not line:  # Skip empty lines\n",
    "                    continue\n",
    "                \n",
    "                # Parse JSON\n",
    "                data = json.loads(line)\n",
    "                \n",
    "                # Check if biblio exists\n",
    "                if 'biblio' not in data:\n",
    "                    print(f\"Warning: Line {line_num} has no 'biblio' key, skipping restructure\")\n",
    "                    outfile.write(json.dumps(data) + '\\n')\n",
    "                    processed_count += 1\n",
    "                    continue\n",
    "                \n",
    "                biblio = data['biblio']\n",
    "                \n",
    "                # Extract specified keys from biblio and add to top level\n",
    "                for key in keys_to_extract:\n",
    "                    if key in biblio:\n",
    "                        data[key] = biblio[key]\n",
    "                        # Optionally remove from biblio to avoid duplication\n",
    "                        # del biblio[key]  # Uncomment if you want to remove from biblio\n",
    "                \n",
    "                # Write restructured data\n",
    "                outfile.write(json.dumps(data) + '\\n')\n",
    "                processed_count += 1\n",
    "                \n",
    "                # Progress indicator\n",
    "                if processed_count % 1000 == 0:\n",
    "                    print(f\"Processed {processed_count} records...\")\n",
    "                    \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON on line {line_num}: {e}\")\n",
    "                error_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error on line {line_num}: {e}\")\n",
    "                error_count += 1\n",
    "    \n",
    "    print(f\"\\nProcessing complete!\")\n",
    "    print(f\"Successfully processed: {processed_count} records\")\n",
    "    print(f\"Errors encountered: {error_count} records\")\n",
    "    print(f\"Output saved to: {output_file}\")\n",
    "\n",
    "def preview_restructure(input_file: str, num_lines: int = 3) -> None:\n",
    "    \"\"\"\n",
    "    Preview the restructuring by showing before and after for first few lines.\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to input JSONL file\n",
    "        num_lines: Number of lines to preview\n",
    "    \"\"\"\n",
    "    keys_to_extract = ['classifications_cpc', 'invention_title', 'parties', 'priority_claims']\n",
    "    \n",
    "    print(f\"=== PREVIEW OF RESTRUCTURING (First {num_lines} lines) ===\\n\")\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        for i in range(num_lines):\n",
    "            line = file.readline().strip()\n",
    "            if not line:\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                original_data = json.loads(line)\n",
    "                restructured_data = original_data.copy()\n",
    "                \n",
    "                print(f\"--- LINE {i+1} ---\")\n",
    "                print(\"BEFORE (relevant keys):\")\n",
    "                print(f\"  Top-level keys: {list(original_data.keys())}\")\n",
    "                if 'biblio' in original_data:\n",
    "                    biblio_keys = list(original_data['biblio'].keys())\n",
    "                    print(f\"  biblio keys: {biblio_keys}\")\n",
    "                    \n",
    "                    # Show which keys will be extracted\n",
    "                    extractable = [k for k in keys_to_extract if k in original_data['biblio']]\n",
    "                    print(f\"  Keys to extract from biblio: {extractable}\")\n",
    "                else:\n",
    "                    print(\"  No 'biblio' key found\")\n",
    "                \n",
    "                # Perform restructuring\n",
    "                if 'biblio' in restructured_data:\n",
    "                    biblio = restructured_data['biblio']\n",
    "                    for key in keys_to_extract:\n",
    "                        if key in biblio:\n",
    "                            restructured_data[key] = biblio[key]\n",
    "                \n",
    "                print(\"\\nAFTER:\")\n",
    "                print(f\"  Top-level keys: {list(restructured_data.keys())}\")\n",
    "                \n",
    "                # Show sample values for extracted keys\n",
    "                for key in keys_to_extract:\n",
    "                    if key in restructured_data:\n",
    "                        value = restructured_data[key]\n",
    "                        if isinstance(value, str):\n",
    "                            preview_val = value[:100] + \"...\" if len(value) > 100 else value\n",
    "                        elif isinstance(value, list):\n",
    "                            preview_val = f\"[list with {len(value)} items]\"\n",
    "                        elif isinstance(value, dict):\n",
    "                            preview_val = f\"{{dict with keys: {list(value.keys())}}}\"\n",
    "                        else:\n",
    "                            preview_val = str(value)\n",
    "                        print(f\"  {key}: {preview_val}\")\n",
    "                \n",
    "                print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing line {i+1}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"patents_data1.jsonl\"  # Change this to your actual filename\n",
    "    \n",
    "    # First, preview the changes\n",
    "    print(\"PREVIEW MODE - Showing what changes will be made:\")\n",
    "    print(\"=\"*60)\n",
    "    preview_restructure(input_file, num_lines=2)\n",
    "    \n",
    "    # Ask for confirmation\n",
    "    response = input(\"Do you want to proceed with restructuring the entire file? (y/n): \")\n",
    "    \n",
    "    if response.lower().strip() in ['y', 'yes']:\n",
    "        restructure_patent_data(input_file)\n",
    "    else:\n",
    "        print(\"Operation cancelled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0870c05-a53d-49ba-ad27-52d69500945b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing patents_data1_restructured.jsonl...\n",
      "\n",
      "Processing complete!\n",
      "Total records processed: 667\n",
      "Biblio keys dropped: 667\n",
      "File updated: patents_data1_restructured.jsonl\n",
      "Done! The biblio key has been removed from all records.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def drop_biblio_key(input_file: str, output_file: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Remove the 'biblio' key from all lines in a JSONL file.\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to input JSONL file\n",
    "        output_file: Path to output JSONL file (defaults to overwriting input file)\n",
    "    \"\"\"\n",
    "    if output_file is None:\n",
    "        output_file = input_file  # Overwrite the original file\n",
    "    \n",
    "    processed_count = 0\n",
    "    biblio_dropped_count = 0\n",
    "    \n",
    "    print(f\"Processing {input_file}...\")\n",
    "    \n",
    "    # Read all lines first\n",
    "    lines_to_write = []\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "        for line_num, line in enumerate(infile, 1):\n",
    "            try:\n",
    "                line = line.strip()\n",
    "                if not line:  # Skip empty lines\n",
    "                    continue\n",
    "                \n",
    "                # Parse JSON\n",
    "                data = json.loads(line)\n",
    "                \n",
    "                # Drop biblio key if it exists\n",
    "                if 'biblio' in data:\n",
    "                    del data['biblio']\n",
    "                    biblio_dropped_count += 1\n",
    "                \n",
    "                # Add to lines to write\n",
    "                lines_to_write.append(json.dumps(data))\n",
    "                processed_count += 1\n",
    "                \n",
    "                # Progress indicator\n",
    "                if processed_count % 1000 == 0:\n",
    "                    print(f\"Processed {processed_count} records...\")\n",
    "                    \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON on line {line_num}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error on line {line_num}: {e}\")\n",
    "    \n",
    "    # Write all lines back\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        for line in lines_to_write:\n",
    "            outfile.write(line + '\\n')\n",
    "    \n",
    "    print(f\"\\nProcessing complete!\")\n",
    "    print(f\"Total records processed: {processed_count}\")\n",
    "    print(f\"Biblio keys dropped: {biblio_dropped_count}\")\n",
    "    print(f\"File updated: {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"patents_data1_restructured.jsonl\"\n",
    "    \n",
    "    # This will overwrite the original restructured file\n",
    "    drop_biblio_key(input_file)\n",
    "    \n",
    "    print(\"Done! The biblio key has been removed from all records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4660c90d-dc51-46f7-a29b-0d7018ea1de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPLETE STRUCTURE OF patents_data.jsonl ===\n",
      "\n",
      "=== GROUPED BY TOP-LEVEL KEYS ===\n",
      "\n",
      "ABSTRACT_TEXT:\n",
      "  (root)                                   [str]\n",
      "\n",
      "APPLICANT_NAME:\n",
      "  (root)                                   [str]\n",
      "\n",
      "CLAIMS:\n",
      "  (root)                                   [list]\n",
      "\n",
      "CPC_SYMBOLS:\n",
      "  (root)                                   [list]\n",
      "\n",
      "DATE_PUBLISHED:\n",
      "  (root)                                   [str]\n",
      "\n",
      "DESCRIPTION:\n",
      "  (root)                                   [str]\n",
      "\n",
      "EARLIEST_CLAIM_DATE:\n",
      "  (root)                                   [str]\n",
      "\n",
      "INVENTION_TITLE_TEXT:\n",
      "  (root)                                   [str]\n",
      "\n",
      "LENS_ID:\n",
      "  (root)                                   [str]\n",
      "\n",
      "Total number of unique paths: 9\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def explore_structure(obj, path=\"\", all_paths=None):\n",
    "    \"\"\"Recursively explore the structure of a JSON object\"\"\"\n",
    "    if all_paths is None:\n",
    "        all_paths = set()\n",
    "    \n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            current_path = f\"{path}.{key}\" if path else key\n",
    "            all_paths.add(current_path)\n",
    "            \n",
    "            # Recursively explore nested structures\n",
    "            if isinstance(value, (dict, list)):\n",
    "                explore_structure(value, current_path, all_paths)\n",
    "    \n",
    "    elif isinstance(obj, list) and obj:\n",
    "        # For lists, explore the first item to understand the structure\n",
    "        current_path = f\"{path}[0]\" if path else \"[0]\"\n",
    "        explore_structure(obj[0], current_path, all_paths)\n",
    "    \n",
    "    return all_paths\n",
    "\n",
    "def get_value_types(obj, path=\"\", type_info=None):\n",
    "    \"\"\"Get type information for each path\"\"\"\n",
    "    if type_info is None:\n",
    "        type_info = {}\n",
    "    \n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            current_path = f\"{path}.{key}\" if path else key\n",
    "            type_info[current_path] = type(value).__name__\n",
    "            \n",
    "            if isinstance(value, (dict, list)):\n",
    "                get_value_types(value, current_path, type_info)\n",
    "    \n",
    "    elif isinstance(obj, list) and obj:\n",
    "        current_path = f\"{path}[0]\" if path else \"[0]\"\n",
    "        type_info[current_path] = f\"list[{type(obj[0]).__name__}]\"\n",
    "        get_value_types(obj[0], current_path, type_info)\n",
    "    \n",
    "    return type_info\n",
    "\n",
    "# Read the first line to understand the structure\n",
    "with open('patents_data1_restructured_flattened.jsonl', 'r', encoding='utf-8') as file:\n",
    "    first_line = file.readline().strip()\n",
    "    data = json.loads(first_line)\n",
    "\n",
    "print(\"=== COMPLETE STRUCTURE OF patents_data.jsonl ===\\n\")\n",
    "\n",
    "# Get all paths and their types\n",
    "all_paths = explore_structure(data)\n",
    "type_info = get_value_types(data)\n",
    "\n",
    "# Sort paths for better readability\n",
    "sorted_paths = sorted(all_paths)\n",
    "\n",
    "# Group by top-level keys\n",
    "print(\"=== GROUPED BY TOP-LEVEL KEYS ===\")\n",
    "top_level_groups = defaultdict(list)\n",
    "for path in sorted_paths:\n",
    "    top_key = path.split('.')[0].split('[')[0]\n",
    "    top_level_groups[top_key].append(path)\n",
    "\n",
    "for top_key, paths in sorted(top_level_groups.items()):\n",
    "    print(f\"\\n{top_key.upper()}:\")\n",
    "    for path in paths:\n",
    "        data_type = type_info.get(path, \"unknown\")\n",
    "        indent = \"  \" * (path.count('.') + path.count('['))\n",
    "        display_path = path.replace(f\"{top_key}.\", \"\").replace(f\"{top_key}\", \"\")\n",
    "        if display_path.startswith('.'):\n",
    "            display_path = display_path[1:]\n",
    "        print(f\"  {indent}{display_path or '(root)':<40} [{data_type}]\")\n",
    "\n",
    "print(f\"\\nTotal number of unique paths: {len(sorted_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "decd2c38-9152-4987-8f1d-6609ef1cc55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter filename:  patents_data1_restructured.jsonl\n",
      "Enter key path to drop (e.g., 'parties.agents' or 'biblio'):  abstract\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing patents_data1_restructured.jsonl...\n",
      "Dropping key path: 'abstract'\n",
      "\n",
      "Processing complete!\n",
      "Total records processed: 667\n",
      "Key paths successfully dropped: 667\n",
      "Errors encountered: 0\n",
      "File updated: patents_data1_restructured.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "def drop_nested_key(data: Dict[Any, Any], key_path: str) -> bool:\n",
    "    \"\"\"\n",
    "    Drop a nested key from a dictionary based on dot notation path.\n",
    "    Handles both dict keys and list operations.\n",
    "    \n",
    "    Args:\n",
    "        data: Dictionary to modify\n",
    "        key_path: Dot-separated path to the key \n",
    "                 Examples:\n",
    "                 - 'parties.agents' (drop agents from parties dict)\n",
    "                 - 'abstract.lang' (drop lang from all objects in abstract list)\n",
    "                 - 'abstract[0].lang' (drop lang from first object in abstract list)\n",
    "                 - 'metadata' (drop entire metadata key)\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if key was found and dropped, False otherwise\n",
    "    \"\"\"\n",
    "    keys = key_path.split('.')\n",
    "    \n",
    "    # Navigate to the parent of the key to be dropped\n",
    "    current = data\n",
    "    \n",
    "    # Navigate through all keys except the last one\n",
    "    for key in keys[:-1]:\n",
    "        # Handle array index notation like 'abstract[0]'\n",
    "        if '[' in key and ']' in key:\n",
    "            array_key = key.split('[')[0]\n",
    "            index_str = key.split('[')[1].split(']')[0]\n",
    "            \n",
    "            if not isinstance(current, dict) or array_key not in current:\n",
    "                return False\n",
    "            current = current[array_key]\n",
    "            \n",
    "            if not isinstance(current, list):\n",
    "                return False\n",
    "            \n",
    "            try:\n",
    "                index = int(index_str)\n",
    "                if index >= len(current):\n",
    "                    return False\n",
    "                current = current[index]\n",
    "            except (ValueError, IndexError):\n",
    "                return False\n",
    "        else:\n",
    "            if not isinstance(current, dict) or key not in current:\n",
    "                return False\n",
    "            current = current[key]\n",
    "    \n",
    "    # Drop the final key\n",
    "    final_key = keys[-1]\n",
    "    dropped_any = False\n",
    "    \n",
    "    # If current is a list and we want to drop a key from all objects in the list\n",
    "    if isinstance(current, list):\n",
    "        for item in current:\n",
    "            if isinstance(item, dict) and final_key in item:\n",
    "                del item[final_key]\n",
    "                dropped_any = True\n",
    "    # If current is a dict, drop the key normally\n",
    "    elif isinstance(current, dict) and final_key in current:\n",
    "        del current[final_key]\n",
    "        dropped_any = True\n",
    "    \n",
    "    return dropped_any\n",
    "\n",
    "def intelligent_key_dropper(filename: str, key_path: str, output_file: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Drop specified nested keys from all lines in a JSONL file.\n",
    "    \n",
    "    Args:\n",
    "        filename: Path to the JSONL file\n",
    "        key_path: Dot-separated path to key to drop\n",
    "                 Examples:\n",
    "                 - 'parties.agents' (drops agents from parties dict)\n",
    "                 - 'abstract.lang' (drops lang from ALL objects in abstract list)\n",
    "                 - 'abstract[0].lang' (drops lang from first object in abstract list only)\n",
    "                 - 'biblio' (drops entire biblio key)\n",
    "                 - 'metadata.source.url' (drops url from metadata.source dict)\n",
    "        output_file: Output file path (defaults to overwriting input file)\n",
    "    \n",
    "    Examples:\n",
    "        intelligent_key_dropper('data.jsonl', 'parties.agents')      # Drops agents from parties\n",
    "        intelligent_key_dropper('data.jsonl', 'abstract.lang')       # Drops lang from all abstract items\n",
    "        intelligent_key_dropper('data.jsonl', 'abstract[0].text')    # Drops text from first abstract item\n",
    "        intelligent_key_dropper('data.jsonl', 'biblio')             # Drops entire biblio key\n",
    "    \"\"\"\n",
    "    if output_file is None:\n",
    "        output_file = filename  # Overwrite the original file\n",
    "    \n",
    "    processed_count = 0\n",
    "    keys_dropped_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    print(f\"Processing {filename}...\")\n",
    "    print(f\"Dropping key path: '{key_path}'\")\n",
    "    \n",
    "    # Read, process, and collect all lines\n",
    "    lines_to_write = []\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as infile:\n",
    "        for line_num, line in enumerate(infile, 1):\n",
    "            try:\n",
    "                line = line.strip()\n",
    "                if not line:  # Skip empty lines\n",
    "                    continue\n",
    "                \n",
    "                # Parse JSON\n",
    "                data = json.loads(line)\n",
    "                \n",
    "                # Try to drop the specified key path\n",
    "                if drop_nested_key(data, key_path):\n",
    "                    keys_dropped_count += 1\n",
    "                \n",
    "                # Add to lines to write\n",
    "                lines_to_write.append(json.dumps(data))\n",
    "                processed_count += 1\n",
    "                \n",
    "                # Progress indicator\n",
    "                if processed_count % 1000 == 0:\n",
    "                    print(f\"Processed {processed_count} records...\")\n",
    "                    \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON on line {line_num}: {e}\")\n",
    "                error_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error on line {line_num}: {e}\")\n",
    "                error_count += 1\n",
    "    \n",
    "    # Write all lines back\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        for line in lines_to_write:\n",
    "            outfile.write(line + '\\n')\n",
    "    \n",
    "    print(f\"\\nProcessing complete!\")\n",
    "    print(f\"Total records processed: {processed_count}\")\n",
    "    print(f\"Key paths successfully dropped: {keys_dropped_count}\")\n",
    "    print(f\"Errors encountered: {error_count}\")\n",
    "    print(f\"File updated: {output_file}\")\n",
    "\n",
    "def batch_drop_keys(filename: str, key_paths: List[str], output_file: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Drop multiple key paths from all lines in a JSONL file in a single pass.\n",
    "    \n",
    "    Args:\n",
    "        filename: Path to the JSONL file\n",
    "        key_paths: List of dot-separated paths to keys to drop\n",
    "        output_file: Output file path (defaults to overwriting input file)\n",
    "    \n",
    "    Example:\n",
    "        batch_drop_keys('data.jsonl', ['parties.agents', 'biblio.source', 'metadata'])\n",
    "    \"\"\"\n",
    "    if output_file is None:\n",
    "        output_file = filename\n",
    "    \n",
    "    processed_count = 0\n",
    "    total_keys_dropped = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    print(f\"Processing {filename}...\")\n",
    "    print(f\"Dropping key paths: {key_paths}\")\n",
    "    \n",
    "    lines_to_write = []\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as infile:\n",
    "        for line_num, line in enumerate(infile, 1):\n",
    "            try:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                \n",
    "                data = json.loads(line)\n",
    "                \n",
    "                # Drop all specified key paths\n",
    "                keys_dropped_this_line = 0\n",
    "                for key_path in key_paths:\n",
    "                    if drop_nested_key(data, key_path):\n",
    "                        keys_dropped_this_line += 1\n",
    "                \n",
    "                total_keys_dropped += keys_dropped_this_line\n",
    "                lines_to_write.append(json.dumps(data))\n",
    "                processed_count += 1\n",
    "                \n",
    "                if processed_count % 1000 == 0:\n",
    "                    print(f\"Processed {processed_count} records...\")\n",
    "                    \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON on line {line_num}: {e}\")\n",
    "                error_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error on line {line_num}: {e}\")\n",
    "                error_count += 1\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        for line in lines_to_write:\n",
    "            outfile.write(line + '\\n')\n",
    "    \n",
    "    print(f\"\\nProcessing complete!\")\n",
    "    print(f\"Total records processed: {processed_count}\")\n",
    "    print(f\"Total key paths dropped: {total_keys_dropped}\")\n",
    "    print(f\"Errors encountered: {error_count}\")\n",
    "    print(f\"File updated: {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Single key drop examples:\n",
    "    # intelligent_key_dropper('patent_data1_restructured.jsonl', 'biblio')\n",
    "    # intelligent_key_dropper('patent_data1_restructured.jsonl', 'parties.agents')\n",
    "    # intelligent_key_dropper('patent_data1_restructured.jsonl', 'metadata.source.url')\n",
    "    \n",
    "    # Multiple key drop example:\n",
    "    # batch_drop_keys('patent_data1_restructured.jsonl', ['biblio', 'parties.agents', 'metadata.source'])\n",
    "    \n",
    "    # Interactive mode\n",
    "    filename = input(\"Enter filename: \").strip()\n",
    "    key_path = input(\"Enter key path to drop (e.g., 'parties.agents' or 'biblio'): \").strip()\n",
    "    \n",
    "    if filename and key_path:\n",
    "        intelligent_key_dropper(filename, key_path)\n",
    "    else:\n",
    "        print(\"Invalid input. Please provide both filename and key path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "273d558a-605f-44cc-940d-f9d47247fb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREVIEW MODE - Showing what will be extracted:\n",
      "============================================================\n",
      "=== PREVIEW OF FLATTENING (First 2 lines) ===\n",
      "\n",
      "--- LINE 1 ---\n",
      "Will extract to top level:\n",
      "  earliest_claim_date: '2016-10-13'\n",
      "  applicant_name: 'BAIDU USA LLC'\n",
      "  cpc_symbols: ['G05D1/021', 'B60W40/09', 'G06N20/00', '... and 34 more']\n",
      "  invention_title_text: 'Group driving style learning framework for autonom...'\n",
      "  abstract_text: 'A social driving style learning framework or syste...'\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- LINE 2 ---\n",
      "Will extract to top level:\n",
      "  earliest_claim_date: '2018-04-03'\n",
      "  applicant_name: 'FORD GLOBAL TECH LLC'\n",
      "  cpc_symbols: ['B60W30/06', 'B60W2556/50', 'G01C21/00', '... and 9 more']\n",
      "  invention_title_text: 'Automatic navigation using deep reinforcement lear...'\n",
      "  abstract_text: 'A method for training an autonomous vehicle to rea...'\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to proceed with flattening? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing patents_data1_restructured.jsonl...\n",
      "Flattening nested structures...\n",
      "\n",
      "Processing complete!\n",
      "Total records processed: 667\n",
      "Errors encountered: 0\n",
      "\n",
      "Transformations applied:\n",
      "  earliest_claim_date: 667 records\n",
      "  applicant_name: 667 records\n",
      "  cpc_symbols: 667 records\n",
      "  invention_title_text: 667 records\n",
      "  abstract_text: 667 records\n",
      "\n",
      "File updated: patents_data1_restructured.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "def flatten_patent_structure(filename: str, output_file: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Flatten unnecessarily nested single values to top level.\n",
    "    \n",
    "    Transformations:\n",
    "    - priority_claims.earliest_claim.date -> earliest_claim_date\n",
    "    - parties.applicants[0].extracted_name.value -> applicant_name (first applicant)\n",
    "    - classifications_cpc.classifications[].symbol -> cpc_symbols (all symbols as list)  \n",
    "    - invention_title[0].text -> invention_title_text\n",
    "    - abstract[0].text -> abstract_text\n",
    "    \n",
    "    Args:\n",
    "        filename: Path to the JSONL file\n",
    "        output_file: Output file path (defaults to overwriting input file)\n",
    "    \"\"\"\n",
    "    if output_file is None:\n",
    "        output_file = filename\n",
    "    \n",
    "    processed_count = 0\n",
    "    transformations_count = {\n",
    "        'earliest_claim_date': 0,\n",
    "        'applicant_name': 0, \n",
    "        'cpc_symbols': 0,\n",
    "        'invention_title_text': 0,\n",
    "        'abstract_text': 0\n",
    "    }\n",
    "    error_count = 0\n",
    "    \n",
    "    print(f\"Processing {filename}...\")\n",
    "    print(\"Flattening nested structures...\")\n",
    "    \n",
    "    lines_to_write = []\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as infile:\n",
    "        for line_num, line in enumerate(infile, 1):\n",
    "            try:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                \n",
    "                data = json.loads(line)\n",
    "                \n",
    "                # 1. Flatten earliest claim date\n",
    "                if ('priority_claims' in data and \n",
    "                    isinstance(data['priority_claims'], dict) and\n",
    "                    'earliest_claim' in data['priority_claims'] and\n",
    "                    isinstance(data['priority_claims']['earliest_claim'], dict) and\n",
    "                    'date' in data['priority_claims']['earliest_claim']):\n",
    "                    \n",
    "                    data['earliest_claim_date'] = data['priority_claims']['earliest_claim']['date']\n",
    "                    transformations_count['earliest_claim_date'] += 1\n",
    "                \n",
    "                # 2. Flatten first applicant name\n",
    "                if ('parties' in data and \n",
    "                    isinstance(data['parties'], dict) and\n",
    "                    'applicants' in data['parties'] and\n",
    "                    isinstance(data['parties']['applicants'], list) and\n",
    "                    len(data['parties']['applicants']) > 0 and\n",
    "                    isinstance(data['parties']['applicants'][0], dict) and\n",
    "                    'extracted_name' in data['parties']['applicants'][0] and\n",
    "                    isinstance(data['parties']['applicants'][0]['extracted_name'], dict) and\n",
    "                    'value' in data['parties']['applicants'][0]['extracted_name']):\n",
    "                    \n",
    "                    data['applicant_name'] = data['parties']['applicants'][0]['extracted_name']['value']\n",
    "                    transformations_count['applicant_name'] += 1\n",
    "                \n",
    "                # 3. Flatten ALL CPC classification symbols\n",
    "                if ('classifications_cpc' in data and \n",
    "                    isinstance(data['classifications_cpc'], dict) and\n",
    "                    'classifications' in data['classifications_cpc'] and\n",
    "                    isinstance(data['classifications_cpc']['classifications'], list)):\n",
    "                    \n",
    "                    # Extract all symbols into a simple list\n",
    "                    symbols = []\n",
    "                    for classification in data['classifications_cpc']['classifications']:\n",
    "                        if isinstance(classification, dict) and 'symbol' in classification:\n",
    "                            symbols.append(classification['symbol'])\n",
    "                    \n",
    "                    if symbols:  # Only add if we found symbols\n",
    "                        data['cpc_symbols'] = symbols\n",
    "                        transformations_count['cpc_symbols'] += 1\n",
    "                \n",
    "                # 4. Flatten invention title text\n",
    "                if ('invention_title' in data and \n",
    "                    isinstance(data['invention_title'], list) and\n",
    "                    len(data['invention_title']) > 0 and\n",
    "                    isinstance(data['invention_title'][0], dict) and\n",
    "                    'text' in data['invention_title'][0]):\n",
    "                    \n",
    "                    data['invention_title_text'] = data['invention_title'][0]['text']\n",
    "                    transformations_count['invention_title_text'] += 1\n",
    "                \n",
    "                # 5. Flatten abstract text\n",
    "                if ('abstract' in data and \n",
    "                    isinstance(data['abstract'], list) and\n",
    "                    len(data['abstract']) > 0 and\n",
    "                    isinstance(data['abstract'][0], dict) and\n",
    "                    'text' in data['abstract'][0]):\n",
    "                    \n",
    "                    data['abstract_text'] = data['abstract'][0]['text']\n",
    "                    transformations_count['abstract_text'] += 1\n",
    "                \n",
    "                lines_to_write.append(json.dumps(data))\n",
    "                processed_count += 1\n",
    "                \n",
    "                if processed_count % 1000 == 0:\n",
    "                    print(f\"Processed {processed_count} records...\")\n",
    "                    \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON on line {line_num}: {e}\")\n",
    "                error_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error on line {line_num}: {e}\")\n",
    "                error_count += 1\n",
    "    \n",
    "    # Write all lines back\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        for line in lines_to_write:\n",
    "            outfile.write(line + '\\n')\n",
    "    \n",
    "    print(f\"\\nProcessing complete!\")\n",
    "    print(f\"Total records processed: {processed_count}\")\n",
    "    print(f\"Errors encountered: {error_count}\")\n",
    "    print(\"\\nTransformations applied:\")\n",
    "    for key, count in transformations_count.items():\n",
    "        print(f\"  {key}: {count} records\")\n",
    "    print(f\"\\nFile updated: {output_file}\")\n",
    "\n",
    "def preview_flattening(filename: str, num_lines: int = 3) -> None:\n",
    "    \"\"\"Preview what the flattening will do.\"\"\"\n",
    "    print(f\"=== PREVIEW OF FLATTENING (First {num_lines} lines) ===\\n\")\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for i in range(num_lines):\n",
    "            line = file.readline().strip()\n",
    "            if not line:\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                print(f\"--- LINE {i+1} ---\")\n",
    "                \n",
    "                # Show what will be extracted\n",
    "                extractions = []\n",
    "                \n",
    "                # Check earliest claim date\n",
    "                try:\n",
    "                    date = data['priority_claims']['earliest_claim']['date']\n",
    "                    extractions.append(f\"earliest_claim_date: '{date}'\")\n",
    "                except (KeyError, TypeError):\n",
    "                    extractions.append(\"earliest_claim_date: [not found]\")\n",
    "                \n",
    "                # Check applicant name\n",
    "                try:\n",
    "                    name = data['parties']['applicants'][0]['extracted_name']['value']\n",
    "                    extractions.append(f\"applicant_name: '{name}'\")\n",
    "                except (KeyError, TypeError, IndexError):\n",
    "                    extractions.append(\"applicant_name: [not found]\")\n",
    "                \n",
    "                # Check all CPC symbols\n",
    "                try:\n",
    "                    symbols = []\n",
    "                    for classification in data['classifications_cpc']['classifications']:\n",
    "                        if 'symbol' in classification:\n",
    "                            symbols.append(classification['symbol'])\n",
    "                    if symbols:\n",
    "                        symbols_preview = symbols[:3]  # Show first 3\n",
    "                        if len(symbols) > 3:\n",
    "                            symbols_preview.append(f\"... and {len(symbols)-3} more\")\n",
    "                        extractions.append(f\"cpc_symbols: {symbols_preview}\")\n",
    "                    else:\n",
    "                        extractions.append(\"cpc_symbols: [no symbols found]\")\n",
    "                except (KeyError, TypeError):\n",
    "                    extractions.append(\"cpc_symbols: [not found]\")\n",
    "                \n",
    "                # Check invention title\n",
    "                try:\n",
    "                    title = data['invention_title'][0]['text']\n",
    "                    title_preview = title[:50] + \"...\" if len(title) > 50 else title\n",
    "                    extractions.append(f\"invention_title_text: '{title_preview}'\")\n",
    "                except (KeyError, TypeError, IndexError):\n",
    "                    extractions.append(\"invention_title_text: [not found]\")\n",
    "                \n",
    "                # Check abstract\n",
    "                try:\n",
    "                    abstract = data['abstract'][0]['text']\n",
    "                    abstract_preview = abstract[:50] + \"...\" if len(abstract) > 50 else abstract\n",
    "                    extractions.append(f\"abstract_text: '{abstract_preview}'\")\n",
    "                except (KeyError, TypeError, IndexError):\n",
    "                    extractions.append(\"abstract_text: [not found]\")\n",
    "                \n",
    "                print(\"Will extract to top level:\")\n",
    "                for extraction in extractions:\n",
    "                    print(f\"  {extraction}\")\n",
    "                \n",
    "                print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing line {i+1}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"patents_data1_restructured.jsonl\"\n",
    "    \n",
    "    # Preview first\n",
    "    print(\"PREVIEW MODE - Showing what will be extracted:\")\n",
    "    print(\"=\"*60)\n",
    "    preview_flattening(filename, num_lines=2)\n",
    "    \n",
    "    # Ask for confirmation\n",
    "    response = input(\"Do you want to proceed with flattening? (y/n): \")\n",
    "    \n",
    "    if response.lower().strip() in ['y', 'yes']:\n",
    "        flatten_patent_structure(filename)\n",
    "    else:\n",
    "        print(\"Operation cancelled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f4d49be0-6eca-43bc-a860-9eb5ff78a5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREVIEW MODE - Showing what changes will be made:\n",
      "============================================================\n",
      "=== PREVIEW OF FLATTENING (First 2 lines) ===\n",
      "\n",
      "--- LINE 1 ---\n",
      "CLAIMS:\n",
      "  BEFORE: list - Complex nested structure\n",
      "  AFTER:  list with 22 items\n",
      "  First claim preview: 1. A non-transitory machine-readable medium storing instructions, which when executed by a processor...\n",
      "DESCRIPTION:\n",
      "  BEFORE: dict\n",
      "          Keys: ['text']\n",
      "  AFTER:  str with 56295 characters\n",
      "  Preview: RELATED APPLICATIONS This application is a continuation application of a co-pending U.S. patent appl...\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- LINE 2 ---\n",
      "CLAIMS:\n",
      "  BEFORE: list - Complex nested structure\n",
      "  AFTER:  list with 18 items\n",
      "  First claim preview: 1. A method comprising: identifying a state of an autonomous vehicle within a simulated environment,...\n",
      "DESCRIPTION:\n",
      "  BEFORE: dict\n",
      "          Keys: ['text']\n",
      "  AFTER:  str with 36197 characters\n",
      "  Preview: BACKGROUND Field of the Invention This invention relates to navigation for vehicles. Background of t...\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to proceed with flattening the entire file? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing patents_data1_restructured.jsonl...\n",
      "Output will be saved to patents_data1_restructured_flattened.jsonl\n",
      "Line 1 - Claims flattened: 22 claims\n",
      "Line 1 - Description flattened: 56295 characters\n",
      "  Preview: RELATED APPLICATIONS This application is a continuation application of a co-pending U.S. patent appl...\n",
      "Line 2 - Claims flattened: 18 claims\n",
      "Line 2 - Description flattened: 36197 characters\n",
      "  Preview: BACKGROUND Field of the Invention This invention relates to navigation for vehicles. Background of t...\n",
      "Line 3 - Claims flattened: 18 claims\n",
      "Line 3 - Description flattened: 236250 characters\n",
      "  Preview: CLAIM TO PRIORITY This Patent Application claims the benefit of and priority to U.S. Non-Provisional...\n",
      "\n",
      "Flattening complete!\n",
      "Successfully processed: 667 records\n",
      "Claims flattened: 667 records\n",
      "Descriptions flattened: 667 records\n",
      "Errors encountered: 0 records\n",
      "Output saved to: patents_data1_restructured_flattened.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Any, List, Union\n",
    "\n",
    "def flatten_claims(claims_data: Any) -> List[str]:\n",
    "    \"\"\"\n",
    "    Flatten the nested claims structure to a simple list of strings.\n",
    "    Structure: claims[0].claims[0].claim_text (where claim_text is a list)\n",
    "    \n",
    "    Args:\n",
    "        claims_data: The nested claims structure\n",
    "        \n",
    "    Returns:\n",
    "        List of claim text strings\n",
    "    \"\"\"\n",
    "    flattened_claims = []\n",
    "    \n",
    "    if not claims_data:\n",
    "        return flattened_claims\n",
    "    \n",
    "    try:\n",
    "        # Handle the structure: claims[0].claims[0].claim_text\n",
    "        if isinstance(claims_data, list):\n",
    "            for claims_group in claims_data:  # First level: claims[0]\n",
    "                if isinstance(claims_group, dict) and 'claims' in claims_group:\n",
    "                    inner_claims = claims_group['claims']  # Get claims[0].claims\n",
    "                    \n",
    "                    if isinstance(inner_claims, list):\n",
    "                        for claim_item in inner_claims:  # claims[0].claims[0]\n",
    "                            if isinstance(claim_item, dict) and 'claim_text' in claim_item:\n",
    "                                claim_text = claim_item['claim_text']\n",
    "                                \n",
    "                                # Handle claim_text being a list (join with space)\n",
    "                                if isinstance(claim_text, list):\n",
    "                                    flattened_text = ' '.join(str(item) for item in claim_text if item)\n",
    "                                    if flattened_text.strip():\n",
    "                                        flattened_claims.append(flattened_text.strip())\n",
    "                                elif isinstance(claim_text, str) and claim_text.strip():\n",
    "                                    flattened_claims.append(claim_text.strip())\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error flattening claims: {e}\")\n",
    "        return []\n",
    "    \n",
    "    return flattened_claims\n",
    "\n",
    "def flatten_description(description_data: Any) -> str:\n",
    "    \"\"\"\n",
    "    Flatten the description structure to a simple string.\n",
    "    \n",
    "    Args:\n",
    "        description_data: The description structure (dict with 'text' key or string)\n",
    "        \n",
    "    Returns:\n",
    "        Description text as string\n",
    "    \"\"\"\n",
    "    if not description_data:\n",
    "        return \"\"\n",
    "    \n",
    "    if isinstance(description_data, dict):\n",
    "        # Extract text field if it exists\n",
    "        return description_data.get('text', '')\n",
    "    elif isinstance(description_data, str):\n",
    "        return description_data\n",
    "    else:\n",
    "        return str(description_data)\n",
    "\n",
    "def flatten_patent_data(input_file: str, output_file: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Flatten claims and description structures in patent data.\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to input JSONL file\n",
    "        output_file: Path to output JSONL file (defaults to input_file with '_flattened' suffix)\n",
    "    \"\"\"\n",
    "    if output_file is None:\n",
    "        name, ext = os.path.splitext(input_file)\n",
    "        output_file = f\"{name}_flattened{ext}\"\n",
    "    \n",
    "    processed_count = 0\n",
    "    error_count = 0\n",
    "    claims_flattened = 0\n",
    "    descriptions_flattened = 0\n",
    "    \n",
    "    print(f\"Processing {input_file}...\")\n",
    "    print(f\"Output will be saved to {output_file}\")\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, \\\n",
    "         open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        \n",
    "        for line_num, line in enumerate(infile, 1):\n",
    "            try:\n",
    "                line = line.strip()\n",
    "                if not line:  # Skip empty lines\n",
    "                    continue\n",
    "                \n",
    "                # Parse JSON\n",
    "                data = json.loads(line)\n",
    "                \n",
    "                # Flatten claims if present (lowercase key)\n",
    "                if 'claims' in data:\n",
    "                    original_claims = data['claims']\n",
    "                    flattened_claims = flatten_claims(original_claims)\n",
    "                    data['claims'] = flattened_claims\n",
    "                    claims_flattened += 1\n",
    "                    \n",
    "                    # Debug info for first few records\n",
    "                    if line_num <= 3:\n",
    "                        print(f\"Line {line_num} - Claims flattened: {len(flattened_claims)} claims\")\n",
    "                \n",
    "                # Flatten description if present (lowercase key)\n",
    "                if 'description' in data:\n",
    "                    original_description = data['description']\n",
    "                    flattened_description = flatten_description(original_description)\n",
    "                    data['description'] = flattened_description\n",
    "                    descriptions_flattened += 1\n",
    "                    \n",
    "                    # Debug info for first few records\n",
    "                    if line_num <= 3:\n",
    "                        desc_preview = flattened_description[:100] + \"...\" if len(flattened_description) > 100 else flattened_description\n",
    "                        print(f\"Line {line_num} - Description flattened: {len(flattened_description)} characters\")\n",
    "                        print(f\"  Preview: {desc_preview}\")\n",
    "                \n",
    "                # Write flattened data\n",
    "                outfile.write(json.dumps(data, ensure_ascii=False) + '\\n')\n",
    "                processed_count += 1\n",
    "                \n",
    "                # Progress indicator\n",
    "                if processed_count % 1000 == 0:\n",
    "                    print(f\"Processed {processed_count} records...\")\n",
    "                    \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON on line {line_num}: {e}\")\n",
    "                error_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error on line {line_num}: {e}\")\n",
    "                error_count += 1\n",
    "    \n",
    "    print(f\"\\nFlattening complete!\")\n",
    "    print(f\"Successfully processed: {processed_count} records\")\n",
    "    print(f\"Claims flattened: {claims_flattened} records\")\n",
    "    print(f\"Descriptions flattened: {descriptions_flattened} records\")\n",
    "    print(f\"Errors encountered: {error_count} records\")\n",
    "    print(f\"Output saved to: {output_file}\")\n",
    "\n",
    "def preview_flattening(input_file: str, num_lines: int = 2) -> None:\n",
    "    \"\"\"\n",
    "    Preview the flattening by showing before and after for first few lines.\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to input JSONL file\n",
    "        num_lines: Number of lines to preview\n",
    "    \"\"\"\n",
    "    print(f\"=== PREVIEW OF FLATTENING (First {num_lines} lines) ===\\n\")\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        for i in range(num_lines):\n",
    "            line = file.readline().strip()\n",
    "            if not line:\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                \n",
    "                print(f\"--- LINE {i+1} ---\")\n",
    "                \n",
    "                # Show claims before/after (lowercase key)\n",
    "                if 'claims' in data:\n",
    "                    original_claims = data['claims']\n",
    "                    flattened_claims = flatten_claims(original_claims)\n",
    "                    \n",
    "                    print(f\"CLAIMS:\")\n",
    "                    print(f\"  BEFORE: {type(original_claims).__name__} - Complex nested structure\")\n",
    "                    print(f\"  AFTER:  {type(flattened_claims).__name__} with {len(flattened_claims)} items\")\n",
    "                    \n",
    "                    if flattened_claims:\n",
    "                        preview = flattened_claims[0][:100] + \"...\" if len(flattened_claims[0]) > 100 else flattened_claims[0]\n",
    "                        print(f\"  First claim preview: {preview}\")\n",
    "                \n",
    "                # Show description before/after (lowercase key)\n",
    "                if 'description' in data:\n",
    "                    original_desc = data['description']\n",
    "                    flattened_desc = flatten_description(original_desc)\n",
    "                    \n",
    "                    print(f\"DESCRIPTION:\")\n",
    "                    print(f\"  BEFORE: {type(original_desc).__name__}\")\n",
    "                    if isinstance(original_desc, dict):\n",
    "                        print(f\"          Keys: {list(original_desc.keys())}\")\n",
    "                    print(f\"  AFTER:  {type(flattened_desc).__name__} with {len(flattened_desc)} characters\")\n",
    "                    \n",
    "                    if flattened_desc:\n",
    "                        preview = flattened_desc[:100] + \"...\" if len(flattened_desc) > 100 else flattened_desc\n",
    "                        print(f\"  Preview: {preview}\")\n",
    "                \n",
    "                print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing line {i+1}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"patents_data1_restructured.jsonl\"\n",
    "    \n",
    "    # First, preview the changes\n",
    "    print(\"PREVIEW MODE - Showing what changes will be made:\")\n",
    "    print(\"=\"*60)\n",
    "    preview_flattening(input_file, num_lines=2)\n",
    "    \n",
    "    # Ask for confirmation\n",
    "    response = input(\"Do you want to proceed with flattening the entire file? (y/n): \")\n",
    "    \n",
    "    if response.lower().strip() in ['y', 'yes']:\n",
    "        flatten_patent_data(input_file)\n",
    "    else:\n",
    "        print(\"Operation cancelled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4135848b-f574-4612-a1cd-e277275f2ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating JSONL structure...\n",
      "============================================================\n",
      "JSONL STRUCTURE VALIDATION REPORT\n",
      "============================================================\n",
      "📊 Total lines processed: 667\n",
      "✅ Valid lines: 667\n",
      "❌ Invalid lines: 0\n",
      "📈 Success rate: 100.00%\n",
      "🎯 Structure consistent: Yes\n",
      "\n",
      "📋 Field Presence Count:\n",
      "  abstract_text: 667\n",
      "  applicant_name: 667\n",
      "  claims: 667\n",
      "  cpc_symbols: 667\n",
      "  date_published: 667\n",
      "  description: 667\n",
      "  earliest_claim_date: 667\n",
      "  invention_title_text: 667\n",
      "  lens_id: 667\n",
      "\n",
      "🎉 All records have consistent structure!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Dict, Any\n",
    "from collections import defaultdict\n",
    "\n",
    "def validate_jsonl_structure(filename: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Validate the structure consistency of a JSONL file without making any changes.\n",
    "    \n",
    "    Args:\n",
    "        filename: Path to the JSONL file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing validation results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Expected structure\n",
    "    expected_fields = {\n",
    "        'abstract_text': str,\n",
    "        'applicant_name': str,\n",
    "        'claims': list,\n",
    "        'cpc_symbols': list,\n",
    "        'date_published': str,\n",
    "        'description': str,\n",
    "        'earliest_claim_date': str,\n",
    "        'invention_title_text': str,\n",
    "        'lens_id': str\n",
    "    }\n",
    "    \n",
    "    # Tracking variables\n",
    "    total_lines = 0\n",
    "    valid_lines = 0\n",
    "    errors = []\n",
    "    field_presence = defaultdict(int)\n",
    "    type_errors = defaultdict(list)\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            for line_num, line in enumerate(file, 1):\n",
    "                total_lines += 1\n",
    "                line = line.strip()\n",
    "                \n",
    "                if not line:  # Skip empty lines\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    # Parse JSON\n",
    "                    data = json.loads(line)\n",
    "                    \n",
    "                    # Check if it's a dictionary\n",
    "                    if not isinstance(data, dict):\n",
    "                        errors.append(f\"Line {line_num}: Not a JSON object\")\n",
    "                        continue\n",
    "                    \n",
    "                    line_valid = True\n",
    "                    \n",
    "                    # Check for missing fields\n",
    "                    missing_fields = set(expected_fields.keys()) - set(data.keys())\n",
    "                    if missing_fields:\n",
    "                        errors.append(f\"Line {line_num}: Missing fields: {missing_fields}\")\n",
    "                        line_valid = False\n",
    "                    \n",
    "                    # Check for extra fields\n",
    "                    extra_fields = set(data.keys()) - set(expected_fields.keys())\n",
    "                    if extra_fields:\n",
    "                        errors.append(f\"Line {line_num}: Extra fields: {extra_fields}\")\n",
    "                        line_valid = False\n",
    "                    \n",
    "                    # Check field types\n",
    "                    for field, expected_type in expected_fields.items():\n",
    "                        if field in data:\n",
    "                            field_presence[field] += 1\n",
    "                            if not isinstance(data[field], expected_type):\n",
    "                                actual_type = type(data[field]).__name__\n",
    "                                type_errors[field].append(f\"Line {line_num}: Expected {expected_type.__name__}, got {actual_type}\")\n",
    "                                line_valid = False\n",
    "                    \n",
    "                    if line_valid:\n",
    "                        valid_lines += 1\n",
    "                        \n",
    "                except json.JSONDecodeError as e:\n",
    "                    errors.append(f\"Line {line_num}: JSON decode error - {str(e)}\")\n",
    "                    \n",
    "    except FileNotFoundError:\n",
    "        return {\"error\": f\"File '{filename}' not found\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Unexpected error: {str(e)}\"}\n",
    "    \n",
    "    # Compile results\n",
    "    results = {\n",
    "        \"total_lines\": total_lines,\n",
    "        \"valid_lines\": valid_lines,\n",
    "        \"invalid_lines\": total_lines - valid_lines,\n",
    "        \"success_rate\": f\"{(valid_lines/total_lines*100):.2f}%\" if total_lines > 0 else \"0%\",\n",
    "        \"field_presence\": dict(field_presence),\n",
    "        \"structure_errors\": errors,\n",
    "        \"type_errors\": {field: errs for field, errs in type_errors.items()},\n",
    "        \"is_consistent\": len(errors) == 0 and len(type_errors) == 0\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_validation_report(results: Dict[str, Any]):\n",
    "    \"\"\"Print a formatted validation report.\"\"\"\n",
    "    \n",
    "    if \"error\" in results:\n",
    "        print(f\"❌ Error: {results['error']}\")\n",
    "        return\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"JSONL STRUCTURE VALIDATION REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(f\"📊 Total lines processed: {results['total_lines']}\")\n",
    "    print(f\"✅ Valid lines: {results['valid_lines']}\")\n",
    "    print(f\"❌ Invalid lines: {results['invalid_lines']}\")\n",
    "    print(f\"📈 Success rate: {results['success_rate']}\")\n",
    "    print(f\"🎯 Structure consistent: {'Yes' if results['is_consistent'] else 'No'}\")\n",
    "    \n",
    "    print(\"\\n📋 Field Presence Count:\")\n",
    "    for field, count in results['field_presence'].items():\n",
    "        print(f\"  {field}: {count}\")\n",
    "    \n",
    "    if results['structure_errors']:\n",
    "        print(f\"\\n⚠️  Structure Errors:\")\n",
    "        for error in results['structure_errors']:\n",
    "            print(f\"  {error}\")\n",
    "    \n",
    "    if results['type_errors']:\n",
    "        print(f\"\\n🔍 Type Errors:\")\n",
    "        for field, errors in results['type_errors'].items():\n",
    "            print(f\"  {field}:\")\n",
    "            for error in errors:\n",
    "                print(f\"    {error}\")\n",
    "    \n",
    "    if results['is_consistent']:\n",
    "        print(\"\\n🎉 All records have consistent structure!\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️  Found {results['invalid_lines']} inconsistent records out of {results['total_lines']} total.\")\n",
    "\n",
    "def check_specific_line(filename: str, line_number: int):\n",
    "    \"\"\"\n",
    "    Check a specific line for structure consistency.\n",
    "    \n",
    "    Args:\n",
    "        filename: Path to the JSONL file\n",
    "        line_number: Line number to check (1-indexed)\n",
    "    \"\"\"\n",
    "    \n",
    "    expected_fields = {\n",
    "        'abstract_text': str,\n",
    "        'applicant_name': str,\n",
    "        'claims': list,\n",
    "        'cpc_symbols': list,\n",
    "        'date_published': str,\n",
    "        'description': str,\n",
    "        'earliest_claim_date': str,\n",
    "        'invention_title_text': str,\n",
    "        'lens_id': str\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            for current_line, line in enumerate(file, 1):\n",
    "                if current_line == line_number:\n",
    "                    line = line.strip()\n",
    "                    \n",
    "                    if not line:\n",
    "                        print(f\"Line {line_number}: Empty line\")\n",
    "                        return\n",
    "                    \n",
    "                    try:\n",
    "                        data = json.loads(line)\n",
    "                        \n",
    "                        print(f\"Line {line_number} structure analysis:\")\n",
    "                        print(f\"  Fields present: {list(data.keys())}\")\n",
    "                        \n",
    "                        missing = set(expected_fields.keys()) - set(data.keys())\n",
    "                        extra = set(data.keys()) - set(expected_fields.keys())\n",
    "                        \n",
    "                        if missing:\n",
    "                            print(f\"  Missing fields: {missing}\")\n",
    "                        if extra:\n",
    "                            print(f\"  Extra fields: {extra}\")\n",
    "                        \n",
    "                        print(\"  Field types:\")\n",
    "                        for field, value in data.items():\n",
    "                            expected_type = expected_fields.get(field, \"Unknown\")\n",
    "                            actual_type = type(value).__name__\n",
    "                            status = \"✅\" if field in expected_fields and isinstance(value, expected_fields[field]) else \"❌\"\n",
    "                            print(f\"    {field}: {actual_type} {status}\")\n",
    "                        \n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Line {line_number}: JSON decode error - {str(e)}\")\n",
    "                    \n",
    "                    return\n",
    "            \n",
    "            print(f\"Line {line_number} not found in file\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{filename}' not found\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"av_patentdata.jsonl\"\n",
    "    \n",
    "    print(\"Validating JSONL structure...\")\n",
    "    results = validate_jsonl_structure(filename)\n",
    "    print_validation_report(results)\n",
    "    \n",
    "    # Option to check specific lines\n",
    "    if not results.get('is_consistent', False) and 'error' not in results:\n",
    "        while True:\n",
    "            try:\n",
    "                line_input = input(\"\\nEnter line number to inspect (or 'q' to quit): \")\n",
    "                if line_input.lower() == 'q':\n",
    "                    break\n",
    "                line_num = int(line_input)\n",
    "                check_specific_line(filename, line_num)\n",
    "            except ValueError:\n",
    "                print(\"Please enter a valid line number or 'q' to quit\")\n",
    "            except KeyboardInterrupt:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4f88c4-ac6f-457f-9006-303cc538391f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
