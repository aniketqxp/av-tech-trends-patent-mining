{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9284fa77-80bb-4a21-b1f7-f8fdcb2ba27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"GOOGLE_API_KEY not found...\")\n",
    "\n",
    "client = genai.Client(api_key=API_KEY)\n",
    "MODEL_TO_USE = \"gemini-1.5-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1398923-2115-4289-98ea-4ed64783e0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your prompt (or type 'exit' to quit):  hello there\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response:\n",
      " Hello there! How can I help you today?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your prompt (or type 'exit' to quit):  xit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response:\n",
      " \"xit\" isn't a command or a word with a standard meaning.  It might be:\n",
      "\n",
      "* **A typo:**  Perhaps you meant something else?  Could you clarify what you're trying to do or say?\n",
      "* **An abbreviation:**  In a specific context (like a game or program), it might have a particular meaning.  If so, please provide more context.\n",
      "* **A made-up word:**  It might be a newly coined term or slang.\n",
      "\n",
      "Please provide more information so I can understand what you need.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your prompt (or type 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    prompt = input(\"\\nEnter your prompt (or type 'exit' to quit): \")\n",
    "    if prompt.lower() == \"exit\":\n",
    "        break\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=MODEL_TO_USE,\n",
    "            contents=prompt\n",
    "        )\n",
    "        print(\"\\nResponse:\\n\", response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f3ac5ab-be30-4a8d-92f2-310bf34ad6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b23ca1fc-ee7f-451c-8072-bbb8f8a7fd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_patent(jsonl_file_path: str, patent_index: int = 0):\n",
    "    \"\"\"\n",
    "    Test function to process a single patent and display the results\n",
    "    \n",
    "    Args:\n",
    "        jsonl_file_path: Path to your JSONL file\n",
    "        patent_index: Index of the patent to test (0-based)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Setup API\n",
    "    load_dotenv()\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"GOOGLE_API_KEY not found in environment variables\")\n",
    "    \n",
    "    client = genai.Client(api_key=api_key)\n",
    "    model = \"gemini-1.5-flash\"\n",
    "    \n",
    "    # Load single patent\n",
    "    print(f\"Loading patent at index {patent_index}...\")\n",
    "    with open(jsonl_file_path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == patent_index:\n",
    "                patent_data = json.loads(line.strip())\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Patent index {patent_index} not found in file\")\n",
    "            return\n",
    "    \n",
    "    print(f\"Loaded patent: {patent_data.get('lens_id', '000-152-677-120-075')}\")\n",
    "    print(f\"Title: {patent_data.get('invention_title_text', 'No title')[:100]}...\")\n",
    "    \n",
    "    # Preprocess text function\n",
    "    def preprocess_text(text):\n",
    "        if pd.isna(text) or text == '':\n",
    "            return ''\n",
    "        text = str(text)\n",
    "        text = re.sub(r'\\b(fig\\.|figure)\\s*\\d+\\b', 'figure', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\bclaim\\s*\\d+\\b', 'claim', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "    \n",
    "    # Prepare patent text\n",
    "    def prepare_patent_text(patent_data, max_tokens=3000):\n",
    "        title = preprocess_text(patent_data.get('invention_title_text', ''))\n",
    "        abstract = preprocess_text(patent_data.get('abstract_text', ''))\n",
    "        \n",
    "        claims = patent_data.get('claims', [])\n",
    "        if isinstance(claims, list):\n",
    "            claims_text = ' '.join([str(claim) for claim in claims])\n",
    "        else:\n",
    "            claims_text = str(claims)\n",
    "        claims_text = preprocess_text(claims_text)\n",
    "        \n",
    "        # Estimate tokens (rough: 1 token ‚âà 4 characters)\n",
    "        def estimate_tokens(text):\n",
    "            return len(text) // 4\n",
    "        \n",
    "        combined_parts = []\n",
    "        total_tokens = 0\n",
    "        \n",
    "        if title:\n",
    "            combined_parts.append(f\"TITLE: {title}\")\n",
    "            total_tokens += estimate_tokens(title)\n",
    "        \n",
    "        if abstract and (total_tokens + estimate_tokens(abstract)) <= max_tokens:\n",
    "            combined_parts.append(f\"ABSTRACT: {abstract}\")\n",
    "            total_tokens += estimate_tokens(abstract)\n",
    "        \n",
    "        remaining_tokens = max_tokens - total_tokens\n",
    "        if claims_text and remaining_tokens > 100:\n",
    "            if estimate_tokens(claims_text) <= remaining_tokens:\n",
    "                combined_parts.append(f\"CLAIMS: {claims_text}\")\n",
    "                total_tokens += estimate_tokens(claims_text)\n",
    "            else:\n",
    "                max_chars = remaining_tokens * 4\n",
    "                truncated_claims = claims_text[:max_chars]\n",
    "                combined_parts.append(f\"CLAIMS: {truncated_claims}\")\n",
    "                total_tokens += estimate_tokens(truncated_claims)\n",
    "        \n",
    "        return \"\\n\\n\".join(combined_parts), total_tokens\n",
    "    \n",
    "    # Prepare the patent text\n",
    "    patent_text, token_count = prepare_patent_text(patent_data)\n",
    "    \n",
    "    print(f\"\\nPrepared text (‚âà{token_count} tokens):\")\n",
    "    print(\"-\" * 50)\n",
    "    print(patent_text[:500] + \"...\" if len(patent_text) > 500 else patent_text)\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Create analysis prompt\n",
    "    prompt = f\"\"\"\n",
    "You are an expert patent analyst specializing in autonomous vehicle technologies. Analyze the following patent and provide a structured analysis.\n",
    "\n",
    "PATENT CONTENT:\n",
    "{patent_text}\n",
    "\n",
    "Please provide your analysis in the following EXACT JSON format (ensure valid JSON syntax):\n",
    "\n",
    "{{\n",
    "    \"core_innovation\": {{\n",
    "        \"problem_addressed\": \"Brief description of the main problem this patent addresses\",\n",
    "        \"proposed_solution\": \"Brief description of the key solution or innovation\",\n",
    "        \"novelty_aspect\": \"What makes this innovation novel or unique\",\n",
    "        \"technical_approach\": \"Brief description of the technical approach used\"\n",
    "    }},\n",
    "    \"conceptual_categories\": {{\n",
    "        \"primary_category\": \"The main category this patent falls into\",\n",
    "        \"secondary_categories\": [\"List of additional relevant categories\"],\n",
    "        \"confidence_score\": \"High/Medium/Low confidence in categorization\"\n",
    "    }},\n",
    "    \"av_technology_areas\": [\n",
    "        \"List of relevant AV technology areas from: perception_sensing, localization_mapping, path_planning_control, ai_ml_architecture, v2x_communication, safety_validation, simulation_testing, cybersecurity, human_machine_interface, hardware_sensors, software_algorithms, data_processing, vehicle_control_systems, other\"\n",
    "    ]\n",
    "}}\n",
    "\n",
    "IMPORTANT: \n",
    "- Respond ONLY with valid JSON - no additional text or explanations\n",
    "- Use the exact field names shown above\n",
    "- Keep descriptions concise but informative (max 2-3 sentences each)\n",
    "- For av_technology_areas, select from the provided list only\n",
    "- If uncertain about a field, use \"Not clearly specified\" rather than leaving empty\n",
    "\"\"\"\n",
    "    \n",
    "    # Call API\n",
    "    print(\"\\nCalling Gemini API...\")\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=model,\n",
    "            contents=prompt\n",
    "        )\n",
    "        \n",
    "        # Parse response\n",
    "        response_text = response.text.strip()\n",
    "        print(f\"\\nRaw API Response:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(response_text)\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Try to extract JSON if wrapped in markdown\n",
    "        if \"```json\" in response_text:\n",
    "            start = response_text.find(\"```json\") + 7\n",
    "            end = response_text.find(\"```\", start)\n",
    "            if end > start:\n",
    "                response_text = response_text[start:end].strip()\n",
    "        elif \"```\" in response_text:\n",
    "            start = response_text.find(\"```\") + 3\n",
    "            end = response_text.find(\"```\", start)\n",
    "            if end > start:\n",
    "                response_text = response_text[start:end].strip()\n",
    "        \n",
    "        # Parse JSON\n",
    "        analysis_result = json.loads(response_text)\n",
    "        \n",
    "        print(f\"\\nParsed JSON Result:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(json.dumps(analysis_result, indent=2))\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Show structured output\n",
    "        print(f\"\\nStructured Analysis for Patent: {patent_data.get('lens_id', '000-152-677-120-075')}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        core_innovation = analysis_result.get('core_innovation', {})\n",
    "        print(f\"PROBLEM ADDRESSED: {core_innovation.get('problem_addressed', 'N/A')}\")\n",
    "        print(f\"PROPOSED SOLUTION: {core_innovation.get('proposed_solution', 'N/A')}\")\n",
    "        print(f\"NOVELTY ASPECT: {core_innovation.get('novelty_aspect', 'N/A')}\")\n",
    "        print(f\"TECHNICAL APPROACH: {core_innovation.get('technical_approach', 'N/A')}\")\n",
    "        \n",
    "        categories = analysis_result.get('conceptual_categories', {})\n",
    "        print(f\"\\nPRIMARY CATEGORY: {categories.get('primary_category', 'N/A')}\")\n",
    "        print(f\"SECONDARY CATEGORIES: {categories.get('secondary_categories', [])}\")\n",
    "        print(f\"CONFIDENCE: {categories.get('confidence_score', 'N/A')}\")\n",
    "        \n",
    "        print(f\"\\nAV TECHNOLOGY AREAS: {analysis_result.get('av_technology_areas', [])}\")\n",
    "        \n",
    "        # Create final result structure\n",
    "        final_result = {\n",
    "            # Original patent metadata\n",
    "            'lens_id': patent_data.get('lens_id', ''),\n",
    "            'invention_title_text': patent_data.get('invention_title_text', ''),\n",
    "            'abstract_text': patent_data.get('abstract_text', ''),\n",
    "            'applicant_name': patent_data.get('applicant_name', ''),\n",
    "            'date_published': patent_data.get('date_published', ''),\n",
    "            'earliest_claim_date': patent_data.get('earliest_claim_date', ''),\n",
    "            'cpc_symbols': patent_data.get('cpc_symbols', []),\n",
    "            \n",
    "            # Analysis results\n",
    "            'problem_addressed': core_innovation.get('problem_addressed', ''),\n",
    "            'proposed_solution': core_innovation.get('proposed_solution', ''),\n",
    "            'novelty_aspect': core_innovation.get('novelty_aspect', ''),\n",
    "            'technical_approach': core_innovation.get('technical_approach', ''),\n",
    "            'primary_category': categories.get('primary_category', ''),\n",
    "            'secondary_categories': categories.get('secondary_categories', []),\n",
    "            'categorization_confidence': categories.get('confidence_score', ''),\n",
    "            'av_technology_areas': analysis_result.get('av_technology_areas', []),\n",
    "            \n",
    "            # Processing metadata\n",
    "            'processing_timestamp': datetime.now().isoformat(),\n",
    "            'estimated_tokens': token_count\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nFinal DataFrame Row Structure:\")\n",
    "        print(\"=\" * 60)\n",
    "        for key, value in final_result.items():\n",
    "            if isinstance(value, str) and len(value) > 100:\n",
    "                print(f\"{key}: {value[:100]}...\")\n",
    "            else:\n",
    "                print(f\"{key}: {value}\")\n",
    "        \n",
    "        return final_result, analysis_result\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing error: {e}\")\n",
    "        print(f\"Raw response: {response_text}\")\n",
    "        return None, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa10993a-e59b-4dd0-8807-61f1aa87e2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 20:58:25,302 - INFO - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading patent at index 0...\n",
      "Loaded patent: 143-105-704-034-927\n",
      "Title: Group driving style learning framework for autonomous vehicles...\n",
      "\n",
      "Prepared text (‚âà3000 tokens):\n",
      "--------------------------------------------------\n",
      "TITLE: Group driving style learning framework for autonomous vehicles\n",
      "\n",
      "ABSTRACT: A social driving style learning framework or system for autonomous vehicles is utilized, which can dynamically learn the social driving styles from surrounding vehicles and adopt the driving style as needed. Each of the autonomous vehicles within a particular driving area is equipped with the driving style learning system to perceive the driving behaviors of the surrounding vehicles to derive a set of driving style ...\n",
      "--------------------------------------------------\n",
      "\n",
      "Calling Gemini API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 20:58:25,765 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-1.5-flash'}, 'quotaValue': '500'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '33s'}]}}\n",
      "\n",
      "‚ùå Test failed. Check the error messages above.\n"
     ]
    }
   ],
   "source": [
    "# Test usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with first patent (index 0)\n",
    "    result, raw_analysis = test_single_patent(\"av_patentdata.jsonl\", patent_index=0)\n",
    "    \n",
    "    if result:\n",
    "        print(\"\\n‚úÖ Test completed successfully!\")\n",
    "        print(\"You can now run the full pipeline with confidence.\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Test failed. Check the error messages above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e056fa1-79f9-4e4c-9e7a-80c72be7b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "from typing import Dict, List, Optional, Any\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c21647-0cfd-4e0c-9d87-33db5d6d28a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatentAnalysisPipeline:\n",
    "    \"\"\"\n",
    "    Pipeline for analyzing patent data using Gemini API to extract core innovations\n",
    "    and categorize patents into conceptual categories.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, jsonl_file_path: str, output_dir: str = \"output\"):\n",
    "        \"\"\"\n",
    "        Initialize the pipeline\n",
    "        \n",
    "        Args:\n",
    "            jsonl_file_path: Path to the JSONL file containing patent data\n",
    "            output_dir: Directory to save output files\n",
    "        \"\"\"\n",
    "        self.jsonl_file_path = jsonl_file_path\n",
    "        self.output_dir = output_dir\n",
    "        self.data = None\n",
    "        self.processed_data = []\n",
    "        self.failed_patents = []\n",
    "        \n",
    "        # Load environment and setup API\n",
    "        self.setup_api()\n",
    "        \n",
    "        # Create output directory\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Token limits and processing parameters\n",
    "        self.max_tokens_per_patent = 3000  # Conservative limit for Gemini\n",
    "        self.base_delay = 2  # Base delay between requests (seconds)\n",
    "        self.max_delay = 300  # Maximum delay cap (5 minutes)\n",
    "    \n",
    "    def setup_api(self):\n",
    "        \"\"\"Setup Gemini API client\"\"\"\n",
    "        load_dotenv()\n",
    "        self.api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"GOOGLE_API_KEY not found in environment variables\")\n",
    "        \n",
    "        self.client = genai.Client(api_key=self.api_key)\n",
    "        self.model = \"gemini-1.5-flash\"\n",
    "    \n",
    "    def load_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Load and parse JSONL file, keeping only records missing from the JSON checkpoint\"\"\"\n",
    "    \n",
    "        # Define the file paths\n",
    "        json_path = r\"C:\\Users\\Aniket Shinde\\Desktop\\Main\\Jupyter Notebooks\\patent_analysis_output\\processed_patents_checkpoint_650_20250616_193652.json\"\n",
    "        csv_path = \"lens-export.csv\"\n",
    "    \n",
    "        # Step 1: Load existing JSON and collect lens_ids\n",
    "        try:\n",
    "            with open(json_path, 'r', encoding='utf-8') as f_json:\n",
    "                json_data = json.load(f_json)\n",
    "                json_lens_ids = {patent.get(\"lens_id\") for patent in json_data if \"lens_id\" in patent}\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error reading JSON checkpoint: {e}\")\n",
    "    \n",
    "        # Step 2: Load CSV and collect all lens_ids\n",
    "        csv_lens_ids = set()\n",
    "        try:\n",
    "            with open(csv_path, 'r', encoding='utf-8') as f_csv:\n",
    "                reader = csv.DictReader(f_csv)\n",
    "                for row in reader:\n",
    "                    lens_id = row.get(\"Lens ID\")\n",
    "                    if lens_id:\n",
    "                        csv_lens_ids.add(lens_id)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error reading CSV file: {e}\")\n",
    "    \n",
    "        # Step 3: Identify lens_ids missing from JSON\n",
    "        missing_lens_ids = csv_lens_ids - json_lens_ids\n",
    "        print(f\"Number of patents in JSON: {len(json_lens_ids)}\")\n",
    "        print(f\"Number of patents in CSV: {len(csv_lens_ids)}\")\n",
    "        print(f\"Number of missing patents in JSON: {len(missing_lens_ids)}\")\n",
    "    \n",
    "        # Step 4: Read only missing patents from JSONL\n",
    "        data = []\n",
    "        try:\n",
    "            with open(self.jsonl_file_path, 'r', encoding='utf-8') as f_jsonl:\n",
    "                for line in f_jsonl:\n",
    "                    try:\n",
    "                        record = json.loads(line.strip())\n",
    "                        if record.get(\"lens_id\") in missing_lens_ids:\n",
    "                            data.append(record)\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "    \n",
    "            self.data = pd.DataFrame(data)\n",
    "            return self.data\n",
    "    \n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"File not found: {self.jsonl_file_path}\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error loading data from JSONL: {e}\")\n",
    "    \n",
    "    def preprocess_text(self, text: str) -> str:\n",
    "        \"\"\"Clean and preprocess text for better LLM processing\"\"\"\n",
    "        if pd.isna(text) or text == '':\n",
    "            return ''\n",
    "        \n",
    "        # Convert to string if not already\n",
    "        text = str(text)\n",
    "        \n",
    "        # Clean figure and claim references\n",
    "        text = re.sub(r'\\b(fig\\.|figure)\\s*\\d+\\b', 'figure', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\bclaim\\s*\\d+\\b', 'claim', text, flags=re.IGNORECASE)\n",
    "        \n",
    "        # Remove excessive whitespace and normalize\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = text.strip()\n",
    "        \n",
    "        return text\n",
    "\n",
    "    def extract_retry_delay(self, error_details: str) -> int:\n",
    "        \"\"\"Extract retry delay from API error response\"\"\"\n",
    "        try:\n",
    "            # Look for retryDelay in the error message\n",
    "            delay_match = re.search(r\"'retryDelay':\\s*'(\\d+)s'\", error_details)\n",
    "            if delay_match:\n",
    "                return int(delay_match.group(1))\n",
    "            \n",
    "            # Fallback: look for other delay patterns\n",
    "            delay_match = re.search(r\"retry.*?(\\d+)\\s*s\", error_details, re.IGNORECASE)\n",
    "            if delay_match:\n",
    "                return int(delay_match.group(1))\n",
    "                \n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        return 60  # Default fallback\n",
    "    \n",
    "    def prepare_patent_text(self, patent_row: pd.Series) -> tuple[str, int]:\n",
    "        \"\"\"\n",
    "        Prepare combined text for a single patent with token management\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (combined_text, estimated_tokens)\n",
    "        \"\"\"\n",
    "        # Extract and clean components\n",
    "        title = self.preprocess_text(patent_row.get('invention_title_text', ''))\n",
    "        abstract = self.preprocess_text(patent_row.get('abstract_text', ''))\n",
    "        \n",
    "        # Handle claims - convert list to string\n",
    "        claims = patent_row.get('claims', [])\n",
    "        if isinstance(claims, list):\n",
    "            claims_text = ' '.join([str(claim) for claim in claims])\n",
    "        else:\n",
    "            claims_text = str(claims)\n",
    "        claims_text = self.preprocess_text(claims_text)\n",
    "        \n",
    "        # Estimate tokens (rough approximation: 1 token ‚âà 4 characters)\n",
    "        def estimate_tokens(text):\n",
    "            return len(text) // 4\n",
    "        \n",
    "        title_tokens = estimate_tokens(title)\n",
    "        abstract_tokens = estimate_tokens(abstract)\n",
    "        claims_tokens = estimate_tokens(claims_text)\n",
    "        \n",
    "        # Build combined text with priority: title (always include) -> abstract -> claims\n",
    "        combined_parts = []\n",
    "        total_tokens = 0\n",
    "        \n",
    "        # Always include title\n",
    "        if title:\n",
    "            combined_parts.append(f\"TITLE: {title}\")\n",
    "            total_tokens += title_tokens\n",
    "        \n",
    "        # Include abstract if space allows\n",
    "        if abstract and (total_tokens + abstract_tokens) <= self.max_tokens_per_patent:\n",
    "            combined_parts.append(f\"ABSTRACT: {abstract}\")\n",
    "            total_tokens += abstract_tokens\n",
    "        \n",
    "        # Include claims if space allows (truncate if necessary)\n",
    "        remaining_tokens = self.max_tokens_per_patent - total_tokens\n",
    "        if claims_text and remaining_tokens > 100:  # Keep some buffer\n",
    "            if claims_tokens <= remaining_tokens:\n",
    "                combined_parts.append(f\"CLAIMS: {claims_text}\")\n",
    "                total_tokens += claims_tokens\n",
    "            else:\n",
    "                # Truncate claims to fit\n",
    "                max_chars = remaining_tokens * 4\n",
    "                truncated_claims = claims_text[:max_chars]\n",
    "                combined_parts.append(f\"CLAIMS: {truncated_claims}\")\n",
    "                total_tokens += estimate_tokens(truncated_claims)\n",
    "        \n",
    "        combined_text = \"\\n\\n\".join(combined_parts)\n",
    "        return combined_text, total_tokens\n",
    "    \n",
    "    def create_analysis_prompt(self, patent_text: str) -> str:\n",
    "        \"\"\"Create the analysis prompt for Gemini API\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "You are an expert patent analyst specializing in autonomous vehicle technologies. Analyze the following patent and provide a structured analysis.\n",
    "\n",
    "PATENT CONTENT:\n",
    "{patent_text}\n",
    "\n",
    "Please provide your analysis in the following EXACT JSON format (ensure valid JSON syntax):\n",
    "\n",
    "{{\n",
    "    \"core_innovation\": {{\n",
    "        \"problem_addressed\": \"Brief description of the main problem this patent addresses\",\n",
    "        \"proposed_solution\": \"Brief description of the key solution or innovation\",\n",
    "        \"novelty_aspect\": \"What makes this innovation novel or unique\",\n",
    "        \"technical_approach\": \"Brief description of the technical approach used\"\n",
    "    }},\n",
    "    \"conceptual_categories\": {{\n",
    "        \"primary_category\": \"The main category this patent falls into\",\n",
    "        \"secondary_categories\": [\"List of additional relevant categories\"],\n",
    "        \"confidence_score\": \"High/Medium/Low confidence in categorization\"\n",
    "    }},\n",
    "    \"av_technology_areas\": [\n",
    "        \"List of relevant AV technology areas from: perception_sensing, localization_mapping, path_planning_control, ai_ml_architecture, v2x_communication, safety_validation, simulation_testing, cybersecurity, human_machine_interface, hardware_sensors, software_algorithms, data_processing, vehicle_control_systems, other\"\n",
    "    ]\n",
    "}}\n",
    "\n",
    "IMPORTANT: \n",
    "- Respond ONLY with valid JSON - no additional text or explanations\n",
    "- Use the exact field names shown above\n",
    "- Keep descriptions concise but informative (max 2-3 sentences each)\n",
    "- For av_technology_areas, select from the provided list only\n",
    "- If uncertain about a field, use \"Not clearly specified\" rather than leaving empty\n",
    "\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def call_gemini_api(self, prompt: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Call Gemini API with robust retry logic that respects API limits\n",
    "        \"\"\"\n",
    "        attempt = 0\n",
    "        \n",
    "        while True:\n",
    "            attempt += 1\n",
    "            \n",
    "            try:\n",
    "                # Always wait before making a request (except first attempt)\n",
    "                if attempt > 1:\n",
    "                    time.sleep(self.base_delay)\n",
    "                \n",
    "                response = self.client.models.generate_content(\n",
    "                    model=self.model,\n",
    "                    contents=prompt\n",
    "                )\n",
    "                \n",
    "                # Parse JSON response\n",
    "                response_text = response.text.strip()\n",
    "                \n",
    "                # Try to extract JSON if wrapped in markdown code blocks\n",
    "                if \"```json\" in response_text:\n",
    "                    start = response_text.find(\"```json\") + 7\n",
    "                    end = response_text.find(\"```\", start)\n",
    "                    if end > start:\n",
    "                        response_text = response_text[start:end].strip()\n",
    "                elif \"```\" in response_text:\n",
    "                    start = response_text.find(\"```\") + 3\n",
    "                    end = response_text.find(\"```\", start)\n",
    "                    if end > start:\n",
    "                        response_text = response_text[start:end].strip()\n",
    "                \n",
    "                # Parse JSON\n",
    "                parsed_response = json.loads(response_text)\n",
    "                return parsed_response\n",
    "                \n",
    "            except json.JSONDecodeError:\n",
    "                # For JSON decode errors, try a few times then give up\n",
    "                if attempt >= 3:\n",
    "                    return None\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_str = str(e)\n",
    "                \n",
    "                # Handle 429 RESOURCE_EXHAUSTED - respect the API's suggested delay\n",
    "                if \"429\" in error_str and \"RESOURCE_EXHAUSTED\" in error_str:\n",
    "                    retry_delay = self.extract_retry_delay(error_str)\n",
    "                    # Add 50% buffer to the suggested delay to be extra safe\n",
    "                    actual_delay = min(int(retry_delay * 1.5), self.max_delay)\n",
    "                    print(f\"Rate limit hit (429). Waiting {actual_delay} seconds...\")\n",
    "                    time.sleep(actual_delay)\n",
    "                    continue\n",
    "                \n",
    "                # Handle server errors (5xx) - use exponential backoff\n",
    "                elif any(code in error_str for code in [\"500\", \"502\", \"503\", \"504\", \"520\", \"521\", \"522\", \"523\", \"524\"]):\n",
    "                    delay = min(self.base_delay * (2 ** min(attempt - 1, 6)), self.max_delay)\n",
    "                    print(f\"Server error (attempt {attempt}). Waiting {delay} seconds...\")\n",
    "                    time.sleep(delay)\n",
    "                    continue\n",
    "                \n",
    "                # Handle client errors (4xx except 429) - these are permanent\n",
    "                elif any(code in error_str for code in [\"400\", \"401\", \"403\", \"404\"]):\n",
    "                    return None\n",
    "                \n",
    "                # Unknown errors - try with exponential backoff\n",
    "                else:\n",
    "                    if attempt <= 5:\n",
    "                        delay = min(self.base_delay * (2 ** min(attempt - 1, 4)), self.max_delay)\n",
    "                        print(f\"Unknown error (attempt {attempt}). Waiting {delay} seconds...\")\n",
    "                        time.sleep(delay)\n",
    "                        continue\n",
    "                    else:\n",
    "                        return None\n",
    "    \n",
    "    def process_single_patent(self, idx: int, patent_row: pd.Series) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Process a single patent and return the analysis\"\"\"\n",
    "        lens_id = patent_row.get('lens_id', f'patent_{idx}')\n",
    "        \n",
    "        try:\n",
    "            # Prepare patent text\n",
    "            patent_text, token_count = self.prepare_patent_text(patent_row)\n",
    "            \n",
    "            if not patent_text.strip():\n",
    "                return None\n",
    "            \n",
    "            print(f\"Processing patent {idx + 1}: {lens_id} (~{token_count} tokens)\")\n",
    "            \n",
    "            # Create prompt and call API\n",
    "            prompt = self.create_analysis_prompt(patent_text)\n",
    "            analysis_result = self.call_gemini_api(prompt)\n",
    "            \n",
    "            if analysis_result is None:\n",
    "                return None\n",
    "            \n",
    "            # Combine original data with analysis\n",
    "            result = {\n",
    "                # Original patent metadata\n",
    "                'lens_id': lens_id,\n",
    "                'invention_title_text': patent_row.get('invention_title_text', ''),\n",
    "                'abstract_text': patent_row.get('abstract_text', ''),\n",
    "                'applicant_name': patent_row.get('applicant_name', ''),\n",
    "                'date_published': patent_row.get('date_published', ''),\n",
    "                'earliest_claim_date': patent_row.get('earliest_claim_date', ''),\n",
    "                'cpc_symbols': patent_row.get('cpc_symbols', []),\n",
    "                'claims': patent_row.get('claims', []),\n",
    "                'description': patent_row.get('description', ''),\n",
    "                \n",
    "                # Analysis results\n",
    "                'problem_addressed': analysis_result.get('core_innovation', {}).get('problem_addressed', ''),\n",
    "                'proposed_solution': analysis_result.get('core_innovation', {}).get('proposed_solution', ''),\n",
    "                'novelty_aspect': analysis_result.get('core_innovation', {}).get('novelty_aspect', ''),\n",
    "                'technical_approach': analysis_result.get('core_innovation', {}).get('technical_approach', ''),\n",
    "                'primary_category': analysis_result.get('conceptual_categories', {}).get('primary_category', ''),\n",
    "                'secondary_categories': analysis_result.get('conceptual_categories', {}).get('secondary_categories', []),\n",
    "                'categorization_confidence': analysis_result.get('conceptual_categories', {}).get('confidence_score', ''),\n",
    "                'av_technology_areas': analysis_result.get('av_technology_areas', []),\n",
    "                \n",
    "                # Processing metadata\n",
    "                'processing_timestamp': datetime.now().isoformat(),\n",
    "                'estimated_tokens': token_count\n",
    "            }\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception:\n",
    "            return None\n",
    "    \n",
    "    def process_all_patents(self, start_idx: int = 0, batch_size: int = 50):\n",
    "        \"\"\"\n",
    "        Process all patents in the dataset with conservative rate limiting\n",
    "        \n",
    "        Args:\n",
    "            start_idx: Index to start processing from (for resuming)\n",
    "            batch_size: Save progress every N patents\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            self.load_data()\n",
    "        \n",
    "        total_patents = len(self.data)\n",
    "        print(f\"Starting to process {total_patents - start_idx} patents (starting from index {start_idx})\")\n",
    "        \n",
    "        for idx in range(start_idx, total_patents):\n",
    "            patent_row = self.data.iloc[idx]\n",
    "            lens_id = patent_row.get('lens_id', f'patent_{idx}')\n",
    "            \n",
    "            print(f\"Processing patent {idx + 1}/{total_patents}: {lens_id}\")\n",
    "            \n",
    "            # Process single patent\n",
    "            result = self.process_single_patent(idx, patent_row)\n",
    "            \n",
    "            if result is not None:\n",
    "                self.processed_data.append(result)\n",
    "                print(f\"‚úì Successfully processed patent {idx + 1}/{total_patents}\")\n",
    "            else:\n",
    "                self.failed_patents.append({\n",
    "                    'index': idx,\n",
    "                    'lens_id': lens_id,\n",
    "                    'reason': 'Processing failed'\n",
    "                })\n",
    "                print(f\"‚úó Failed to process patent {idx + 1}/{total_patents}\")\n",
    "            \n",
    "            # Always add delay between patents to be conservative\n",
    "            if idx < total_patents - 1:  # Don't delay after the last patent\n",
    "                time.sleep(self.base_delay)\n",
    "            \n",
    "            # Save progress periodically\n",
    "            if (idx + 1) % batch_size == 0:\n",
    "                self.save_progress(f\"checkpoint_{idx + 1}\")\n",
    "                print(f\"üìÅ Saved progress at patent {idx + 1}\")\n",
    "        \n",
    "        # Final save\n",
    "        self.save_results()\n",
    "        print(f\"Processing complete! Successfully processed {len(self.processed_data)} patents\")\n",
    "        print(f\"Failed patents: {len(self.failed_patents)}\")\n",
    "    \n",
    "    def save_progress(self, filename_suffix: str = \"\"):\n",
    "        \"\"\"Save current progress to files\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        if filename_suffix:\n",
    "            progress_file = f\"{self.output_dir}/processed_patents_{filename_suffix}_{timestamp}.json\"\n",
    "        else:\n",
    "            progress_file = f\"{self.output_dir}/processed_patents_{timestamp}.json\"\n",
    "        \n",
    "        # Save processed data\n",
    "        with open(progress_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.processed_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # Save failed patents log\n",
    "        failed_file = f\"{self.output_dir}/failed_patents_{timestamp}.json\"\n",
    "        with open(failed_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.failed_patents, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"Progress saved to {progress_file}\")\n",
    "    \n",
    "    def save_results(self):\n",
    "        \"\"\"Save final results as DataFrame and various formats\"\"\"\n",
    "        if not self.processed_data:\n",
    "            print(\"No processed data to save\")\n",
    "            return\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(self.processed_data)\n",
    "        \n",
    "        # Save as different formats\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # CSV\n",
    "        csv_file = f\"{self.output_dir}/patent_analysis_results_{timestamp}.csv\"\n",
    "        df.to_csv(csv_file, index=False, encoding='utf-8')\n",
    "        \n",
    "        # Excel\n",
    "        excel_file = f\"{self.output_dir}/patent_analysis_results_{timestamp}.xlsx\"\n",
    "        df.to_excel(excel_file, index=False, engine='openpyxl')\n",
    "        \n",
    "        # JSON\n",
    "        json_file = f\"{self.output_dir}/patent_analysis_results_{timestamp}.json\"\n",
    "        df.to_json(json_file, orient='records', indent=2, force_ascii=False)\n",
    "        \n",
    "        # Pickle for future use\n",
    "        pickle_file = f\"{self.output_dir}/patent_analysis_results_{timestamp}.pkl\"\n",
    "        df.to_pickle(pickle_file)\n",
    "        \n",
    "        print(f\"Results saved in multiple formats with timestamp {timestamp}\")\n",
    "        \n",
    "        # Print summary statistics\n",
    "        self.print_summary_stats(df)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def print_summary_stats(self, df: pd.DataFrame):\n",
    "        \"\"\"Print summary statistics of the processing results\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"PROCESSING SUMMARY\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Total patents processed: {len(df)}\")\n",
    "        print(f\"Total patents failed: {len(self.failed_patents)}\")\n",
    "        print(f\"Success rate: {len(df)/(len(df) + len(self.failed_patents))*100:.1f}%\")\n",
    "        \n",
    "        if len(df) > 0:\n",
    "            print(f\"\\nTop Primary Categories:\")\n",
    "            primary_cats = df['primary_category'].value_counts().head(10)\n",
    "            for cat, count in primary_cats.items():\n",
    "                print(f\"  {cat}: {count}\")\n",
    "            \n",
    "            print(f\"\\nTop AV Technology Areas:\")\n",
    "            # Flatten the list of lists\n",
    "            all_areas = []\n",
    "            for areas in df['av_technology_areas']:\n",
    "                if isinstance(areas, list):\n",
    "                    all_areas.extend(areas)\n",
    "            area_counts = pd.Series(all_areas).value_counts().head(10)\n",
    "            for area, count in area_counts.items():\n",
    "                print(f\"  {area}: {count}\")\n",
    "        \n",
    "        print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de459ca4-b134-4299-8200-74e7eb2c057a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patents in JSON: 493\n",
      "Number of patents in CSV: 667\n",
      "Number of missing patents in JSON: 174\n",
      "Starting to process 174 patents (starting from index 0)\n",
      "Processing patent 1/174: 196-557-021-684-98X\n",
      "Processing patent 1: 196-557-021-684-98X (~746 tokens)\n",
      "‚úì Successfully processed patent 1/174\n",
      "Processing patent 2/174: 097-230-147-819-508\n",
      "Processing patent 2: 097-230-147-819-508 (~2568 tokens)\n",
      "‚úì Successfully processed patent 2/174\n",
      "Processing patent 3/174: 165-884-370-654-504\n",
      "Processing patent 3: 165-884-370-654-504 (~2386 tokens)\n",
      "‚úì Successfully processed patent 3/174\n",
      "Processing patent 4/174: 175-337-774-629-516\n",
      "Processing patent 4: 175-337-774-629-516 (~1716 tokens)\n",
      "‚úì Successfully processed patent 4/174\n",
      "Processing patent 5/174: 185-160-791-286-190\n",
      "Processing patent 5: 185-160-791-286-190 (~1774 tokens)\n",
      "‚úì Successfully processed patent 5/174\n",
      "Processing patent 6/174: 158-879-448-169-219\n",
      "Processing patent 6: 158-879-448-169-219 (~3000 tokens)\n",
      "‚úì Successfully processed patent 6/174\n",
      "Processing patent 7/174: 021-382-421-165-451\n",
      "Processing patent 7: 021-382-421-165-451 (~2970 tokens)\n",
      "‚úì Successfully processed patent 7/174\n",
      "Processing patent 8/174: 035-513-494-375-092\n",
      "Processing patent 8: 035-513-494-375-092 (~1414 tokens)\n",
      "‚úì Successfully processed patent 8/174\n",
      "Processing patent 9/174: 146-320-903-404-194\n",
      "Processing patent 9: 146-320-903-404-194 (~2285 tokens)\n",
      "‚úì Successfully processed patent 9/174\n",
      "Processing patent 10/174: 094-369-473-781-696\n",
      "Processing patent 10: 094-369-473-781-696 (~2707 tokens)\n",
      "‚úì Successfully processed patent 10/174\n",
      "Progress saved to patent_analysis_output1/processed_patents_checkpoint_10_20250617_090931.json\n",
      "üìÅ Saved progress at patent 10\n",
      "Processing patent 11/174: 157-924-235-494-222\n",
      "Processing patent 11: 157-924-235-494-222 (~3000 tokens)\n",
      "‚úì Successfully processed patent 11/174\n",
      "Processing patent 12/174: 025-635-593-546-830\n",
      "Processing patent 12: 025-635-593-546-830 (~2642 tokens)\n",
      "‚úì Successfully processed patent 12/174\n",
      "Processing patent 13/174: 116-835-229-588-01X\n",
      "Processing patent 13: 116-835-229-588-01X (~2844 tokens)\n",
      "‚úì Successfully processed patent 13/174\n",
      "Processing patent 14/174: 102-417-092-882-495\n",
      "Processing patent 14: 102-417-092-882-495 (~3000 tokens)\n",
      "‚úì Successfully processed patent 14/174\n",
      "Processing patent 15/174: 022-953-362-574-29X\n",
      "Processing patent 15: 022-953-362-574-29X (~2551 tokens)\n",
      "‚úì Successfully processed patent 15/174\n",
      "Processing patent 16/174: 182-045-319-534-59X\n",
      "Processing patent 16: 182-045-319-534-59X (~2568 tokens)\n",
      "‚úì Successfully processed patent 16/174\n",
      "Processing patent 17/174: 192-586-311-363-276\n",
      "Processing patent 17: 192-586-311-363-276 (~3000 tokens)\n",
      "‚úì Successfully processed patent 17/174\n",
      "Processing patent 18/174: 035-961-451-891-408\n",
      "Processing patent 18: 035-961-451-891-408 (~1951 tokens)\n",
      "‚úì Successfully processed patent 18/174\n",
      "Processing patent 19/174: 019-860-269-598-923\n",
      "Processing patent 19: 019-860-269-598-923 (~3000 tokens)\n",
      "‚úì Successfully processed patent 19/174\n",
      "Processing patent 20/174: 090-323-946-857-971\n",
      "Processing patent 20: 090-323-946-857-971 (~2162 tokens)\n",
      "‚úì Successfully processed patent 20/174\n",
      "Progress saved to patent_analysis_output1/processed_patents_checkpoint_20_20250617_091017.json\n",
      "üìÅ Saved progress at patent 20\n",
      "Processing patent 21/174: 192-813-724-793-917\n",
      "Processing patent 21: 192-813-724-793-917 (~3000 tokens)\n",
      "‚úì Successfully processed patent 21/174\n",
      "Processing patent 22/174: 027-652-790-587-92X\n",
      "Processing patent 22: 027-652-790-587-92X (~1948 tokens)\n",
      "‚úì Successfully processed patent 22/174\n",
      "Processing patent 23/174: 041-668-086-786-996\n",
      "Processing patent 23: 041-668-086-786-996 (~3000 tokens)\n",
      "‚úì Successfully processed patent 23/174\n",
      "Processing patent 24/174: 074-327-754-177-259\n",
      "Processing patent 24: 074-327-754-177-259 (~2237 tokens)\n",
      "‚úì Successfully processed patent 24/174\n",
      "Processing patent 25/174: 010-090-759-416-162\n",
      "Processing patent 25: 010-090-759-416-162 (~1871 tokens)\n",
      "‚úì Successfully processed patent 25/174\n",
      "Processing patent 26/174: 059-981-074-643-79X\n",
      "Processing patent 26: 059-981-074-643-79X (~2325 tokens)\n",
      "‚úì Successfully processed patent 26/174\n",
      "Processing patent 27/174: 092-649-582-800-933\n",
      "Processing patent 27: 092-649-582-800-933 (~3000 tokens)\n",
      "‚úì Successfully processed patent 27/174\n",
      "Processing patent 28/174: 156-755-255-606-569\n",
      "Processing patent 28: 156-755-255-606-569 (~2341 tokens)\n",
      "‚úì Successfully processed patent 28/174\n",
      "Processing patent 29/174: 197-095-250-985-420\n",
      "Processing patent 29: 197-095-250-985-420 (~3000 tokens)\n",
      "‚úì Successfully processed patent 29/174\n",
      "Processing patent 30/174: 157-414-018-604-19X\n",
      "Processing patent 30: 157-414-018-604-19X (~860 tokens)\n",
      "‚úì Successfully processed patent 30/174\n",
      "Progress saved to patent_analysis_output1/processed_patents_checkpoint_30_20250617_091102.json\n",
      "üìÅ Saved progress at patent 30\n",
      "Processing patent 31/174: 173-174-139-072-118\n",
      "Processing patent 31: 173-174-139-072-118 (~1995 tokens)\n",
      "‚úì Successfully processed patent 31/174\n",
      "Processing patent 32/174: 122-610-447-883-041\n",
      "Processing patent 32: 122-610-447-883-041 (~1965 tokens)\n",
      "‚úì Successfully processed patent 32/174\n",
      "Processing patent 33/174: 188-623-509-868-662\n",
      "Processing patent 33: 188-623-509-868-662 (~2253 tokens)\n",
      "‚úì Successfully processed patent 33/174\n",
      "Processing patent 34/174: 047-148-638-280-176\n",
      "Processing patent 34: 047-148-638-280-176 (~1539 tokens)\n",
      "‚úì Successfully processed patent 34/174\n",
      "Processing patent 35/174: 030-386-153-783-88X\n",
      "Processing patent 35: 030-386-153-783-88X (~2382 tokens)\n",
      "‚úì Successfully processed patent 35/174\n",
      "Processing patent 36/174: 195-131-671-444-668\n",
      "Processing patent 36: 195-131-671-444-668 (~1791 tokens)\n",
      "‚úì Successfully processed patent 36/174\n",
      "Processing patent 37/174: 123-438-789-390-479\n",
      "Processing patent 37: 123-438-789-390-479 (~2410 tokens)\n",
      "‚úì Successfully processed patent 37/174\n",
      "Processing patent 38/174: 038-556-992-896-279\n",
      "Processing patent 38: 038-556-992-896-279 (~3000 tokens)\n",
      "‚úì Successfully processed patent 38/174\n",
      "Processing patent 39/174: 047-534-075-006-290\n",
      "Processing patent 39: 047-534-075-006-290 (~3000 tokens)\n",
      "‚úì Successfully processed patent 39/174\n",
      "Processing patent 40/174: 051-786-376-412-976\n",
      "Processing patent 40: 051-786-376-412-976 (~1446 tokens)\n",
      "‚úì Successfully processed patent 40/174\n",
      "Progress saved to patent_analysis_output1/processed_patents_checkpoint_40_20250617_091149.json\n",
      "üìÅ Saved progress at patent 40\n",
      "Processing patent 41/174: 070-917-389-318-598\n",
      "Processing patent 41: 070-917-389-318-598 (~1633 tokens)\n",
      "‚úì Successfully processed patent 41/174\n",
      "Processing patent 42/174: 192-010-666-122-04X\n",
      "Processing patent 42: 192-010-666-122-04X (~3000 tokens)\n",
      "‚úì Successfully processed patent 42/174\n",
      "Processing patent 43/174: 176-209-529-587-885\n",
      "Processing patent 43: 176-209-529-587-885 (~2922 tokens)\n",
      "‚úì Successfully processed patent 43/174\n",
      "Processing patent 44/174: 014-143-781-289-974\n",
      "Processing patent 44: 014-143-781-289-974 (~1977 tokens)\n",
      "‚úì Successfully processed patent 44/174\n",
      "Processing patent 45/174: 054-801-105-273-208\n",
      "Processing patent 45: 054-801-105-273-208 (~2104 tokens)\n",
      "‚úì Successfully processed patent 45/174\n",
      "Processing patent 46/174: 154-052-040-538-42X\n",
      "Processing patent 46: 154-052-040-538-42X (~2733 tokens)\n",
      "‚úì Successfully processed patent 46/174\n",
      "Processing patent 47/174: 148-267-425-294-72X\n",
      "Processing patent 47: 148-267-425-294-72X (~2890 tokens)\n",
      "‚úì Successfully processed patent 47/174\n",
      "Processing patent 48/174: 161-382-530-134-79X\n",
      "Processing patent 48: 161-382-530-134-79X (~2455 tokens)\n",
      "‚úì Successfully processed patent 48/174\n",
      "Processing patent 49/174: 033-164-148-639-82X\n",
      "Processing patent 49: 033-164-148-639-82X (~2468 tokens)\n",
      "‚úì Successfully processed patent 49/174\n",
      "Processing patent 50/174: 098-610-600-168-872\n",
      "Processing patent 50: 098-610-600-168-872 (~3000 tokens)\n",
      "‚úì Successfully processed patent 50/174\n",
      "Progress saved to patent_analysis_output1/processed_patents_checkpoint_50_20250617_091238.json\n",
      "üìÅ Saved progress at patent 50\n",
      "Processing patent 51/174: 134-731-463-275-341\n",
      "Processing patent 51: 134-731-463-275-341 (~2804 tokens)\n",
      "‚úì Successfully processed patent 51/174\n",
      "Processing patent 52/174: 067-984-669-805-288\n",
      "Processing patent 52: 067-984-669-805-288 (~1899 tokens)\n",
      "‚úì Successfully processed patent 52/174\n",
      "Processing patent 53/174: 194-106-719-074-520\n",
      "Processing patent 53: 194-106-719-074-520 (~2196 tokens)\n",
      "‚úì Successfully processed patent 53/174\n",
      "Processing patent 54/174: 198-362-755-573-384\n",
      "Processing patent 54: 198-362-755-573-384 (~3000 tokens)\n",
      "‚úì Successfully processed patent 54/174\n",
      "Processing patent 55/174: 057-809-783-315-10X\n",
      "Processing patent 55: 057-809-783-315-10X (~1226 tokens)\n",
      "‚úì Successfully processed patent 55/174\n",
      "Processing patent 56/174: 143-024-387-598-774\n",
      "Processing patent 56: 143-024-387-598-774 (~3000 tokens)\n",
      "‚úì Successfully processed patent 56/174\n",
      "Processing patent 57/174: 007-126-905-721-573\n",
      "Processing patent 57: 007-126-905-721-573 (~2543 tokens)\n",
      "‚úì Successfully processed patent 57/174\n",
      "Processing patent 58/174: 175-148-572-654-972\n",
      "Processing patent 58: 175-148-572-654-972 (~1514 tokens)\n",
      "‚úì Successfully processed patent 58/174\n",
      "Processing patent 59/174: 081-582-559-895-96X\n",
      "Processing patent 59: 081-582-559-895-96X (~2158 tokens)\n",
      "‚úì Successfully processed patent 59/174\n",
      "Processing patent 60/174: 148-468-144-730-573\n",
      "Processing patent 60: 148-468-144-730-573 (~3000 tokens)\n",
      "‚úì Successfully processed patent 60/174\n",
      "Progress saved to patent_analysis_output1/processed_patents_checkpoint_60_20250617_091325.json\n",
      "üìÅ Saved progress at patent 60\n",
      "Processing patent 61/174: 151-244-732-659-49X\n",
      "Processing patent 61: 151-244-732-659-49X (~3000 tokens)\n",
      "‚úì Successfully processed patent 61/174\n",
      "Processing patent 62/174: 029-248-311-267-194\n",
      "Processing patent 62: 029-248-311-267-194 (~1854 tokens)\n",
      "‚úì Successfully processed patent 62/174\n",
      "Processing patent 63/174: 039-861-614-932-225\n",
      "Processing patent 63: 039-861-614-932-225 (~2942 tokens)\n",
      "‚úì Successfully processed patent 63/174\n",
      "Processing patent 64/174: 100-609-339-598-896\n",
      "Processing patent 64: 100-609-339-598-896 (~3000 tokens)\n",
      "‚úì Successfully processed patent 64/174\n",
      "Processing patent 65/174: 104-287-418-271-767\n",
      "Processing patent 65: 104-287-418-271-767 (~1265 tokens)\n",
      "‚úì Successfully processed patent 65/174\n",
      "Processing patent 66/174: 063-635-174-984-498\n",
      "Processing patent 66: 063-635-174-984-498 (~2751 tokens)\n",
      "‚úì Successfully processed patent 66/174\n",
      "Processing patent 67/174: 153-466-989-714-999\n",
      "Processing patent 67: 153-466-989-714-999 (~1398 tokens)\n",
      "‚úì Successfully processed patent 67/174\n",
      "Processing patent 68/174: 145-998-341-890-516\n",
      "Processing patent 68: 145-998-341-890-516 (~2136 tokens)\n",
      "‚úì Successfully processed patent 68/174\n",
      "Processing patent 69/174: 046-637-369-926-530\n",
      "Processing patent 69: 046-637-369-926-530 (~2778 tokens)\n",
      "‚úì Successfully processed patent 69/174\n",
      "Processing patent 70/174: 075-146-614-407-175\n",
      "Processing patent 70: 075-146-614-407-175 (~3000 tokens)\n",
      "‚úì Successfully processed patent 70/174\n",
      "Progress saved to patent_analysis_output1/processed_patents_checkpoint_70_20250617_091412.json\n",
      "üìÅ Saved progress at patent 70\n",
      "Processing patent 71/174: 088-023-572-144-347\n",
      "Processing patent 71: 088-023-572-144-347 (~3000 tokens)\n",
      "‚úì Successfully processed patent 71/174\n",
      "Processing patent 72/174: 014-417-462-061-441\n",
      "Processing patent 72: 014-417-462-061-441 (~3000 tokens)\n",
      "‚úì Successfully processed patent 72/174\n",
      "Processing patent 73/174: 118-882-669-355-900\n",
      "Processing patent 73: 118-882-669-355-900 (~1969 tokens)\n",
      "‚úì Successfully processed patent 73/174\n",
      "Processing patent 74/174: 102-277-156-370-48X\n",
      "Processing patent 74: 102-277-156-370-48X (~3000 tokens)\n",
      "‚úì Successfully processed patent 74/174\n",
      "Processing patent 75/174: 109-317-648-072-006\n",
      "Processing patent 75: 109-317-648-072-006 (~1397 tokens)\n",
      "‚úì Successfully processed patent 75/174\n",
      "Processing patent 76/174: 170-842-269-115-165\n",
      "Processing patent 76: 170-842-269-115-165 (~2201 tokens)\n",
      "‚úì Successfully processed patent 76/174\n",
      "Processing patent 77/174: 127-360-270-877-81X\n",
      "Processing patent 77: 127-360-270-877-81X (~1411 tokens)\n",
      "‚úì Successfully processed patent 77/174\n",
      "Processing patent 78/174: 063-867-572-652-643\n",
      "Processing patent 78: 063-867-572-652-643 (~3000 tokens)\n",
      "‚úì Successfully processed patent 78/174\n",
      "Processing patent 79/174: 175-444-277-823-514\n",
      "Processing patent 79: 175-444-277-823-514 (~1100 tokens)\n",
      "‚úì Successfully processed patent 79/174\n",
      "Processing patent 80/174: 126-283-888-708-214\n",
      "Processing patent 80: 126-283-888-708-214 (~3000 tokens)\n",
      "‚úì Successfully processed patent 80/174\n",
      "Progress saved to patent_analysis_output1/processed_patents_checkpoint_80_20250617_091457.json\n",
      "üìÅ Saved progress at patent 80\n",
      "Processing patent 81/174: 072-146-618-856-219\n",
      "Processing patent 81: 072-146-618-856-219 (~2308 tokens)\n",
      "‚úì Successfully processed patent 81/174\n",
      "Processing patent 82/174: 099-585-554-490-645\n",
      "Processing patent 82: 099-585-554-490-645 (~2828 tokens)\n",
      "‚úì Successfully processed patent 82/174\n",
      "Processing patent 83/174: 007-846-758-300-992\n",
      "Processing patent 83: 007-846-758-300-992 (~1090 tokens)\n",
      "‚úì Successfully processed patent 83/174\n",
      "Processing patent 84/174: 199-811-731-956-724\n",
      "Processing patent 84: 199-811-731-956-724 (~1951 tokens)\n",
      "‚úì Successfully processed patent 84/174\n",
      "Processing patent 85/174: 006-624-306-595-099\n",
      "Processing patent 85: 006-624-306-595-099 (~1976 tokens)\n",
      "‚úì Successfully processed patent 85/174\n",
      "Processing patent 86/174: 141-206-717-392-141\n",
      "Processing patent 86: 141-206-717-392-141 (~3000 tokens)\n",
      "‚úì Successfully processed patent 86/174\n",
      "Processing patent 87/174: 148-349-461-832-694\n",
      "Processing patent 87: 148-349-461-832-694 (~2526 tokens)\n",
      "‚úì Successfully processed patent 87/174\n",
      "Processing patent 88/174: 088-769-424-336-962\n",
      "Processing patent 88: 088-769-424-336-962 (~1642 tokens)\n",
      "‚úì Successfully processed patent 88/174\n",
      "Processing patent 89/174: 160-944-727-648-167\n",
      "Processing patent 89: 160-944-727-648-167 (~3000 tokens)\n",
      "‚úì Successfully processed patent 89/174\n",
      "Processing patent 90/174: 194-434-578-291-515\n",
      "Processing patent 90: 194-434-578-291-515 (~3000 tokens)\n",
      "‚úì Successfully processed patent 90/174\n",
      "Progress saved to patent_analysis_output1/processed_patents_checkpoint_90_20250617_091543.json\n",
      "üìÅ Saved progress at patent 90\n",
      "Processing patent 91/174: 000-152-677-120-075\n",
      "Processing patent 91: 000-152-677-120-075 (~3000 tokens)\n",
      "‚úì Successfully processed patent 91/174\n",
      "Processing patent 92/174: 099-601-677-696-579\n",
      "Processing patent 92: 099-601-677-696-579 (~2916 tokens)\n",
      "‚úì Successfully processed patent 92/174\n",
      "Processing patent 93/174: 147-547-997-895-15X\n",
      "Processing patent 93: 147-547-997-895-15X (~1876 tokens)\n",
      "‚úì Successfully processed patent 93/174\n",
      "Processing patent 94/174: 154-496-517-931-817\n",
      "Processing patent 94: 154-496-517-931-817 (~3000 tokens)\n",
      "‚úì Successfully processed patent 94/174\n",
      "Processing patent 95/174: 144-578-038-341-488\n",
      "Processing patent 95: 144-578-038-341-488 (~2534 tokens)\n",
      "‚úì Successfully processed patent 95/174\n",
      "Processing patent 96/174: 019-910-078-190-629\n",
      "Processing patent 96: 019-910-078-190-629 (~2804 tokens)\n",
      "‚úì Successfully processed patent 96/174\n",
      "Processing patent 97/174: 173-343-207-157-557\n",
      "Processing patent 97: 173-343-207-157-557 (~2454 tokens)\n",
      "‚úì Successfully processed patent 97/174\n",
      "Processing patent 98/174: 053-601-310-222-917\n",
      "Processing patent 98: 053-601-310-222-917 (~2851 tokens)\n",
      "‚úì Successfully processed patent 98/174\n",
      "Processing patent 99/174: 188-333-305-881-456\n",
      "Processing patent 99: 188-333-305-881-456 (~1172 tokens)\n",
      "‚úì Successfully processed patent 99/174\n",
      "Processing patent 100/174: 144-809-285-945-751\n",
      "Processing patent 100: 144-809-285-945-751 (~3000 tokens)\n",
      "‚úì Successfully processed patent 100/174\n",
      "Progress saved to patent_analysis_output1/processed_patents_checkpoint_100_20250617_091629.json\n",
      "üìÅ Saved progress at patent 100\n",
      "Processing patent 101/174: 063-530-109-806-440\n",
      "Processing patent 101: 063-530-109-806-440 (~2038 tokens)\n",
      "‚úì Successfully processed patent 101/174\n",
      "Processing patent 102/174: 005-666-763-856-839\n",
      "Processing patent 102: 005-666-763-856-839 (~3000 tokens)\n",
      "‚úì Successfully processed patent 102/174\n",
      "Processing patent 103/174: 017-138-129-876-230\n",
      "Processing patent 103: 017-138-129-876-230 (~1938 tokens)\n",
      "‚úì Successfully processed patent 103/174\n",
      "Processing patent 104/174: 068-043-442-380-475\n",
      "Processing patent 104: 068-043-442-380-475 (~1962 tokens)\n",
      "‚úì Successfully processed patent 104/174\n",
      "Processing patent 105/174: 152-355-924-468-848\n",
      "Processing patent 105: 152-355-924-468-848 (~2372 tokens)\n",
      "‚úì Successfully processed patent 105/174\n",
      "Processing patent 106/174: 187-847-409-002-841\n",
      "Processing patent 106: 187-847-409-002-841 (~1920 tokens)\n",
      "‚úì Successfully processed patent 106/174\n",
      "Processing patent 107/174: 107-880-197-484-967\n",
      "Processing patent 107: 107-880-197-484-967 (~3000 tokens)\n",
      "‚úì Successfully processed patent 107/174\n",
      "Processing patent 108/174: 196-449-894-096-337\n",
      "Processing patent 108: 196-449-894-096-337 (~1787 tokens)\n",
      "‚úì Successfully processed patent 108/174\n",
      "Processing patent 109/174: 047-751-888-209-301\n",
      "Processing patent 109: 047-751-888-209-301 (~1727 tokens)\n",
      "‚úì Successfully processed patent 109/174\n",
      "Processing patent 110/174: 068-144-882-104-776\n",
      "Processing patent 110: 068-144-882-104-776 (~1614 tokens)\n",
      "‚úì Successfully processed patent 110/174\n",
      "Progress saved to patent_analysis_output1/processed_patents_checkpoint_110_20250617_091714.json\n",
      "üìÅ Saved progress at patent 110\n",
      "Processing patent 111/174: 190-936-207-257-507\n",
      "Processing patent 111: 190-936-207-257-507 (~2206 tokens)\n",
      "‚úì Successfully processed patent 111/174\n",
      "Processing patent 112/174: 167-566-131-301-524\n",
      "Processing patent 112: 167-566-131-301-524 (~2340 tokens)\n",
      "‚úì Successfully processed patent 112/174\n",
      "Processing patent 113/174: 110-643-705-085-620\n",
      "Processing patent 113: 110-643-705-085-620 (~3000 tokens)\n",
      "‚úì Successfully processed patent 113/174\n",
      "Processing patent 114/174: 021-883-642-933-923\n",
      "Processing patent 114: 021-883-642-933-923 (~2441 tokens)\n",
      "‚úì Successfully processed patent 114/174\n",
      "Processing patent 115/174: 168-114-367-016-788\n",
      "Processing patent 115: 168-114-367-016-788 (~1370 tokens)\n",
      "‚úì Successfully processed patent 115/174\n",
      "Processing patent 116/174: 133-138-790-055-772\n",
      "Processing patent 116: 133-138-790-055-772 (~3000 tokens)\n",
      "‚úì Successfully processed patent 116/174\n",
      "Processing patent 117/174: 086-574-286-090-534\n",
      "Processing patent 117: 086-574-286-090-534 (~1727 tokens)\n",
      "‚úì Successfully processed patent 117/174\n",
      "Processing patent 118/174: 100-317-222-451-474\n",
      "Processing patent 118: 100-317-222-451-474 (~2651 tokens)\n",
      "‚úì Successfully processed patent 118/174\n",
      "Processing patent 119/174: 076-715-179-326-859\n",
      "Processing patent 119: 076-715-179-326-859 (~1810 tokens)\n",
      "‚úì Successfully processed patent 119/174\n",
      "Processing patent 120/174: 106-639-292-158-249\n",
      "Processing patent 120: 106-639-292-158-249 (~1602 tokens)\n",
      "‚úì Successfully processed patent 120/174\n",
      "Progress saved to patent_analysis_output1/processed_patents_checkpoint_120_20250617_091800.json\n",
      "üìÅ Saved progress at patent 120\n",
      "Processing patent 121/174: 156-289-246-308-425\n",
      "Processing patent 121: 156-289-246-308-425 (~2923 tokens)\n",
      "‚úì Successfully processed patent 121/174\n",
      "Processing patent 122/174: 060-953-668-643-444\n",
      "Processing patent 122: 060-953-668-643-444 (~3000 tokens)\n",
      "‚úì Successfully processed patent 122/174\n",
      "Processing patent 123/174: 130-610-074-312-966\n",
      "Processing patent 123: 130-610-074-312-966 (~3000 tokens)\n",
      "‚úì Successfully processed patent 123/174\n",
      "Processing patent 124/174: 004-203-580-589-363\n",
      "Processing patent 124: 004-203-580-589-363 (~3000 tokens)\n",
      "‚úì Successfully processed patent 124/174\n",
      "Processing patent 125/174: 150-447-330-472-28X\n",
      "Processing patent 125: 150-447-330-472-28X (~3000 tokens)\n",
      "‚úì Successfully processed patent 125/174\n",
      "Processing patent 126/174: 195-408-105-820-795\n",
      "Processing patent 126: 195-408-105-820-795 (~1662 tokens)\n",
      "‚úì Successfully processed patent 126/174\n",
      "Processing patent 127/174: 043-605-959-100-979\n",
      "Processing patent 127: 043-605-959-100-979 (~3000 tokens)\n",
      "‚úì Successfully processed patent 127/174\n",
      "Processing patent 128/174: 178-959-552-439-990\n",
      "Processing patent 128: 178-959-552-439-990 (~3000 tokens)\n",
      "‚úì Successfully processed patent 128/174\n",
      "Processing patent 129/174: 118-017-360-569-672\n",
      "Processing patent 129: 118-017-360-569-672 (~2262 tokens)\n",
      "‚úì Successfully processed patent 129/174\n",
      "Processing patent 130/174: 191-432-894-947-645\n",
      "Processing patent 130: 191-432-894-947-645 (~2985 tokens)\n",
      "‚úì Successfully processed patent 130/174\n",
      "Progress saved to patent_analysis_output1/processed_patents_checkpoint_130_20250617_091845.json\n",
      "üìÅ Saved progress at patent 130\n",
      "Processing patent 131/174: 026-040-568-655-473\n",
      "Processing patent 131: 026-040-568-655-473 (~3000 tokens)\n",
      "‚úì Successfully processed patent 131/174\n",
      "Processing patent 132/174: 137-263-675-367-082\n",
      "Processing patent 132: 137-263-675-367-082 (~3000 tokens)\n",
      "‚úì Successfully processed patent 132/174\n",
      "Processing patent 133/174: 009-208-440-609-259\n",
      "Processing patent 133: 009-208-440-609-259 (~1981 tokens)\n",
      "‚úì Successfully processed patent 133/174\n",
      "Processing patent 134/174: 183-398-107-952-394\n",
      "Processing patent 134: 183-398-107-952-394 (~2053 tokens)\n",
      "‚úì Successfully processed patent 134/174\n",
      "Processing patent 135/174: 037-124-820-840-257\n",
      "Processing patent 135: 037-124-820-840-257 (~2274 tokens)\n",
      "‚úì Successfully processed patent 135/174\n",
      "Processing patent 136/174: 166-209-741-514-533\n",
      "Processing patent 136: 166-209-741-514-533 (~3000 tokens)\n",
      "‚úì Successfully processed patent 136/174\n",
      "Processing patent 137/174: 009-098-732-754-779\n",
      "Processing patent 137: 009-098-732-754-779 (~2759 tokens)\n",
      "‚úì Successfully processed patent 137/174\n",
      "Processing patent 138/174: 045-603-964-182-773\n",
      "Processing patent 138: 045-603-964-182-773 (~2968 tokens)\n",
      "‚úì Successfully processed patent 138/174\n",
      "Processing patent 139/174: 155-375-822-702-004\n",
      "Processing patent 139: 155-375-822-702-004 (~2445 tokens)\n",
      "‚úì Successfully processed patent 139/174\n",
      "Processing patent 140/174: 020-498-612-514-202\n",
      "Processing patent 140: 020-498-612-514-202 (~2134 tokens)\n",
      "‚úì Successfully processed patent 140/174\n",
      "Progress saved to patent_analysis_output1/processed_patents_checkpoint_140_20250617_091932.json\n",
      "üìÅ Saved progress at patent 140\n",
      "Processing patent 141/174: 077-962-993-149-804\n",
      "Processing patent 141: 077-962-993-149-804 (~2361 tokens)\n",
      "‚úì Successfully processed patent 141/174\n",
      "Processing patent 142/174: 146-623-536-823-415\n",
      "Processing patent 142: 146-623-536-823-415 (~2160 tokens)\n",
      "‚úì Successfully processed patent 142/174\n",
      "Processing patent 143/174: 056-862-760-542-656\n",
      "Processing patent 143: 056-862-760-542-656 (~2574 tokens)\n",
      "‚úì Successfully processed patent 143/174\n",
      "Processing patent 144/174: 051-651-442-641-868\n",
      "Processing patent 144: 051-651-442-641-868 (~2050 tokens)\n",
      "‚úì Successfully processed patent 144/174\n",
      "Processing patent 145/174: 091-738-444-989-203\n",
      "Processing patent 145: 091-738-444-989-203 (~3000 tokens)\n",
      "‚úì Successfully processed patent 145/174\n",
      "Processing patent 146/174: 054-823-927-077-588\n",
      "Processing patent 146: 054-823-927-077-588 (~3000 tokens)\n",
      "‚úì Successfully processed patent 146/174\n",
      "Processing patent 147/174: 189-411-182-498-218\n",
      "Processing patent 147: 189-411-182-498-218 (~1479 tokens)\n",
      "‚úì Successfully processed patent 147/174\n",
      "Processing patent 148/174: 148-411-415-090-903\n",
      "Processing patent 148: 148-411-415-090-903 (~2897 tokens)\n",
      "‚úì Successfully processed patent 148/174\n",
      "Processing patent 149/174: 146-218-171-797-816\n",
      "Processing patent 149: 146-218-171-797-816 (~1900 tokens)\n",
      "‚úì Successfully processed patent 149/174\n",
      "Processing patent 150/174: 139-953-245-967-126\n",
      "Processing patent 150: 139-953-245-967-126 (~3000 tokens)\n",
      "‚úì Successfully processed patent 150/174\n",
      "Progress saved to patent_analysis_output1/processed_patents_checkpoint_150_20250617_092018.json\n",
      "üìÅ Saved progress at patent 150\n",
      "Processing patent 151/174: 004-109-111-936-894\n",
      "Processing patent 151: 004-109-111-936-894 (~2363 tokens)\n",
      "‚úì Successfully processed patent 151/174\n",
      "Processing patent 152/174: 151-552-527-834-02X\n",
      "Processing patent 152: 151-552-527-834-02X (~3000 tokens)\n",
      "‚úì Successfully processed patent 152/174\n",
      "Processing patent 153/174: 141-548-245-375-641\n",
      "Processing patent 153: 141-548-245-375-641 (~3000 tokens)\n",
      "‚úì Successfully processed patent 153/174\n",
      "Processing patent 154/174: 153-365-008-723-60X\n",
      "Processing patent 154: 153-365-008-723-60X (~3000 tokens)\n",
      "‚úì Successfully processed patent 154/174\n",
      "Processing patent 155/174: 163-654-550-199-573\n",
      "Processing patent 155: 163-654-550-199-573 (~3000 tokens)\n",
      "‚úì Successfully processed patent 155/174\n",
      "Processing patent 156/174: 111-777-939-519-68X\n",
      "Processing patent 156: 111-777-939-519-68X (~2618 tokens)\n",
      "‚úì Successfully processed patent 156/174\n",
      "Processing patent 157/174: 133-605-858-278-383\n",
      "Processing patent 157: 133-605-858-278-383 (~2797 tokens)\n",
      "‚úì Successfully processed patent 157/174\n",
      "Processing patent 158/174: 141-468-546-111-359\n",
      "Processing patent 158: 141-468-546-111-359 (~3000 tokens)\n",
      "‚úì Successfully processed patent 158/174\n",
      "Processing patent 159/174: 104-523-406-829-585\n",
      "Processing patent 159: 104-523-406-829-585 (~2333 tokens)\n",
      "‚úì Successfully processed patent 159/174\n",
      "Processing patent 160/174: 057-954-266-808-003\n",
      "Processing patent 160: 057-954-266-808-003 (~2949 tokens)\n",
      "‚úì Successfully processed patent 160/174\n",
      "Progress saved to patent_analysis_output1/processed_patents_checkpoint_160_20250617_092105.json\n",
      "üìÅ Saved progress at patent 160\n",
      "Processing patent 161/174: 151-861-053-049-204\n",
      "Processing patent 161: 151-861-053-049-204 (~1292 tokens)\n",
      "‚úì Successfully processed patent 161/174\n",
      "Processing patent 162/174: 124-397-744-900-883\n",
      "Processing patent 162: 124-397-744-900-883 (~1667 tokens)\n",
      "‚úì Successfully processed patent 162/174\n",
      "Processing patent 163/174: 069-816-774-283-119\n",
      "Processing patent 163: 069-816-774-283-119 (~1667 tokens)\n",
      "‚úì Successfully processed patent 163/174\n",
      "Processing patent 164/174: 059-243-980-923-078\n",
      "Processing patent 164: 059-243-980-923-078 (~3000 tokens)\n",
      "‚úì Successfully processed patent 164/174\n",
      "Processing patent 165/174: 164-453-592-705-759\n",
      "Processing patent 165: 164-453-592-705-759 (~2412 tokens)\n",
      "‚úì Successfully processed patent 165/174\n",
      "Processing patent 166/174: 110-205-395-356-308\n",
      "Processing patent 166: 110-205-395-356-308 (~3000 tokens)\n",
      "‚úì Successfully processed patent 166/174\n",
      "Processing patent 167/174: 039-521-201-094-074\n",
      "Processing patent 167: 039-521-201-094-074 (~3000 tokens)\n",
      "‚úì Successfully processed patent 167/174\n",
      "Processing patent 168/174: 105-569-879-718-236\n",
      "Processing patent 168: 105-569-879-718-236 (~2221 tokens)\n",
      "‚úì Successfully processed patent 168/174\n",
      "Processing patent 169/174: 120-447-377-906-059\n",
      "Processing patent 169: 120-447-377-906-059 (~3000 tokens)\n",
      "‚úì Successfully processed patent 169/174\n",
      "Processing patent 170/174: 125-854-461-858-061\n",
      "Processing patent 170: 125-854-461-858-061 (~1978 tokens)\n",
      "‚úì Successfully processed patent 170/174\n",
      "Progress saved to patent_analysis_output1/processed_patents_checkpoint_170_20250617_092150.json\n",
      "üìÅ Saved progress at patent 170\n",
      "Processing patent 171/174: 064-061-744-662-703\n",
      "Processing patent 171: 064-061-744-662-703 (~2668 tokens)\n",
      "‚úì Successfully processed patent 171/174\n",
      "Processing patent 172/174: 116-864-765-045-29X\n",
      "Processing patent 172: 116-864-765-045-29X (~2016 tokens)\n",
      "‚úì Successfully processed patent 172/174\n",
      "Processing patent 173/174: 056-572-752-855-040\n",
      "Processing patent 173: 056-572-752-855-040 (~3000 tokens)\n",
      "‚úì Successfully processed patent 173/174\n",
      "Processing patent 174/174: 147-161-553-114-808\n",
      "Processing patent 174: 147-161-553-114-808 (~2498 tokens)\n",
      "‚úì Successfully processed patent 174/174\n",
      "Results saved in multiple formats with timestamp 20250617_092207\n",
      "\n",
      "==================================================\n",
      "PROCESSING SUMMARY\n",
      "==================================================\n",
      "Total patents processed: 174\n",
      "Total patents failed: 0\n",
      "Success rate: 100.0%\n",
      "\n",
      "Top Primary Categories:\n",
      "  Wireless Communication: 13\n",
      "  Computer Vision: 8\n",
      "  Wireless Communication Systems: 4\n",
      "  Image Processing: 4\n",
      "  Video Compression: 3\n",
      "  Image Processing and Computer Vision: 3\n",
      "  Image Processing and Generation: 3\n",
      "  AI/ML Architecture: 3\n",
      "  Cybersecurity: 3\n",
      "  Hardware Architecture: 3\n",
      "\n",
      "Top AV Technology Areas:\n",
      "  ai_ml_architecture: 141\n",
      "  data_processing: 141\n",
      "  software_algorithms: 85\n",
      "  perception_sensing: 47\n",
      "  hardware_sensors: 43\n",
      "  v2x_communication: 30\n",
      "  simulation_testing: 30\n",
      "  human_machine_interface: 23\n",
      "  other: 22\n",
      "  vehicle_control_systems: 13\n",
      "==================================================\n",
      "Processing complete! Successfully processed 174 patents\n",
      "Failed patents: 0\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize pipeline\n",
    "    pipeline = PatentAnalysisPipeline(\n",
    "        jsonl_file_path=\"av_patentdata.jsonl\",\n",
    "        output_dir=\"patent_analysis_output1\"\n",
    "    )\n",
    "    \n",
    "    # Load data\n",
    "    pipeline.load_data()\n",
    "    \n",
    "    # Process all patents (can resume from specific index if needed)\n",
    "    pipeline.process_all_patents(start_idx=0, batch_size=10)\n",
    "    \n",
    "    # Or process a subset for testing\n",
    "    # pipeline.process_all_patents(start_idx=0, batch_size=5)  # Process first 5 patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "684956e2-e883-44c6-afd4-2408c91ff816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patents in JSON: 493\n",
      "Number of patents in CSV: 667\n",
      "Number of missing patents in JSON: 174\n",
      "Missing Lens IDs:\n",
      "000-152-677-120-075\n",
      "004-109-111-936-894\n",
      "004-203-580-589-363\n",
      "005-666-763-856-839\n",
      "006-624-306-595-099\n",
      "007-126-905-721-573\n",
      "007-846-758-300-992\n",
      "009-098-732-754-779\n",
      "009-208-440-609-259\n",
      "010-090-759-416-162\n",
      "014-143-781-289-974\n",
      "014-417-462-061-441\n",
      "017-138-129-876-230\n",
      "019-860-269-598-923\n",
      "019-910-078-190-629\n",
      "020-498-612-514-202\n",
      "021-382-421-165-451\n",
      "021-883-642-933-923\n",
      "022-953-362-574-29X\n",
      "025-635-593-546-830\n",
      "026-040-568-655-473\n",
      "027-652-790-587-92X\n",
      "029-248-311-267-194\n",
      "030-386-153-783-88X\n",
      "033-164-148-639-82X\n",
      "035-513-494-375-092\n",
      "035-961-451-891-408\n",
      "037-124-820-840-257\n",
      "038-556-992-896-279\n",
      "039-521-201-094-074\n",
      "039-861-614-932-225\n",
      "041-668-086-786-996\n",
      "043-605-959-100-979\n",
      "045-603-964-182-773\n",
      "046-637-369-926-530\n",
      "047-148-638-280-176\n",
      "047-534-075-006-290\n",
      "047-751-888-209-301\n",
      "051-651-442-641-868\n",
      "051-786-376-412-976\n",
      "053-601-310-222-917\n",
      "054-801-105-273-208\n",
      "054-823-927-077-588\n",
      "056-572-752-855-040\n",
      "056-862-760-542-656\n",
      "057-809-783-315-10X\n",
      "057-954-266-808-003\n",
      "059-243-980-923-078\n",
      "059-981-074-643-79X\n",
      "060-953-668-643-444\n",
      "063-530-109-806-440\n",
      "063-635-174-984-498\n",
      "063-867-572-652-643\n",
      "064-061-744-662-703\n",
      "067-984-669-805-288\n",
      "068-043-442-380-475\n",
      "068-144-882-104-776\n",
      "069-816-774-283-119\n",
      "070-917-389-318-598\n",
      "072-146-618-856-219\n",
      "074-327-754-177-259\n",
      "075-146-614-407-175\n",
      "076-715-179-326-859\n",
      "077-962-993-149-804\n",
      "081-582-559-895-96X\n",
      "086-574-286-090-534\n",
      "088-023-572-144-347\n",
      "088-769-424-336-962\n",
      "090-323-946-857-971\n",
      "091-738-444-989-203\n",
      "092-649-582-800-933\n",
      "094-369-473-781-696\n",
      "097-230-147-819-508\n",
      "098-610-600-168-872\n",
      "099-585-554-490-645\n",
      "099-601-677-696-579\n",
      "100-317-222-451-474\n",
      "100-609-339-598-896\n",
      "102-277-156-370-48X\n",
      "102-417-092-882-495\n",
      "104-287-418-271-767\n",
      "104-523-406-829-585\n",
      "105-569-879-718-236\n",
      "106-639-292-158-249\n",
      "107-880-197-484-967\n",
      "109-317-648-072-006\n",
      "110-205-395-356-308\n",
      "110-643-705-085-620\n",
      "111-777-939-519-68X\n",
      "116-835-229-588-01X\n",
      "116-864-765-045-29X\n",
      "118-017-360-569-672\n",
      "118-882-669-355-900\n",
      "120-447-377-906-059\n",
      "122-610-447-883-041\n",
      "123-438-789-390-479\n",
      "124-397-744-900-883\n",
      "125-854-461-858-061\n",
      "126-283-888-708-214\n",
      "127-360-270-877-81X\n",
      "130-610-074-312-966\n",
      "133-138-790-055-772\n",
      "133-605-858-278-383\n",
      "134-731-463-275-341\n",
      "137-263-675-367-082\n",
      "139-953-245-967-126\n",
      "141-206-717-392-141\n",
      "141-468-546-111-359\n",
      "141-548-245-375-641\n",
      "143-024-387-598-774\n",
      "144-578-038-341-488\n",
      "144-809-285-945-751\n",
      "145-998-341-890-516\n",
      "146-218-171-797-816\n",
      "146-320-903-404-194\n",
      "146-623-536-823-415\n",
      "147-161-553-114-808\n",
      "147-547-997-895-15X\n",
      "148-267-425-294-72X\n",
      "148-349-461-832-694\n",
      "148-411-415-090-903\n",
      "148-468-144-730-573\n",
      "150-447-330-472-28X\n",
      "151-244-732-659-49X\n",
      "151-552-527-834-02X\n",
      "151-861-053-049-204\n",
      "152-355-924-468-848\n",
      "153-365-008-723-60X\n",
      "153-466-989-714-999\n",
      "154-052-040-538-42X\n",
      "154-496-517-931-817\n",
      "155-375-822-702-004\n",
      "156-289-246-308-425\n",
      "156-755-255-606-569\n",
      "157-414-018-604-19X\n",
      "157-924-235-494-222\n",
      "158-879-448-169-219\n",
      "160-944-727-648-167\n",
      "161-382-530-134-79X\n",
      "163-654-550-199-573\n",
      "164-453-592-705-759\n",
      "165-884-370-654-504\n",
      "166-209-741-514-533\n",
      "167-566-131-301-524\n",
      "168-114-367-016-788\n",
      "170-842-269-115-165\n",
      "173-174-139-072-118\n",
      "173-343-207-157-557\n",
      "175-148-572-654-972\n",
      "175-337-774-629-516\n",
      "175-444-277-823-514\n",
      "176-209-529-587-885\n",
      "178-959-552-439-990\n",
      "182-045-319-534-59X\n",
      "183-398-107-952-394\n",
      "185-160-791-286-190\n",
      "187-847-409-002-841\n",
      "188-333-305-881-456\n",
      "188-623-509-868-662\n",
      "189-411-182-498-218\n",
      "190-936-207-257-507\n",
      "191-432-894-947-645\n",
      "192-010-666-122-04X\n",
      "192-586-311-363-276\n",
      "192-813-724-793-917\n",
      "194-106-719-074-520\n",
      "194-434-578-291-515\n",
      "195-131-671-444-668\n",
      "195-408-105-820-795\n",
      "196-449-894-096-337\n",
      "196-557-021-684-98X\n",
      "197-095-250-985-420\n",
      "198-362-755-573-384\n",
      "199-811-731-956-724\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# File paths\n",
    "json_path = r\"C:\\Users\\Aniket Shinde\\Desktop\\Main\\Jupyter Notebooks\\patent_analysis_output\\processed_patents_checkpoint_650_20250616_193652.json\"\n",
    "csv_path = \"lens-export.csv\"\n",
    "\n",
    "# Read JSON and collect lens_ids\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    json_data = json.load(f)\n",
    "    json_lens_ids = {patent.get(\"lens_id\") for patent in json_data if \"lens_id\" in patent}\n",
    "\n",
    "# Read CSV and collect Lens ID column\n",
    "csv_lens_ids = set()\n",
    "with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        lens_id = row.get(\"Lens ID\")\n",
    "        if lens_id:\n",
    "            csv_lens_ids.add(lens_id)\n",
    "\n",
    "# Find missing IDs\n",
    "missing_in_json = csv_lens_ids - json_lens_ids\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of patents in JSON: {len(json_lens_ids)}\")\n",
    "print(f\"Number of patents in CSV: {len(csv_lens_ids)}\")\n",
    "print(f\"Number of missing patents in JSON: {len(missing_in_json)}\")\n",
    "print(\"Missing Lens IDs:\")\n",
    "for lens_id in sorted(missing_in_json):\n",
    "    print(lens_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "416844cc-06ae-463e-add5-9cf3387572b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patent objects (lens_ids): 174\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_path = r\"C:\\Users\\Aniket Shinde\\Desktop\\Main\\Jupyter Notebooks\\patent_analysis_output1\\patent_analysis_results_20250617_092207.json\"\n",
    "\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    lens_ids = [patent.get(\"lens_id\") for patent in data if \"lens_id\" in patent]\n",
    "\n",
    "print(f\"Number of patent objects (lens_ids): {len(lens_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1abcb0e8-adbf-46f3-8035-19856e40fbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patent objects (lens_ids): 493\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_path = r\"C:\\Users\\Aniket Shinde\\Desktop\\Main\\Jupyter Notebooks\\patent_analysis_output\\processed_patents_checkpoint_650_20250616_193652.json\"\n",
    "\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    lens_ids = [patent.get(\"lens_id\") for patent in data if \"lens_id\" in patent]\n",
    "\n",
    "print(f\"Number of patent objects (lens_ids): {len(lens_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84633f6d-9fa4-4226-b93d-a4646e36af7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined file saved to: C:\\Users\\Aniket Shinde\\Desktop\\Main\\Jupyter Notebooks\\av_patent_data.json\n",
      "Total patents combined: 667\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Input file paths\n",
    "file1 = r\"C:\\Users\\Aniket Shinde\\Desktop\\Main\\Jupyter Notebooks\\patent_analysis_output\\processed_patents_checkpoint_650_20250616_193652.json\"\n",
    "file2 = r\"C:\\Users\\Aniket Shinde\\Desktop\\Main\\Jupyter Notebooks\\patent_analysis_output1\\patent_analysis_results_20250617_092207.json\"\n",
    "\n",
    "# Output file path\n",
    "output_file = r\"C:\\Users\\Aniket Shinde\\Desktop\\Main\\Jupyter Notebooks\\av_patent_data.json\"\n",
    "\n",
    "# Load both files\n",
    "with open(file1, 'r', encoding='utf-8') as f1:\n",
    "    data1 = json.load(f1)\n",
    "\n",
    "with open(file2, 'r', encoding='utf-8') as f2:\n",
    "    data2 = json.load(f2)\n",
    "\n",
    "# Combine them\n",
    "combined_data = data1 + data2\n",
    "\n",
    "# Optional: confirm no duplicate lens_ids\n",
    "lens_ids = [item.get(\"lens_id\") for item in combined_data if \"lens_id\" in item]\n",
    "assert len(lens_ids) == len(set(lens_ids)), \"Duplicate lens_ids detected!\"\n",
    "\n",
    "# Save to output\n",
    "with open(output_file, 'w', encoding='utf-8') as out:\n",
    "    json.dump(combined_data, out, indent=2)\n",
    "\n",
    "print(f\"Combined file saved to: {output_file}\")\n",
    "print(f\"Total patents combined: {len(combined_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3ec2295-fd1a-4748-9b37-662a3f1cf97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All lens IDs in lens-export.csv are present in the combined JSON.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# File paths\n",
    "csv_path = \"lens-export.csv\"\n",
    "combined_json_path = r\"C:\\Users\\Aniket Shinde\\Desktop\\Main\\Jupyter Notebooks\\av_patent_data.json\"\n",
    "\n",
    "# Step 1: Load CSV Lens IDs\n",
    "csv_lens_ids = set()\n",
    "with open(csv_path, 'r', encoding='utf-8') as f_csv:\n",
    "    reader = csv.DictReader(f_csv)\n",
    "    for row in reader:\n",
    "        lens_id = row.get(\"Lens ID\")\n",
    "        if lens_id:\n",
    "            csv_lens_ids.add(lens_id)\n",
    "\n",
    "# Step 2: Load Combined JSON Lens IDs\n",
    "with open(combined_json_path, 'r', encoding='utf-8') as f_json:\n",
    "    json_data = json.load(f_json)\n",
    "    json_lens_ids = {patent.get(\"lens_id\") for patent in json_data if \"lens_id\" in patent}\n",
    "\n",
    "# Step 3: Compare\n",
    "missing_ids = csv_lens_ids - json_lens_ids\n",
    "\n",
    "# Results\n",
    "if not missing_ids:\n",
    "    print(\"‚úÖ All lens IDs in lens-export.csv are present in the combined JSON.\")\n",
    "else:\n",
    "    print(f\"‚ùå {len(missing_ids)} lens IDs are missing in the combined JSON.\")\n",
    "    print(\"Missing Lens IDs:\")\n",
    "    for lens_id in sorted(missing_ids):\n",
    "        print(lens_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c08966d-75f1-4f2b-903f-cc9483ce377d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys in each patent object:\n",
      "- lens_id\n",
      "- invention_title_text\n",
      "- abstract_text\n",
      "- applicant_name\n",
      "- date_published\n",
      "- earliest_claim_date\n",
      "- cpc_symbols\n",
      "- claims\n",
      "- description\n",
      "- problem_addressed\n",
      "- proposed_solution\n",
      "- novelty_aspect\n",
      "- technical_approach\n",
      "- primary_category\n",
      "- secondary_categories\n",
      "- categorization_confidence\n",
      "- av_technology_areas\n",
      "- processing_timestamp\n",
      "- estimated_tokens\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Path to combined JSON file\n",
    "combined_json_path = r\"C:\\Users\\Aniket Shinde\\Desktop\\Main\\Jupyter Notebooks\\av_patent_data.json\"\n",
    "\n",
    "# Load JSON data\n",
    "with open(combined_json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Sanity check\n",
    "if not data:\n",
    "    print(\"‚ùå The JSON file is empty.\")\n",
    "else:\n",
    "    # Print top-level keys of the first patent object\n",
    "    print(\"Top-level keys in each patent object:\")\n",
    "    for key in data[0].keys():\n",
    "        print(\"-\", key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a2a7ed-8039-48a6-a4b5-c51b87ca678c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
